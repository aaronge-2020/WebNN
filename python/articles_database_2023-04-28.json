{
    "articles": [
        {
            "title": "Classical-to-Quantum Sequence Encoding in Genomics",
            "authors": [
                "Nouhaila Innan",
                "Muhammad Al-Zafar Khan"
            ],
            "abstract": "DNA sequencing allows for the determination of the genetic code of an\norganism, and therefore is an indispensable tool that has applications in\nMedicine, Life Sciences, Evolutionary Biology, Food Sciences and Technology,\nand Agriculture. In this paper, we present several novel methods of performing\nclassical-to-quantum data encoding inspired by various mathematical fields, and\nwe demonstrate these ideas within Bioinformatics. In particular, we introduce\nalgorithms that draw inspiration from diverse fields such as Electrical and\nElectronic Engineering, Information Theory, Differential Geometry, and Neural\nNetwork architectures. We provide a complete overview of the existing data\nencoding schemes and show how to use them in Genomics. The algorithms provided\nutilise lossless compression, wavelet-based encoding, and information entropy.\nMoreover, we propose a contemporary method for testing encoded DNA sequences\nusing Quantum Boltzmann Machines. To evaluate the effectiveness of our\nalgorithms, we discuss a potential dataset that serves as a sandbox environment\nfor testing against real-world scenarios. Our research contributes to\ndeveloping classical-to-quantum data encoding methods in the science of\nBioinformatics by introducing innovative algorithms that utilise diverse fields\nand advanced techniques. Our findings offer insights into the potential of\nQuantum Computing in Bioinformatics and have implications for future research\nin this area.",
            "categories": [
                "quant-ph",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2304.10786v1",
            "date": "2023-04-21 07:35:49+00:00"
        },
        {
            "title": "PCD2Vec: A Poisson Correction Distance-Based Approach for Viral Host Classification",
            "authors": [
                "Sarwan Ali",
                "Taslim Murad",
                "Murray Patterson"
            ],
            "abstract": "Coronaviruses are membrane-enveloped, non-segmented positive-strand RNA\nviruses belonging to the Coronaviridae family. Various animal species, mainly\nmammalian and avian, are severely infected by various coronaviruses, causing\nserious concerns like the recent pandemic (COVID-19). Therefore, building a\ndeeper understanding of these viruses is essential to devise prevention and\nmitigation mechanisms. In the Coronavirus genome, an essential structural\nregion is the spike region, and it's responsible for attaching the virus to the\nhost cell membrane. Therefore, the usage of only the spike protein, instead of\nthe full genome, provides most of the essential information for performing\nanalyses such as host classification. In this paper, we propose a novel method\nfor predicting the host specificity of coronaviruses by analyzing spike protein\nsequences from different viral subgenera and species. Our method involves using\nthe Poisson correction distance to generate a distance matrix, followed by\nusing a radial basis function (RBF) kernel and kernel principal component\nanalysis (PCA) to generate a low-dimensional embedding. Finally, we apply\nclassification algorithms to the low-dimensional embedding to generate the\nresulting predictions of the host specificity of coronaviruses. We provide\ntheoretical proofs for the non-negativity, symmetry, and triangle inequality\nproperties of the Poisson correction distance metric, which are important\nproperties in a machine-learning setting. By encoding the spike protein\nstructure and sequences using this comprehensive approach, we aim to uncover\nhidden patterns in the biological sequences to make accurate predictions about\nhost specificity. Finally, our classification results illustrate that our\nmethod can achieve higher predictive accuracy and improve performance over\nexisting baselines.",
            "categories": [
                "q-bio.QM",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2304.06731v1",
            "date": "2023-04-13 03:02:22+00:00"
        },
        {
            "title": "DiscoGen: Learning to Discover Gene Regulatory Networks",
            "authors": [
                "Nan Rosemary Ke",
                "Sara-Jane Dunn",
                "Jorg Bornschein",
                "Silvia Chiappa",
                "Melanie Rey",
                "Jean-Baptiste Lespiau",
                "Albin Cassirer",
                "Jane Wang",
                "Theophane Weber",
                "David Barrett",
                "Matthew Botvinick",
                "Anirudh Goyal",
                "Mike Mozer",
                "Danilo Rezende"
            ],
            "abstract": "Accurately inferring Gene Regulatory Networks (GRNs) is a critical and\nchallenging task in biology. GRNs model the activatory and inhibitory\ninteractions between genes and are inherently causal in nature. To accurately\nidentify GRNs, perturbational data is required. However, most GRN discovery\nmethods only operate on observational data. Recent advances in neural\nnetwork-based causal discovery methods have significantly improved causal\ndiscovery, including handling interventional data, improvements in performance\nand scalability. However, applying state-of-the-art (SOTA) causal discovery\nmethods in biology poses challenges, such as noisy data and a large number of\nsamples. Thus, adapting the causal discovery methods is necessary to handle\nthese challenges. In this paper, we introduce DiscoGen, a neural network-based\nGRN discovery method that can denoise gene expression measurements and handle\ninterventional data. We demonstrate that our model outperforms SOTA neural\nnetwork-based causal discovery methods.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2304.05823v1",
            "date": "2023-04-12 13:02:49+00:00"
        },
        {
            "title": "Transcriptomics-based matching of drugs to diseases with deep learning",
            "authors": [
                "Yannis Papanikolaou",
                "Francesco Tuveri",
                "Misa Ogura",
                "Daniel O'Donovan"
            ],
            "abstract": "In this work we present a deep learning approach to conduct hypothesis-free,\ntranscriptomics-based matching of drugs for diseases. Our proposed neural\nnetwork architecture is trained on approved drug-disease indications, taking as\ninput the relevant disease and drug differential gene expression profiles, and\nlearns to identify novel indications. We assemble an evaluation dataset of\ndisease-drug indications spanning 68 diseases and evaluate in silico our\napproach against the most widely used transcriptomics-based matching baselines,\nCMap and the Characteristic Direction. Our results show a more than 200%\nimprovement over both baselines in terms of standard retrieval metrics. We\nfurther showcase our model's ability to capture different genes' expressions\ninteractions among drugs and diseases. We provide our trained models, data and\ncode to predict with them at https://github.com/healx/dgem-nn-public.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2303.11695v1",
            "date": "2023-03-21 09:32:31+00:00"
        },
        {
            "title": "Multimodal Data Integration for Oncology in the Era of Deep Neural Networks: A Review",
            "authors": [
                "Asim Waqas",
                "Aakash Tripathi",
                "Ravi P. Ramachandran",
                "Paul Stewart",
                "Ghulam Rasool"
            ],
            "abstract": "Cancer has relational information residing at varying scales, modalities, and\nresolutions of the acquired data, such as radiology, pathology, genomics,\nproteomics, and clinical records. Integrating diverse data types can improve\nthe accuracy and reliability of cancer diagnosis and treatment. There can be\ndisease-related information that is too subtle for humans or existing\ntechnological tools to discern visually. Traditional methods typically focus on\npartial or unimodal information about biological systems at individual scales\nand fail to encapsulate the complete spectrum of the heterogeneous nature of\ndata. Deep neural networks have facilitated the development of sophisticated\nmultimodal data fusion approaches that can extract and integrate relevant\ninformation from multiple sources. Recent deep learning frameworks such as\nGraph Neural Networks (GNNs) and Transformers have shown remarkable success in\nmultimodal learning. This review article provides an in-depth analysis of the\nstate-of-the-art in GNNs and Transformers for multimodal data fusion in\noncology settings, highlighting notable research studies and their findings. We\nalso discuss the foundations of multimodal learning, inherent challenges, and\nopportunities for integrative learning in oncology. By examining the current\nstate and potential future developments of multimodal data integration in\noncology, we aim to demonstrate the promising role that multimodal neural\nnetworks can play in cancer prevention, early detection, and treatment through\ninformed oncology practices in personalized settings.",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2303.06471v1",
            "date": "2023-03-11 17:52:03+00:00"
        },
        {
            "title": "Resource saving taxonomy classification with k-mer distributions and machine learning",
            "authors": [
                "Wolfgang Fuhl",
                "Susanne Zabel",
                "Kay Nieselt"
            ],
            "abstract": "Modern high throughput sequencing technologies like metagenomic sequencing\ngenerate millions of sequences which have to be classified based on their\ntaxonomic rank. Modern approaches either apply local alignment and comparison\nto existing data sets like MMseqs2 or use deep neural networks as it is done in\nDeepMicrobes and BERTax. Alignment-based approaches are costly in terms of\nruntime, especially since databases get larger and larger. For the deep\nlearning-based approaches, specialized hardware is necessary for a computation,\nwhich consumes large amounts of energy. In this paper, we propose to use\n$k$-mer distributions obtained from DNA as features to classify its taxonomic\norigin using machine learning approaches like the subspace $k$-nearest\nneighbors algorithm, neural networks or bagged decision trees. In addition, we\npropose a feature space data set balancing approach, which allows reducing the\ndata set for training and improves the performance of the classifiers. By\ncomparing performance, time, and memory consumption of our approach to those of\nstate-of-the-art algorithms (BERTax and MMseqs2) using several datasets, we\nshow that our approach improves the classification on the genus level and\nachieves comparable results for the superkingdom and phylum level.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FTaxonomyClassification&mode=list",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2303.06154v1",
            "date": "2023-03-10 08:01:08+00:00"
        },
        {
            "title": "Learning the Finer Things: Bayesian Structure Learning at the Instantiation Level",
            "authors": [
                "Chase Yakaboski",
                "Eugene Santos Jr"
            ],
            "abstract": "Successful machine learning methods require a trade-off between memorization\nand generalization. Too much memorization and the model cannot generalize to\nunobserved examples. Too much over-generalization and we risk under-fitting the\ndata. While we commonly measure their performance through cross validation and\naccuracy metrics, how should these algorithms cope in domains that are\nextremely under-determined where accuracy is always unsatisfactory? We present\na novel probabilistic graphical model structure learning approach that can\nlearn, generalize and explain in these elusive domains by operating at the\nrandom variable instantiation level. Using Minimum Description Length (MDL)\nanalysis, we propose a new decomposition of the learning problem over all\ntraining exemplars, fusing together minimal entropy inferences to construct a\nfinal knowledge base. By leveraging Bayesian Knowledge Bases (BKBs), a\nframework that operates at the instantiation level and inherently subsumes\nBayesian Networks (BNs), we develop both a theoretical MDL score and associated\nstructure learning algorithm that demonstrates significant improvements over\nlearned BNs on 40 benchmark datasets. Further, our algorithm incorporates\nrecent off-the-shelf DAG learning techniques enabling tractable results even on\nlarge problems. We then demonstrate the utility of our approach in a\nsignificantly under-determined domain by learning gene regulatory networks on\nbreast cancer gene mutational data available from The Cancer Genome Atlas\n(TCGA).",
            "categories": [
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2303.04339v1",
            "date": "2023-03-08 02:31:49+00:00"
        },
        {
            "title": "Seq-HyGAN: Sequence Classification via Hypergraph Attention Network",
            "authors": [
                "Khaled Mohammed Saifuddin",
                "Corey May",
                "Farhan Tanvir",
                "Muhammad Ifte Khairul Islam",
                "Esra Akbas"
            ],
            "abstract": "Sequence classification has a wide range of real-world applications in\ndifferent domains, such as genome classification in health and anomaly\ndetection in business. However, the lack of explicit features in sequence data\nmakes it difficult for machine learning models. While Neural Network (NN)\nmodels address this with learning features automatically, they are limited to\ncapturing adjacent structural connections and ignore global, higher-order\ninformation between the sequences. To address these challenges in the sequence\nclassification problems, we propose a novel Hypergraph Attention Network model,\nnamely Seq-HyGAN. To capture the complex structural similarity between sequence\ndata, we first create a hypergraph where the sequences are depicted as\nhyperedges and subsequences extracted from sequences are depicted as nodes.\nAdditionally, we introduce an attention-based Hypergraph Neural Network model\nthat utilizes a two-level attention mechanism. This model generates a sequence\nrepresentation as a hyperedge while simultaneously learning the crucial\nsubsequences for each sequence. We conduct extensive experiments on four data\nsets to assess and compare our model with several state-of-the-art methods.\nExperimental results demonstrate that our proposed Seq-HyGAN model can\neffectively classify sequence data and significantly outperform the baselines.\nWe also conduct case studies to investigate the contribution of each module in\nSeq-HyGAN.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "link": "http://arxiv.org/pdf/2303.02393v2",
            "date": "2023-03-04 11:53:33+00:00"
        },
        {
            "title": "Evolutionary Computation in Action: Feature Selection for Deep Embedding Spaces of Gigapixel Pathology Images",
            "authors": [
                "Azam Asilian Bidgoli",
                "Shahryar Rahnamayan",
                "Taher Dehkharghanian",
                "Abtin Riasatian",
                "H. R. Tizhoosh"
            ],
            "abstract": "One of the main obstacles of adopting digital pathology is the challenge of\nefficient processing of hyperdimensional digitized biopsy samples, called whole\nslide images (WSIs). Exploiting deep learning and introducing compact WSI\nrepresentations are urgently needed to accelerate image analysis and facilitate\nthe visualization and interpretability of pathology results in a postpandemic\nworld. In this paper, we introduce a new evolutionary approach for WSI\nrepresentation based on large-scale multi-objective optimization (LSMOP) of\ndeep embeddings. We start with patch-based sampling to feed KimiaNet , a\nhistopathology-specialized deep network, and to extract a multitude of feature\nvectors. Coarse multi-objective feature selection uses the reduced search space\nstrategy guided by the classification accuracy and the number of features. In\nthe second stage, the frequent features histogram (FFH), a novel WSI\nrepresentation, is constructed by multiple runs of coarse LSMOP. Fine\nevolutionary feature selection is then applied to find a compact (short-length)\nfeature vector based on the FFH and contributes to a more robust deep-learning\napproach to digital pathology supported by the stochastic power of evolutionary\nalgorithms. We validate the proposed schemes using The Cancer Genome Atlas\n(TCGA) images in terms of WSI representation, classification accuracy, and\nfeature quality. Furthermore, a novel decision space for multicriteria decision\nmaking in the LSMOP field is introduced. Finally, a patch-level visualization\napproach is proposed to increase the interpretability of deep features. The\nproposed evolutionary algorithm finds a very compact feature vector to\nrepresent a WSI (almost 14,000 times smaller than the original feature vectors)\nwith 8% higher accuracy compared to the codes provided by the state-of-the-art\nmethods.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/2303.00943v2",
            "date": "2023-03-02 03:36:15+00:00"
        },
        {
            "title": "Single-Cell Multimodal Prediction via Transformers",
            "authors": [
                "Wenzhuo Tang",
                "Hongzhi Wen",
                "Renming Liu",
                "Jiayuan Ding",
                "Wei Jin",
                "Yuying Xie",
                "Hui Liu",
                "Jiliang Tang"
            ],
            "abstract": "The recent development of multimodal single-cell technology has made the\npossibility of acquiring multiple omics data from individual cells, thereby\nenabling a deeper understanding of cellular states and dynamics. Nevertheless,\nthe proliferation of multimodal single-cell data also introduces tremendous\nchallenges in modeling the complex interactions among different modalities. The\nrecently advanced methods focus on constructing static interaction graphs and\napplying graph neural networks (GNNs) to learn from multimodal data. However,\nsuch static graphs can be suboptimal as they do not take advantage of the\ndownstream task information; meanwhile GNNs also have some inherent limitations\nwhen deeply stacking GNN layers. To tackle these issues, in this work, we\ninvestigate how to leverage transformers for multimodal single-cell data in an\nend-to-end manner while exploiting downstream task information. In particular,\nwe propose a scMoFormer framework which can readily incorporate external domain\nknowledge and model the interactions within each modality and cross modalities.\nExtensive experiments demonstrate that scMoFormer achieves superior performance\non various benchmark datasets. Note that scMoFormer won a Kaggle silver medal\nwith the rank of $24\\ /\\ 1221$ (Top 2%) without ensemble in a NeurIPS 2022\ncompetition. Our implementation is publicly available at Github.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2303.00233v1",
            "date": "2023-03-01 05:03:23+00:00"
        },
        {
            "title": "Revolutionizing Genomics with Reinforcement Learning Techniques",
            "authors": [
                "Mohsen Karami",
                "Roohallah Alizadehsani",
                "Khadijeh",
                "Jahanian",
                "Ahmadreza Argha",
                "Iman Dehzangi",
                "Hamid Alinejad-Rokny"
            ],
            "abstract": "In recent years, Reinforcement Learning (RL) has emerged as a powerful tool\nfor solving a wide range of problems, including decision-making and genomics.\nThe exponential growth of raw genomic data over the past two decades has\nexceeded the capacity of manual analysis, leading to a growing interest in\nautomatic data analysis and processing. RL algorithms are capable of learning\nfrom experience with minimal human supervision, making them well-suited for\ngenomic data analysis and interpretation. One of the key benefits of using RL\nis the reduced cost associated with collecting labeled training data, which is\nrequired for supervised learning. While there have been numerous studies\nexamining the applications of Machine Learning (ML) in genomics, this survey\nfocuses exclusively on the use of RL in various genomics research fields,\nincluding gene regulatory networks (GRNs), genome assembly, and sequence\nalignment. We present a comprehensive technical overview of existing studies on\nthe application of RL in genomics, highlighting the strengths and limitations\nof these approaches. We then discuss potential research directions that are\nworthy of future exploration, including the development of more sophisticated\nreward functions as RL heavily depends on the accuracy of the reward function,\nthe integration of RL with other machine learning techniques, and the\napplication of RL to new and emerging areas in genomics research. Finally, we\npresent our findings and conclude by summarizing the current state of the field\nand the future outlook for RL in genomics.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2302.13268v1",
            "date": "2023-02-26 08:43:08+00:00"
        },
        {
            "title": "A Multimodal Graph Neural Network Framework for Cancer Molecular Subtype Classification",
            "authors": [
                "Bingjun Li",
                "Sheida Nabavi"
            ],
            "abstract": "The recent development of high-throughput sequencing creates a large\ncollection of multi-omics data, which enables researchers to better investigate\ncancer molecular profiles and cancer taxonomy based on molecular subtypes.\nIntegrating multi-omics data has been proven to be effective for building more\nprecise classification models. Current multi-omics integrative models mainly\nuse early fusion by concatenation or late fusion based on deep neural networks.\nDue to the nature of biological systems, graphs are a better representation of\nbio-medical data. Although few graph neural network (GNN) based multi-omics\nintegrative methods have been proposed, they suffer from three common\ndisadvantages. One is most of them use only one type of connection, either\ninter-omics or intra-omic connection; second, they only consider one kind of\nGNN layer, either graph convolution network (GCN) or graph attention network\n(GAT); and third, most of these methods lack testing on a more complex cancer\nclassification task. We propose a novel end-to-end multi-omics GNN framework\nfor accurate and robust cancer subtype classification. The proposed model\nutilizes multi-omics data in the form of heterogeneous multi-layer graphs that\ncombines both inter-omics and intra-omic connections from established\nbiological knowledge. The proposed model incorporates learned graph features\nand global genome features for accurate classification. We test the proposed\nmodel on TCGA Pan-cancer dataset and TCGA breast cancer dataset for molecular\nsubtype and cancer subtype classification, respectively. The proposed model\noutperforms four current state-of-the-art baseline models in multiple\nevaluation metrics. The comparative analysis of GAT-based models and GCN-based\nmodels reveals that GAT-based models are preferred for smaller graphs with less\ninformation and GCN-based models are preferred for larger graphs with extra\ninformation.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2302.12838v1",
            "date": "2023-02-24 15:36:28+00:00"
        },
        {
            "title": "Neural-based classification rule learning for sequential data",
            "authors": [
                "Marine Collery",
                "Philippe Bonnard",
                "Fran\u00e7ois Fages",
                "Remy Kusters"
            ],
            "abstract": "Discovering interpretable patterns for classification of sequential data is\nof key importance for a variety of fields, ranging from genomics to fraud\ndetection or more generally interpretable decision-making. In this paper, we\npropose a novel differentiable fully interpretable method to discover both\nlocal and global patterns (i.e. catching a relative or absolute temporal\ndependency) for rule-based binary classification. It consists of a\nconvolutional binary neural network with an interpretable neural filter and a\ntraining strategy based on dynamically-enforced sparsity. We demonstrate the\nvalidity and usefulness of the approach on synthetic datasets and on an\nopen-source peptides dataset. Key to this end-to-end differentiable method is\nthat the expressive patterns used in the rules are learned alongside the rules\nthemselves.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "link": "http://arxiv.org/pdf/2302.11286v1",
            "date": "2023-02-22 11:05:05+00:00"
        },
        {
            "title": "Time to Embrace Natural Language Processing (NLP)-based Digital Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep Learning Pipelines",
            "authors": [
                "Min Cen",
                "Xingyu Li",
                "Bangwei Guo",
                "Jitendra Jonnagaddala",
                "Hong Zhang",
                "Xu Steven Xu"
            ],
            "abstract": "NLP-based computer vision models, particularly vision transformers, have been\nshown to outperform CNN models in many imaging tasks. However, most digital\npathology artificial-intelligence models are based on CNN architectures,\nprobably owing to a lack of data regarding NLP models for pathology images. In\nthis study, we developed digital pathology pipelines to benchmark the five most\nrecently proposed NLP models (vision transformer (ViT), Swin Transformer,\nMobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18,\nResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal\ncancer (microsatellite instability, CpG island methylator phenotype, and BRAF\nmutation). Hematoxylin and eosin-stained whole-slide images from Molecular and\nCellular Oncology and The Cancer Genome Atlas were used as training and\nexternal validation datasets, respectively. Cross-study external validations\nrevealed that the NLP-based models significantly outperformed the CNN-based\nmodels in biomarker prediction tasks, improving the overall prediction and\nprecision up to approximately 10% and 26%, respectively. Notably, compared with\nexisting models in the current literature using large training datasets, our\nNLP models achieved state-of-the-art predictions for all three biomarkers using\na relatively small training dataset, suggesting that large training datasets\nare not a prerequisite for NLP models or transformers, and NLP may be more\nsuitable for clinical studies in which small training datasets are commonly\ncollected. The superior performance of Sequencer2D suggests that further\nresearch and innovation on both transformer and bidirectional long short-term\nmemory architectures are warranted in the field of digital pathology. NLP\nmodels can replace classic CNN architectures and become the new workhorse\nbackbone in the field of digital pathology.",
            "categories": [
                "cs.CL",
                "cs.CV",
                "cs.LG",
                "eess.IV",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2302.10406v1",
            "date": "2023-02-21 02:42:03+00:00"
        },
        {
            "title": "Interpretable Deep Learning Methods for Multiview Learning",
            "authors": [
                "Hengkang Wang",
                "Han Lu",
                "Ju Sun",
                "Sandra E Safo"
            ],
            "abstract": "Technological advances have enabled the generation of unique and\ncomplementary types of data or views (e.g. genomics, proteomics, metabolomics)\nand opened up a new era in multiview learning research with the potential to\nlead to new biomedical discoveries. We propose iDeepViewLearn (Interpretable\nDeep Learning Method for Multiview Learning) for learning nonlinear\nrelationships in data from multiple views while achieving feature selection.\niDeepViewLearn combines deep learning flexibility with the statistical benefits\nof data and knowledge-driven feature selection, giving interpretable results.\nDeep neural networks are used to learn view-independent low-dimensional\nembedding through an optimization problem that minimizes the difference between\nobserved and reconstructed data, while imposing a regularization penalty on the\nreconstructed data. The normalized Laplacian of a graph is used to model\nbilateral relationships between variables in each view, therefore, encouraging\nselection of related variables. iDeepViewLearn is tested on simulated and two\nreal-world data, including breast cancer-related gene expression and\nmethylation data. iDeepViewLearn had competitive classification results and\nidentified genes and CpG sites that differentiated between individuals who died\nfrom breast cancer and those who did not. The results of our real data\napplication and simulations with small to moderate sample sizes suggest that\niDeepViewLearn may be a useful method for small-sample-size problems compared\nto other deep learning methods for multiview learning.",
            "categories": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2302.07930v1",
            "date": "2023-02-15 20:11:25+00:00"
        },
        {
            "title": "Monge, Bregman and Occam: Interpretable Optimal Transport in High-Dimensions with Feature-Sparse Maps",
            "authors": [
                "Marco Cuturi",
                "Michal Klein",
                "Pierre Ablin"
            ],
            "abstract": "Optimal transport (OT) theory focuses, among all maps\n$T:\\mathbb{R}^d\\rightarrow \\mathbb{R}^d$ that can morph a probability measure\nonto another, on those that are the ``thriftiest'', i.e. such that the averaged\ncost $c(x, T(x))$ between $x$ and its image $T(x)$ be as small as possible.\nMany computational approaches have been proposed to estimate such Monge maps\nwhen $c$ is the $\\ell_2^2$ distance, e.g., using entropic maps [Pooladian'22],\nor neural networks [Makkuva'20, Korotin'20]. We propose a new model for\ntransport maps, built on a family of translation invariant costs $c(x,\ny):=h(x-y)$, where $h:=\\tfrac{1}{2}\\|\\cdot\\|_2^2+\\tau$ and $\\tau$ is a\nregularizer. We propose a generalization of the entropic map suitable for $h$,\nand highlight a surprising link tying it with the Bregman centroids of the\ndivergence $D_h$ generated by $h$, and the proximal operator of $\\tau$. We show\nthat choosing a sparsity-inducing norm for $\\tau$ results in maps that apply\nOccam's razor to transport, in the sense that the displacement vectors\n$\\Delta(x):= T(x)-x$ they induce are sparse, with a sparsity pattern that\nvaries depending on $x$. We showcase the ability of our method to estimate\nmeaningful OT maps for high-dimensional single-cell transcription data, in the\n$34000$-$d$ space of gene counts for cells, without using dimensionality\nreduction, thus retaining the ability to interpret all displacements at the\ngene level.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2302.04065v1",
            "date": "2023-02-08 14:02:34+00:00"
        },
        {
            "title": "DDeMON: Ontology-based function prediction by Deep Learning from Dynamic Multiplex Networks",
            "authors": [
                "Jan Kralj",
                "Bla\u017e \u0160krlj",
                "\u017diva Ram\u0161ak",
                "Nada Lavra\u010d",
                "Kristina Gruden"
            ],
            "abstract": "Biological systems can be studied at multiple levels of information,\nincluding gene, protein, RNA and different interaction networks levels. The\ngoal of this work is to explore how the fusion of systems' level information\nwith temporal dynamics of gene expression can be used in combination with\nnon-linear approximation power of deep neural networks to predict novel gene\nfunctions in a non-model organism potato \\emph{Solanum tuberosum}. We propose\nDDeMON (Dynamic Deep learning from temporal Multiplex Ontology-annotated\nNetworks), an approach for scalable, systems-level inference of function\nannotation using time-dependent multiscale biological information. The proposed\nmethod, which is capable of considering billions of potential links between the\ngenes of interest, was applied on experimental gene expression data and the\nbackground knowledge network to reliably classify genes with unknown function\ninto five different functional ontology categories, linked to the experimental\ndata set. Predicted novel functions of genes were validated using extensive\nprotein domain search approach.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2302.03907v1",
            "date": "2023-02-08 06:53:02+00:00"
        },
        {
            "title": "Unsupervised hierarchical clustering using the learning dynamics of RBMs",
            "authors": [
                "Aur\u00e9lien Decelle",
                "Lorenzo Rosset",
                "Beatriz Seoane"
            ],
            "abstract": "Datasets in the real world are often complex and to some degree hierarchical,\nwith groups and sub-groups of data sharing common characteristics at different\nlevels of abstraction. Understanding and uncovering the hidden structure of\nthese datasets is an important task that has many practical applications. To\naddress this challenge, we present a new and general method for building\nrelational data trees by exploiting the learning dynamics of the Restricted\nBoltzmann Machine (RBM). Our method is based on the mean-field approach,\nderived from the Plefka expansion, and developed in the context of disordered\nsystems. It is designed to be easily interpretable. We tested our method in an\nartificially created hierarchical dataset and on three different real-world\ndatasets (images of digits, mutations in the human genome, and a homologous\nfamily of proteins). The method is able to automatically identify the\nhierarchical structure of the data. This could be useful in the study of\nhomologous protein sequences, where the relationships between proteins are\ncritical for understanding their function and evolution.",
            "categories": [
                "cs.LG",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ],
            "link": "http://arxiv.org/pdf/2302.01851v2",
            "date": "2023-02-03 16:53:32+00:00"
        },
        {
            "title": "ImageNomer: developing an fMRI and omics visualization tool to detect racial bias in functional connectivity",
            "authors": [
                "Anton Orlichenko",
                "Grant Daly",
                "Anqi Liu",
                "Hui Shen",
                "Hong-Wen Deng",
                "Yu-Ping Wang"
            ],
            "abstract": "It can be difficult to identify trends and perform quality control in large,\nhigh-dimensional fMRI or omics datasets. To remedy this, we develop ImageNomer,\na data visualization and analysis tool that allows inspection of both\nsubject-level and cohort-level features. The tool allows visualization of\nphenotype correlation with functional connectivity (FC), partial connectivity\n(PC), dictionary components (PCA and our own method), and genomic data\n(single-nucleotide polymorphisms, SNPs). In addition, it allows visualization\nof weights from arbitrary ML models. ImageNomer is built with a Python backend\nand a Vue frontend. We validate ImageNomer using the Philadelphia\nNeurodevelopmental Cohort (PNC) dataset, which contains multitask fMRI and SNP\ndata of healthy adolescents. Using correlation, greedy selection, or model\nweights, we find that a set of 10 FC features can explain 15% of variation in\nage, compared to 35% for the full 34,716 feature model. The four most\nsignificant FCs are either between bilateral default mode network (DMN) regions\nor spatially proximal subcortical areas. Additionally, we show that whereas\nboth FC (fMRI) and SNPs (genomic) features can account for 10-15% of\nintelligence variation, this predictive ability disappears when controlling for\nrace. We find that FC features can be used to predict race with 85% accuracy,\ncompared to 78% accuracy for sex prediction. Using ImageNomer, this work casts\ndoubt on the possibility of finding unbiased intelligence-related features in\nfMRI and SNPs of healthy adolescents.",
            "categories": [
                "q-bio.PE",
                "cs.LG",
                "q-bio.NC"
            ],
            "link": "http://arxiv.org/pdf/2302.00767v1",
            "date": "2023-02-01 21:32:24+00:00"
        },
        {
            "title": "Graph Neural Operators for Classification of Spatial Transcriptomics Data",
            "authors": [
                "Junaid Ahmed",
                "Alhassan S. Yasin"
            ],
            "abstract": "The inception of spatial transcriptomics has allowed improved comprehension\nof tissue architectures and the disentanglement of complex underlying\nbiological, physiological, and pathological processes through their positional\ncontexts. Recently, these contexts, and by extension the field, have seen much\npromise and elucidation with the application of graph learning approaches. In\nparticular, neural operators have risen in regards to learning the mapping\nbetween infinite-dimensional function spaces. With basic to deep neural network\narchitectures being data-driven, i.e. dependent on quality data for prediction,\nneural operators provide robustness by offering generalization among different\nresolutions despite low quality data. Graph neural operators are a variant that\nutilize graph networks to learn this mapping between function spaces. The aim\nof this research is to identify robust machine learning architectures that\nintegrate spatial information to predict tissue types. Under this notion, we\npropose a study incorporating various graph neural network approaches to\nvalidate the efficacy of applying neural operators towards prediction of brain\nregions in mouse brain tissue samples as a proof of concept towards our\npurpose. We were able to achieve an F1 score of nearly 72% for the graph neural\noperator approach which outperformed all baseline and other graph network\napproaches.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2302.00658v1",
            "date": "2023-02-01 18:32:06+00:00"
        },
        {
            "title": "Partitioning Distributed Compute Jobs with Reinforcement Learning and Graph Neural Networks",
            "authors": [
                "Christopher W. F. Parsonson",
                "Zacharaya Shabka",
                "Alessandro Ottino",
                "Georgios Zervas"
            ],
            "abstract": "From natural language processing to genome sequencing, large-scale machine\nlearning models are bringing advances to a broad range of fields. Many of these\nmodels are too large to be trained on a single machine, and instead must be\ndistributed across multiple devices. This has motivated the research of new\ncompute and network systems capable of handling such tasks. In particular,\nrecent work has focused on developing management schemes which decide how to\nallocate distributed resources such that some overall objective, such as\nminimising the job completion time (JCT), is optimised. However, such studies\nomit explicit consideration of how much a job should be distributed, usually\nassuming that maximum distribution is desirable. In this work, we show that\nmaximum parallelisation is sub-optimal in relation to user-critical metrics\nsuch as throughput and blocking rate. To address this, we propose PAC-ML\n(partitioning for asynchronous computing with machine learning). PAC-ML\nleverages a graph neural network and reinforcement learning to learn how much\nto partition computation graphs such that the number of jobs which meet\narbitrary user-defined JCT requirements is maximised. In experiments with five\nreal deep learning computation graphs on a recently proposed optical\narchitecture across four user-defined JCT requirement distributions, we\ndemonstrate PAC-ML achieving up to 56.2% lower blocking rates in dynamic job\narrival settings than the canonical maximum parallelisation strategy used by\nmost prior works.",
            "categories": [
                "cs.LG",
                "cs.DC"
            ],
            "link": "http://arxiv.org/pdf/2301.13799v1",
            "date": "2023-01-31 17:41:07+00:00"
        },
        {
            "title": "Recurrences reveal shared causal drivers of complex time series",
            "authors": [
                "William Gilpin"
            ],
            "abstract": "Many experimental time series measurements share an unobserved causal driver.\nExamples include genes targeted by transcription factors, ocean flows\ninfluenced by large-scale atmospheric currents, and motor circuits steered by\ndescending neurons. Reliably inferring this unseen driving force is necessary\nto understand the intermittent nature of top-down control schemes in diverse\nbiological and engineered systems. Here, we introduce a new unsupervised\nlearning algorithm that uses recurrences in time series measurements to\ngradually reconstruct an unobserved driving signal. Drawing on the mathematical\ntheory of skew-product dynamical systems, we identify recurrence events shared\nacross response time series, which implicitly define a recurrence graph with\nglass-like structure. As the amount or quality of observed data improves, this\nrecurrence graph undergoes a percolation transition manifesting as weak\nergodicity breaking for random walks on the induced landscape -- revealing the\nshared driver's dynamics, even in the presence of strongly corrupted or noisy\nmeasurements. Across several thousand random dynamical systems, we empirically\nquantify the dependence of reconstruction accuracy on the rate of information\ntransfer from a chaotic driver to the response systems, and we find that\neffective reconstruction proceeds through gradual approximation of the driver's\ndominant unstable periodic orbits. Through extensive benchmarks against\nclassical and neural-network-based signal processing techniques, we demonstrate\nour method's strong ability to extract causal driving signals from diverse\nreal-world datasets spanning neuroscience, genomics, fluid dynamics, and\nphysiology.",
            "categories": [
                "cs.LG",
                "eess.SP",
                "nlin.CD"
            ],
            "link": "http://arxiv.org/pdf/2301.13516v1",
            "date": "2023-01-31 10:07:23+00:00"
        },
        {
            "title": "Gene Teams are on the Field: Evaluation of Variants in Gene-Networks Using High Dimensional Modelling",
            "authors": [
                "Suha Tuna",
                "Cagri Gulec",
                "Emrah Yucesan",
                "Ayse Cirakoglu",
                "Yelda Tarkan Arguden"
            ],
            "abstract": "In medical genetics, each genetic variant is evaluated as an independent\nentity regarding its clinical importance. However, in most complex diseases,\nvariant combinations in specific gene networks, rather than the presence of a\nparticular single variant, predominates. In the case of complex diseases,\ndisease status can be evaluated by considering the success level of a team of\nspecific variants. We propose a high dimensional modelling based method to\nanalyse all the variants in a gene network together. To evaluate our method, we\nselected two gene networks, mTOR and TGF-Beta. For each pathway, we generated\n400 control and 400 patient group samples. mTOR and TGF-? pathways contain 31\nand 93 genes of varying sizes, respectively. We produced Chaos Game\nRepresentation images for each gene sequence to obtain 2-D binary patterns.\nThese patterns were arranged in succession, and a 3-D tensor structure was\nachieved for each gene network. Features for each data sample were acquired by\nexploiting Enhanced Multivariance Products Representation to 3-D data. Features\nwere split as training and testing vectors. Training vectors were employed to\ntrain a Support Vector Machines classification model. We achieved more than 96%\nand 99% classification accuracies for mTOR and TGF-Beta networks, respectively,\nusing a limited amount of training samples.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2301.11763v1",
            "date": "2023-01-27 15:02:23+00:00"
        },
        {
            "title": "Explainable Multilayer Graph Neural Network for Cancer Gene Prediction",
            "authors": [
                "Michail Chatzianastasis",
                "Michalis Vazirgiannis",
                "Zijun Zhang"
            ],
            "abstract": "The identification of cancer genes is a critical, yet challenging problem in\ncancer genomics research. Recently, several computational methods have been\ndeveloped to address this issue, including deep neural networks. However, these\nmethods fail to exploit the multilayered gene-gene interactions and provide\nlittle to no explanation for their predictions. Results: In this study, we\npropose an Explainable Multilayer Graph Neural Network (EMGNN) approach to\nidentify cancer genes, by leveraging multiple gene-gene interaction networks\nand multi-omics data. Compared to conventional graph learning methods, EMGNN\nlearned complementary information in multiple graphs to accurately predict\ncancer genes. Our method consistently outperforms existing approaches while\nproviding valuable biological insights into its predictions. We further release\nour novel cancer gene predictions and connect them with known cancer patterns,\naiming to accelerate the progress of cancer research",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2301.08831v1",
            "date": "2023-01-20 23:57:12+00:00"
        },
        {
            "title": "Deep Biological Pathway Informed Pathology-Genomic Multimodal Survival Prediction",
            "authors": [
                "Lin Qiu",
                "Aminollah Khormali",
                "Kai Liu"
            ],
            "abstract": "The integration of multi-modal data, such as pathological images and genomic\ndata, is essential for understanding cancer heterogeneity and complexity for\npersonalized treatments, as well as for enhancing survival predictions. Despite\nthe progress made in integrating pathology and genomic data, most existing\nmethods cannot mine the complex inter-modality relations thoroughly.\nAdditionally, identifying explainable features from these models that govern\npreclinical discovery and clinical prediction is crucial for cancer diagnosis,\nprognosis, and therapeutic response studies. We propose PONET- a novel\nbiological pathway-informed pathology-genomic deep model that integrates\npathological images and genomic data not only to improve survival prediction\nbut also to identify genes and pathways that cause different survival rates in\npatients. Empirical results on six of The Cancer Genome Atlas (TCGA) datasets\nshow that our proposed method achieves superior predictive performance and\nreveals meaningful biological interpretations. The proposed method establishes\ninsight into how to train biologically informed deep networks on multimodal\nbiomedical data which will have general applicability for understanding\ndiseases and predicting response and resistance to treatment.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "eess.IV",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2301.02383v1",
            "date": "2023-01-06 05:24:41+00:00"
        },
        {
            "title": "Chains of Autoreplicative Random Forests for missing value imputation in high-dimensional datasets",
            "authors": [
                "Ekaterina Antonenko",
                "Jesse Read"
            ],
            "abstract": "Missing values are a common problem in data science and machine learning.\nRemoving instances with missing values can adversely affect the quality of\nfurther data analysis. This is exacerbated when there are relatively many more\nfeatures than instances, and thus the proportion of affected instances is high.\nSuch a scenario is common in many important domains, for example, single\nnucleotide polymorphism (SNP) datasets provide a large number of features over\na genome for a relatively small number of individuals. To preserve as much\ninformation as possible prior to modeling, a rigorous imputation scheme is\nacutely needed. While Denoising Autoencoders is a state-of-the-art method for\nimputation in high-dimensional data, they still require enough complete cases\nto be trained on which is often not available in real-world problems. In this\npaper, we consider missing value imputation as a multi-label classification\nproblem and propose Chains of Autoreplicative Random Forests. Using multi-label\nRandom Forests instead of neural networks works well for low-sampled data as\nthere are fewer parameters to optimize. Experiments on several SNP datasets\nshow that our algorithm effectively imputes missing values based only on\ninformation from the dataset and exhibits better performance than standard\nalgorithms that do not require any additional information. In this paper, the\nalgorithm is implemented specifically for SNP data, but it can easily be\nadapted for other cases of missing value imputation.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2301.00595v1",
            "date": "2023-01-02 10:53:52+00:00"
        },
        {
            "title": "Explainable AI for Bioinformatics: Methods, Tools, and Applications",
            "authors": [
                "Md. Rezaul Karim",
                "Tanhim Islam",
                "Oya Beyan",
                "Christoph Lange",
                "Michael Cochez",
                "Dietrich Rebholz-Schuhmann",
                "Stefan Decker"
            ],
            "abstract": "Artificial intelligence (AI) systems utilizing deep neural networks (DNNs)\nand machine learning (ML) algorithms are widely used for solving important\nproblems in bioinformatics, biomedical informatics, and precision medicine.\nHowever, complex DNNs or ML models, which are often perceived as opaque and\nblack-box, can make it difficult to understand the reasoning behind their\ndecisions. This lack of transparency can be a challenge for both end-users and\ndecision-makers, as well as AI developers. Additionally, in sensitive areas\nlike healthcare, explainability and accountability are not only desirable but\nalso legally required for AI systems that can have a significant impact on\nhuman lives. Fairness is another growing concern, as algorithmic decisions\nshould not show bias or discrimination towards certain groups or individuals\nbased on sensitive attributes. Explainable artificial intelligence (XAI) aims\nto overcome the opaqueness of black-box models and provide transparency in how\nAI systems make decisions. Interpretable ML models can explain how they make\npredictions and the factors that influence their outcomes. However, most\nstate-of-the-art interpretable ML methods are domain-agnostic and evolved from\nfields like computer vision, automated reasoning, or statistics, making direct\napplication to bioinformatics problems challenging without customization and\ndomain-specific adaptation. In this paper, we discuss the importance of\nexplainability in the context of bioinformatics, provide an overview of\nmodel-specific and model-agnostic interpretable ML methods and tools, and\noutline their potential caveats and drawbacks. Besides, we discuss how to\ncustomize existing interpretable ML methods for bioinformatics problems.\nNevertheless, we demonstrate how XAI methods can improve transparency through\ncase studies in bioimaging, cancer genomics, and text mining.",
            "categories": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2212.13261v3",
            "date": "2022-12-25 21:00:36+00:00"
        },
        {
            "title": "Neural Networks beyond explainability: Selective inference for sequence motifs",
            "authors": [
                "Antoine Villi\u00e9",
                "Philippe Veber",
                "Yohann de Castro",
                "Laurent Jacob"
            ],
            "abstract": "Over the past decade, neural networks have been successful at making\npredictions from biological sequences, especially in the context of regulatory\ngenomics. As in other fields of deep learning, tools have been devised to\nextract features such as sequence motifs that can explain the predictions made\nby a trained network. Here we intend to go beyond explainable machine learning\nand introduce SEISM, a selective inference procedure to test the association\nbetween these extracted features and the predicted phenotype. In particular, we\ndiscuss how training a one-layer convolutional network is formally equivalent\nto selecting motifs maximizing some association score. We adapt existing\nsampling-based selective inference procedures by quantizing this selection over\nan infinite set to a large but finite grid. Finally, we show that sampling\nunder a specific choice of parameters is sufficient to characterize the\ncomposite null hypothesis typically used for selective inference-a result that\ngoes well beyond our particular framework. We illustrate the behavior of our\nmethod in terms of calibration, power and speed and discuss its power/speed\ntrade-off with a simpler data-split strategy. SEISM paves the way to an easier\nanalysis of neural networks used in regulatory genomics, and to more powerful\nmethods for genome wide association studies (GWAS).",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2212.12542v1",
            "date": "2022-12-23 10:49:07+00:00"
        },
        {
            "title": "HeartBEiT: Vision Transformer for Electrocardiogram Data Improves Diagnostic Performance at Low Sample Sizes",
            "authors": [
                "Akhil Vaid",
                "Joy Jiang",
                "Ashwin Sawant",
                "Stamatios Lerakis",
                "Edgar Argulian",
                "Yuri Ahuja",
                "Joshua Lampert",
                "Alexander Charney",
                "Hayit Greenspan",
                "Benjamin Glicksberg",
                "Jagat Narula",
                "Girish Nadkarni"
            ],
            "abstract": "The electrocardiogram (ECG) is a ubiquitous diagnostic modality.\nConvolutional neural networks (CNNs) applied towards ECG analysis require large\nsample sizes, and transfer learning approaches result in suboptimal performance\nwhen pre-training is done on natural images. We leveraged masked image modeling\nto create the first vision-based transformer model, HeartBEiT, for\nelectrocardiogram waveform analysis. We pre-trained this model on 8.5 million\nECGs and then compared performance vs. standard CNN architectures for diagnosis\nof hypertrophic cardiomyopathy, low left ventricular ejection fraction and ST\nelevation myocardial infarction using differing training sample sizes and\nindependent validation datasets. We show that HeartBEiT has significantly\nhigher performance at lower sample sizes compared to other models. Finally, we\nalso show that HeartBEiT improves explainability of diagnosis by highlighting\nbiologically relevant regions of the EKG vs. standard CNNs. Thus, we present\nthe first vision-based waveform transformer that can be used to develop\nspecialized models for ECG analysis especially at low sample sizes.",
            "categories": [
                "eess.SP",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2212.14040v1",
            "date": "2022-12-13 16:39:21+00:00"
        },
        {
            "title": "Deep Neural Networks integrating genomics and histopathological images for predicting stages and survival time-to-event in colon cancer",
            "authors": [
                "Olalekan Ogundipe",
                "Zeyneb Kurt",
                "Wai Lok Woo"
            ],
            "abstract": "There exists unexplained diverse variation within the predefined colon cancer\nstages using only features either from genomics or histopathological whole\nslide images as prognostic factors. Unraveling this variation will bring about\nimproved in staging and treatment outcome, hence motivated by the advancement\nof Deep Neural Network libraries and different structures and factors within\nsome genomic dataset, we aggregate atypical patterns in histopathological\nimages with diverse carcinogenic expression from mRNA, miRNA and DNA\nMethylation as an integrative input source into an ensemble deep neural network\nfor colon cancer stages classification and samples stratification into low or\nhigh risk survival groups. The results of our Ensemble Deep Convolutional\nNeural Network model show an improved performance in stages classification on\nthe integrated dataset. The fused input features return Area under curve\nReceiver Operating Characteristic curve (AUC ROC) of 0.95 compared with AUC ROC\nof 0.71 and 0.68 obtained when only genomics and images features are used for\nthe stage's classification, respectively. Also, the extracted features were\nused to split the patients into low or high risk survival groups. Among the\n2548 fused features, 1695 features showed a statistically significant survival\nprobability differences between the two risk groups defined by the extracted\nfeatures.",
            "categories": [
                "q-bio.QM",
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/2212.06834v1",
            "date": "2022-12-13 16:12:45+00:00"
        },
        {
            "title": "Utilizing Mutations to Evaluate Interpretability of Neural Networks on Genomic Data",
            "authors": [
                "Utku Ozbulak",
                "Solha Kang",
                "Jasper Zuallaert",
                "Stephen Depuydt",
                "Joris Vankerschaver"
            ],
            "abstract": "Even though deep neural networks (DNNs) achieve state-of-the-art results for\na number of problems involving genomic data, getting DNNs to explain their\ndecision-making process has been a major challenge due to their black-box\nnature. One way to get DNNs to explain their reasoning for prediction is via\nattribution methods which are assumed to highlight the parts of the input that\ncontribute to the prediction the most. Given the existence of numerous\nattribution methods and a lack of quantitative results on the fidelity of those\nmethods, selection of an attribution method for sequence-based tasks has been\nmostly done qualitatively. In this work, we take a step towards identifying the\nmost faithful attribution method by proposing a computational approach that\nutilizes point mutations. Providing quantitative results on seven popular\nattribution methods, we find Layerwise Relevance Propagation (LRP) to be the\nmost appropriate one for translation initiation, with LRP identifying two\nimportant biological features for translation: the integrity of Kozak sequence\nas well as the detrimental effects of premature stop codons.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2212.06151v1",
            "date": "2022-12-12 07:12:56+00:00"
        },
        {
            "title": "TargetCall: Eliminating the Wasted Computation in Basecalling via Pre-Basecalling Filtering",
            "authors": [
                "Meryem Banu Cavlak",
                "Gagandeep Singh",
                "Mohammed Alser",
                "Can Firtina",
                "Jo\u00ebl Lindegger",
                "Mohammad Sadrosadati",
                "Nika Mansouri Ghiasi",
                "Can Alkan",
                "Onur Mutlu"
            ],
            "abstract": "Basecalling is an essential step in nanopore sequencing analysis where the\nraw signals of nanopore sequencers are converted into nucleotide sequences,\ni.e., reads. State-of-the-art basecallers employ complex deep learning models\nto achieve high basecalling accuracy. This makes basecalling\ncomputationally-inefficient and memory-hungry; bottlenecking the entire genome\nanalysis pipeline. However, for many applications, the majority of reads do no\nmatch the reference genome of interest (i.e., target reference) and thus are\ndiscarded in later steps in the genomics pipeline, wasting the basecalling\ncomputation. To overcome this issue, we propose TargetCall, the first fast and\nwidely-applicable pre-basecalling filter to eliminate the wasted computation in\nbasecalling. TargetCall's key idea is to discard reads that will not match the\ntarget reference (i.e., off-target reads) prior to basecalling. TargetCall\nconsists of two main components: (1) LightCall, a lightweight neural network\nbasecaller that produces noisy reads; and (2) Similarity Check, which labels\neach of these noisy reads as on-target or off-target by matching them to the\ntarget reference. TargetCall filters out all off-target reads before\nbasecalling; and the highly-accurate but slow basecalling is performed only on\nthe raw signals whose noisy reads are labeled as on-target. Our thorough\nexperimental evaluations using both real and simulated data show that\nTargetCall 1) improves the end-to-end basecalling performance of the\nstate-of-the-art basecaller by 3.31x while maintaining high (98.88%)\nsensitivity in keeping on-target reads, 2) maintains high accuracy in\ndownstream analysis, 3) precisely filters out up to 94.71% of off-target reads,\nand 4) achieves better performance, sensitivity, and generality compared to\nprior works. We freely open-source TargetCall at\nhttps://github.com/CMU-SAFARI/TargetCall.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2212.04953v1",
            "date": "2022-12-09 16:03:34+00:00"
        },
        {
            "title": "Bringing the Algorithms to the Data -- Secure Distributed Medical Analytics using the Personal Health Train (PHT-meDIC)",
            "authors": [
                "Marius de Arruda Botelho Herr",
                "Michael Graf",
                "Peter Placzek",
                "Florian K\u00f6nig",
                "Felix B\u00f6tte",
                "Tyra Stickel",
                "David Hieber",
                "Lukas Zimmermann",
                "Michael Slupina",
                "Christopher Mohr",
                "Stephanie Biergans",
                "Mete Akg\u00fcn",
                "Nico Pfeifer",
                "Oliver Kohlbacher"
            ],
            "abstract": "The need for data privacy and security -- enforced through increasingly\nstrict data protection regulations -- renders the use of healthcare data for\nmachine learning difficult. In particular, the transfer of data between\ndifferent hospitals is often not permissible and thus cross-site pooling of\ndata not an option. The Personal Health Train (PHT) paradigm proposed within\nthe GO-FAIR initiative implements an 'algorithm to the data' paradigm that\nensures that distributed data can be accessed for analysis without transferring\nany sensitive data. We present PHT-meDIC, a productively deployed open-source\nimplementation of the PHT concept. Containerization allows us to easily deploy\neven complex data analysis pipelines (e.g, genomics, image analysis) across\nmultiple sites in a secure and scalable manner. We discuss the underlying\ntechnological concepts, security models, and governance processes. The\nimplementation has been successfully applied to distributed analyses of\nlarge-scale data, including applications of deep neural networks to medical\nimage data.",
            "categories": [
                "cs.LG",
                "cs.CR",
                "cs.CY",
                "cs.DC"
            ],
            "link": "http://arxiv.org/pdf/2212.03481v1",
            "date": "2022-12-07 06:29:15+00:00"
        },
        {
            "title": "Giga-SSL: Self-Supervised Learning for Gigapixel Images",
            "authors": [
                "Tristan Lazard",
                "Marvin Lerousseau",
                "Etienne Decenci\u00e8re",
                "Thomas Walter"
            ],
            "abstract": "Whole slide images (WSI) are microscopy images of stained tissue slides\nroutinely prepared for diagnosis and treatment selection in medical practice.\nWSI are very large (gigapixel size) and complex (made of up to millions of\ncells). The current state-of-the-art (SoTA) approach to classify WSI subdivides\nthem into tiles, encodes them by pre-trained networks and applies Multiple\nInstance Learning (MIL) to train for specific downstream tasks. However,\nannotated datasets are often small, typically a few hundred to a few thousand\nWSI, which may cause overfitting and underperforming models. Conversely, the\nnumber of unannotated WSI is ever increasing, with datasets of tens of\nthousands (soon to be millions) of images available. While it has been\npreviously proposed to use these unannotated data to identify suitable tile\nrepresentations by self-supervised learning (SSL), downstream classification\ntasks still require full supervision because parts of the MIL architecture is\nnot trained during tile level SSL pre-training. Here, we propose a strategy of\nslide level SSL to leverage the large number of WSI without annotations to\ninfer powerful slide representations. Applying our method to The Cancer-Genome\nAtlas, one of the most widely used data resources in cancer research (16 TB\nimage data), we are able to downsize the dataset to 23 MB without any loss in\npredictive power: we show that a linear classifier trained on top of these\nembeddings maintains or improves previous SoTA performances on various\nbenchmark WSI classification tasks. Finally, we observe that training a\nclassifier on these representations with tiny datasets (e.g. 50 slides)\nimproved performances over SoTA by an average of +6.3 AUC points over all\ndownstream tasks.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2212.03273v1",
            "date": "2022-12-06 19:09:19+00:00"
        },
        {
            "title": "Scalable Pathogen Detection from Next Generation DNA Sequencing with Deep Learning",
            "authors": [
                "Sai Narayanan",
                "Sathyanarayanan N. Aakur",
                "Priyadharsini Ramamurthy",
                "Arunkumar Bagavathi",
                "Vishalini Ramnath",
                "Akhilesh Ramachandran"
            ],
            "abstract": "Next-generation sequencing technologies have enhanced the scope of\nInternet-of-Things (IoT) to include genomics for personalized medicine through\nthe increased availability of an abundance of genome data collected from\nheterogeneous sources at a reduced cost. Given the sheer magnitude of the\ncollected data and the significant challenges offered by the presence of highly\nsimilar genomic structure across species, there is a need for robust, scalable\nanalysis platforms to extract actionable knowledge such as the presence of\npotentially zoonotic pathogens. The emergence of zoonotic diseases from novel\npathogens, such as the influenza virus in 1918 and SARS-CoV-2 in 2019 that can\njump species barriers and lead to pandemic underscores the need for scalable\nmetagenome analysis. In this work, we propose MG2Vec, a deep learning-based\nsolution that uses the transformer network as its backbone, to learn robust\nfeatures from raw metagenome sequences for downstream biomedical tasks such as\ntargeted and generalized pathogen detection. Extensive experiments on four\nincreasingly challenging, yet realistic diagnostic settings, show that the\nproposed approach can help detect pathogens from uncurated, real-world clinical\nsamples with minimal human supervision in the form of labels. Further, we\ndemonstrate that the learned representations can generalize to completely\nunrelated pathogens across diseases and species for large-scale metagenome\nanalysis. We provide a comprehensive evaluation of a novel representation\nlearning framework for metagenome-based disease diagnostics with deep learning\nand provide a way forward for extracting and using robust vector\nrepresentations from low-cost next generation sequencing to develop\ngeneralizable diagnostic tools.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2212.00015v1",
            "date": "2022-11-30 00:13:59+00:00"
        },
        {
            "title": "Graph Neural Networks for Breast Cancer Data Integration",
            "authors": [
                "Teodora Reu"
            ],
            "abstract": "International initiatives such as METABRIC (Molecular Taxonomy of Breast\nCancer International Consortium) have collected several multigenomic and\nclinical data sets to identify the undergoing molecular processes taking place\nthroughout the evolution of various cancers. Numerous Machine Learning and\nstatistical models have been designed and trained to analyze these types of\ndata independently, however, the integration of such differently shaped and\nsourced information streams has not been extensively studied. To better\nintegrate these data sets and generate meaningful representations that can\nultimately be leveraged for cancer detection tasks could lead to giving\nwell-suited treatments to patients. Hence, we propose a novel learning pipeline\ncomprising three steps - the integration of cancer data modalities as graphs,\nfollowed by the application of Graph Neural Networks in an unsupervised setting\nto generate lower-dimensional embeddings from the combined data, and finally\nfeeding the new representations on a cancer sub-type classification model for\nevaluation. The graph construction algorithms are described in-depth as\nMETABRIC does not store relationships between the patient modalities, with a\ndiscussion of their influence over the quality of the generated embeddings. We\nalso present the models used to generate the lower-latent space\nrepresentations: Graph Neural Networks, Variational Graph Autoencoders and Deep\nGraph Infomax. In parallel, the pipeline is tested on a synthetic dataset to\ndemonstrate that the characteristics of the underlying data, such as homophily\nlevels, greatly influence the performance of the pipeline, which ranges between\n51\\% to 98\\% accuracy on artificial data, and 13\\% and 80\\% on METABRIC. This\nproject has the potential to improve cancer data understanding and encourages\nthe transition of regular data sets to graph-shaped data.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2211.15561v1",
            "date": "2022-11-28 17:10:19+00:00"
        },
        {
            "title": "PINNet: a deep neural network with pathway prior knowledge for Alzheimer's disease",
            "authors": [
                "Yeojin Kim",
                "Hyunju Lee"
            ],
            "abstract": "Identification of Alzheimer's Disease (AD)-related transcriptomic signatures\nfrom blood is important for early diagnosis of the disease. Deep learning\ntechniques are potent classifiers for AD diagnosis, but most have been unable\nto identify biomarkers because of their lack of interpretability. To address\nthese challenges, we propose a pathway information-based neural network\n(PINNet) to predict AD patients and analyze blood and brain transcriptomic\nsignatures using an interpretable deep learning model. PINNet is a deep neural\nnetwork (DNN) model with pathway prior knowledge from either the Gene Ontology\nor Kyoto Encyclopedia of Genes and Genomes databases. Then, a\nbackpropagation-based model interpretation method was applied to reveal\nessential pathways and genes for predicting AD. We compared the performance of\nPINNet with a DNN model without a pathway. Performances of PINNet outperformed\nor were similar to those of DNN without a pathway using blood and brain gene\nexpressions, respectively. Moreover, PINNet considers more AD-related genes as\nessential features than DNN without a pathway in the learning process. Pathway\nanalysis of protein-protein interaction modules of highly contributed genes\nshowed that AD-related genes in blood were enriched with cell migration,\nPI3K-Akt, MAPK signaling, and apoptosis in blood. The pathways enriched in the\nbrain module included cell migration, PI3K-Akt, MAPK signaling, apoptosis,\nprotein ubiquitination, and t-cell activation. Collectively, with prior\nknowledge about pathways, PINNet reveals essential pathways related to AD.",
            "categories": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2211.15669v1",
            "date": "2022-11-27 05:00:26+00:00"
        },
        {
            "title": "Graph-Conditioned MLP for High-Dimensional Tabular Biomedical Data",
            "authors": [
                "Andrei Margeloiu",
                "Nikola Simidjievski",
                "Pietro Lio'",
                "Mateja Jamnik"
            ],
            "abstract": "Genome-wide studies leveraging recent high-throughput sequencing technologies\ncollect high-dimensional data. However, they usually include small cohorts of\npatients, and the resulting tabular datasets suffer from the \"curse of\ndimensionality\". Training neural networks on such datasets is typically\nunstable, and the models overfit. One problem is that modern weight\ninitialisation strategies make simplistic assumptions unsuitable for small-size\ndatasets. We propose Graph-Conditioned MLP, a novel method to introduce priors\non the parameters of an MLP. Instead of randomly initialising the first layer,\nwe condition it directly on the training data. More specifically, we create a\ngraph for each feature in the dataset (e.g., a gene), where each node\nrepresents a sample from the same dataset (e.g., a patient). We then use Graph\nNeural Networks (GNNs) to learn embeddings from these graphs and use the\nembeddings to initialise the MLP's parameters. Our approach opens the prospect\nof introducing additional biological knowledge when constructing the graphs. We\npresent early results on 7 classification tasks from gene expression data and\nshow that GC-MLP outperforms an MLP.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2211.06302v1",
            "date": "2022-11-11 16:13:34+00:00"
        },
        {
            "title": "DeepG2P: Fusing Multi-Modal Data to Improve Crop Production",
            "authors": [
                "Swati Sharma",
                "Aditi Partap",
                "Maria Angels de Luis Balaguer",
                "Sara Malvar",
                "Ranveer Chandra"
            ],
            "abstract": "Agriculture is at the heart of the solution to achieve sustainability in\nfeeding the world population, but advancing our understanding on how\nagricultural output responds to climatic variability is still needed. Precision\nAgriculture (PA), which is a management strategy that uses technology such as\nremote sensing, Geographical Information System (GIS), and machine learning for\ndecision making in the field, has emerged as a promising approach to enhance\ncrop production, increase yield, and reduce water and nutrient losses and\nenvironmental impacts. In this context, multiple models to predict agricultural\nphenotypes, such as crop yield, from genomics (G), environment (E), weather and\nsoil, and field management practices (M) have been developed. These models have\ntraditionally been based on mechanistic or statistical approaches. However, AI\napproaches are intrinsically well-suited to model complex interactions and have\nmore recently been developed, outperforming classical methods. Here, we present\na Natural Language Processing (NLP)-based neural network architecture to\nprocess the G, E and M inputs and their interactions. We show that by modeling\nDNA as natural language, our approach performs better than previous approaches\nwhen tested for new environments and similarly to other approaches for unseen\nseed varieties.",
            "categories": [
                "cs.LG",
                "cs.CY"
            ],
            "link": "http://arxiv.org/pdf/2211.05986v1",
            "date": "2022-11-11 03:32:44+00:00"
        },
        {
            "title": "Efficient Cavity Searching for Gene Network of Influenza A Virus",
            "authors": [
                "Junjie Li",
                "Jietong Zhao",
                "Yanqing Su",
                "Jiahao Shen",
                "Yaohua Liu",
                "Xinyue Fan",
                "Zheng Kou"
            ],
            "abstract": "High order structures (cavities and cliques) of the gene network of influenza\nA virus reveal tight associations among viruses during evolution and are key\nsignals that indicate viral cross-species infection and cause pandemics. As\nindicators for sensing the dynamic changes of viral genes, these higher order\nstructures have been the focus of attention in the field of virology. However,\nthe size of the viral gene network is usually huge, and searching these\nstructures in the networks introduces unacceptable delay. To mitigate this\nissue, in this paper, we propose a simple-yet-effective model named HyperSearch\nbased on deep learning to search cavities in a computable complex network for\ninfluenza virus genetics. Extensive experiments conducted on a public influenza\nvirus dataset demonstrate the effectiveness of HyperSearch over other advanced\ndeep-learning methods without any elaborated model crafting. Moreover,\nHyperSearch can finish the search works in minutes while 0-1 programming takes\ndays. Since the proposed method is simple and easy to be transferred to other\ncomplex networks, HyperSearch has the potential to facilitate the monitoring of\ndynamic changes in viral genes and help humans keep up with the pace of virus\nmutations.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2211.02935v1",
            "date": "2022-11-05 16:24:55+00:00"
        },
        {
            "title": "Fusing Modalities by Multiplexed Graph Neural Networks for Outcome Prediction in Tuberculosis",
            "authors": [
                "Niharika S. D'Souza",
                "Hongzhi Wang",
                "Andrea Giovannini",
                "Antonio Foncubierta-Rodriguez",
                "Kristen L. Beck",
                "Orest Boyko",
                "Tanveer Syeda-Mahmood"
            ],
            "abstract": "In a complex disease such as tuberculosis, the evidence for the disease and\nits evolution may be present in multiple modalities such as clinical, genomic,\nor imaging data. Effective patient-tailored outcome prediction and therapeutic\nguidance will require fusing evidence from these modalities. Such multimodal\nfusion is difficult since the evidence for the disease may not be uniform\nacross all modalities, not all modality features may be relevant, or not all\nmodalities may be present for all patients. All these nuances make simple\nmethods of early, late, or intermediate fusion of features inadequate for\noutcome prediction. In this paper, we present a novel fusion framework using\nmultiplexed graphs and derive a new graph neural network for learning from such\ngraphs. Specifically, the framework allows modalities to be represented through\ntheir targeted encodings, and models their relationship explicitly via\nmultiplexed graphs derived from salient features in a combined latent space. We\npresent results that show that our proposed method outperforms state-of-the-art\nmethods of fusing modalities for multi-outcome prediction on a large\nTuberculosis (TB) dataset.",
            "categories": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ],
            "link": "http://arxiv.org/pdf/2210.14377v1",
            "date": "2022-10-25 23:03:05+00:00"
        },
        {
            "title": "Graph Coloring via Neural Networks for Haplotype Assembly and Viral Quasispecies Reconstruction",
            "authors": [
                "Hansheng Xue",
                "Vaibhav Rajan",
                "Yu Lin"
            ],
            "abstract": "Understanding genetic variation, e.g., through mutations, in organisms is\ncrucial to unravel their effects on the environment and human health. A\nfundamental characterization can be obtained by solving the haplotype assembly\nproblem, which yields the variation across multiple copies of chromosomes.\nVariations among fast evolving viruses that lead to different strains (called\nquasispecies) are also deciphered with similar approaches. In both these cases,\nhigh-throughput sequencing technologies that provide oversampled mixtures of\nlarge noisy fragments (reads) of genomes, are used to infer constituent\ncomponents (haplotypes or quasispecies). The problem is harder for polyploid\nspecies where there are more than two copies of chromosomes. State-of-the-art\nneural approaches to solve this NP-hard problem do not adequately model\nrelations among the reads that are important for deconvolving the input signal.\nWe address this problem by developing a new method, called NeurHap, that\ncombines graph representation learning with combinatorial optimization. Our\nexperiments demonstrate substantially better performance of NeurHap in real and\nsynthetic datasets compared to competing approaches.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2210.12158v1",
            "date": "2022-10-21 12:53:09+00:00"
        },
        {
            "title": "GLCC: A General Framework for Graph-Level Clustering",
            "authors": [
                "Wei Ju",
                "Yiyang Gu",
                "Binqi Chen",
                "Gongbo Sun",
                "Yifang Qin",
                "Xingyuming Liu",
                "Xiao Luo",
                "Ming Zhang"
            ],
            "abstract": "This paper studies the problem of graph-level clustering, which is a novel\nyet challenging task. This problem is critical in a variety of real-world\napplications such as protein clustering and genome analysis in bioinformatics.\nRecent years have witnessed the success of deep clustering coupled with graph\nneural networks (GNNs). However, existing methods focus on clustering among\nnodes given a single graph, while exploring clustering on multiple graphs is\nstill under-explored. In this paper, we propose a general graph-level\nclustering framework named Graph-Level Contrastive Clustering (GLCC) given\nmultiple graphs. Specifically, GLCC first constructs an adaptive affinity graph\nto explore instance- and cluster-level contrastive learning (CL).\nInstance-level CL leverages graph Laplacian based contrastive loss to learn\nclustering-friendly representations while cluster-level CL captures\ndiscriminative cluster representations incorporating neighbor information of\neach sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the\noptimization of representation learning. The two steps can be alternatively\ntrained to collaborate and benefit each other. Experiments on a range of\nwell-known datasets demonstrate the superiority of our proposed GLCC over\ncompetitive baselines.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "cs.SI"
            ],
            "link": "http://arxiv.org/pdf/2210.11879v4",
            "date": "2022-10-21 11:08:10+00:00"
        },
        {
            "title": "Granger causal inference on DAGs identifies genomic loci regulating transcription",
            "authors": [
                "Rohit Singh",
                "Alexander P. Wu",
                "Bonnie Berger"
            ],
            "abstract": "When a dynamical system can be modeled as a sequence of observations, Granger\ncausality is a powerful approach for detecting predictive interactions between\nits variables. However, traditional Granger causal inference has limited\nutility in domains where the dynamics need to be represented as directed\nacyclic graphs (DAGs) rather than as a linear sequence, such as with cell\ndifferentiation trajectories. Here, we present GrID-Net, a framework based on\ngraph neural networks with lagged message passing for Granger causal inference\non DAG-structured systems. Our motivating application is the analysis of\nsingle-cell multimodal data to identify genomic loci that mediate the\nregulation of specific genes. To our knowledge, GrID-Net is the first\nsingle-cell analysis tool that accounts for the temporal lag between a genomic\nlocus becoming accessible and its downstream effect on a target gene's\nexpression. We applied GrID-Net on multimodal single-cell assays that profile\nchromatin accessibility (ATAC-seq) and gene expression (RNA-seq) in the same\ncell and show that it dramatically outperforms existing methods for inferring\nregulatory locus-gene links, achieving up to 71% greater agreement with\nindependent population genetics-based estimates. By extending Granger causality\nto DAG-structured dynamical systems, our work unlocks new domains for causal\nanalyses and, more specifically, opens a path towards elucidating gene\nregulatory interactions relevant to cellular differentiation and complex human\ndiseases at unprecedented scale and resolution.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2210.10168v1",
            "date": "2022-10-18 21:15:10+00:00"
        },
        {
            "title": "SHINE: SubHypergraph Inductive Neural nEtwork",
            "authors": [
                "Yuan Luo"
            ],
            "abstract": "Hypergraph neural networks can model multi-way connections among nodes of the\ngraphs, which are common in real-world applications such as genetic medicine.\nIn particular, genetic pathways or gene sets encode molecular functions driven\nby multiple genes, naturally represented as hyperedges. Thus, hypergraph-guided\nembedding can capture functional relations in learned representations. Existing\nhypergraph neural network models often focus on node-level or graph-level\ninference. There is an unmet need in learning powerful representations of\nsubgraphs of hypergraphs in real-world applications. For example, a cancer\npatient can be viewed as a subgraph of genes harboring mutations in the\npatient, while all the genes are connected by hyperedges that correspond to\npathways representing specific molecular functions. For accurate inductive\nsubgraph prediction, we propose SubHypergraph Inductive Neural nEtwork (SHINE).\nSHINE uses informative genetic pathways that encode molecular functions as\nhyperedges to connect genes as nodes. SHINE jointly optimizes the objectives of\nend-to-end subgraph classification and hypergraph nodes' similarity\nregularization. SHINE simultaneously learns representations for both genes and\npathways using strongly dual attention message passing. The learned\nrepresentations are aggregated via a subgraph attention layer and used to train\na multilayer perceptron for inductive subgraph inferencing. We evaluated SHINE\nagainst a wide array of state-of-the-art (hyper)graph neural networks, XGBoost,\nNMF and polygenic risk score models, using large scale NGS and curated\ndatasets. SHINE outperformed all comparison models significantly, and yielded\ninterpretable disease models with functional insights.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN",
                "q-bio.MN"
            ],
            "link": "http://arxiv.org/pdf/2210.07309v1",
            "date": "2022-10-13 19:26:09+00:00"
        },
        {
            "title": "Self-omics: A Self-supervised Learning Framework for Multi-omics Cancer Data",
            "authors": [
                "Sayed Hashim",
                "Karthik Nandakumar",
                "Mohammad Yaqub"
            ],
            "abstract": "We have gained access to vast amounts of multi-omics data thanks to Next\nGeneration Sequencing. However, it is challenging to analyse this data due to\nits high dimensionality and much of it not being annotated. Lack of annotated\ndata is a significant problem in machine learning, and Self-Supervised Learning\n(SSL) methods are typically used to deal with limited labelled data. However,\nthere is a lack of studies that use SSL methods to exploit inter-omics\nrelationships on unlabelled multi-omics data. In this work, we develop a novel\nand efficient pre-training paradigm that consists of various SSL components,\nincluding but not limited to contrastive alignment, data recovery from\ncorrupted samples, and using one type of omics data to recover other omic\ntypes. Our pre-training paradigm improves performance on downstream tasks with\nlimited labelled data. We show that our approach outperforms the\nstate-of-the-art method in cancer type classification on the TCGA pan-cancer\ndataset in semi-supervised setting. Moreover, we show that the encoders that\nare pre-trained using our approach can be used as powerful feature extractors\neven without fine-tuning. Our ablation study shows that the method is not\noverly dependent on any pretext task component. The network architectures in\nour approach are designed to handle missing omic types and multiple datasets\nfor pre-training and downstream training. Our pre-training paradigm can be\nextended to perform zero-shot classification of rare cancers.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2210.00825v1",
            "date": "2022-10-03 11:20:12+00:00"
        },
        {
            "title": "Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information",
            "authors": [
                "Yulun Wu",
                "Robert A. Barton",
                "Zichen Wang",
                "Vassilis N. Ioannidis",
                "Carlo De Donno",
                "Layne C. Price",
                "Luis F. Voloch",
                "George Karypis"
            ],
            "abstract": "Predicting the responses of a cell under perturbations may bring important\nbenefits to drug discovery and personalized therapeutics. In this work, we\npropose a novel graph variational Bayesian causal inference framework to\npredict a cell's gene expressions under counterfactual perturbations\n(perturbations that this cell did not factually receive), leveraging\ninformation representing biological knowledge in the form of gene regulatory\nnetworks (GRNs) to aid individualized cellular response predictions. Aiming at\na data-adaptive GRN, we also developed an adjacency matrix updating technique\nfor graph convolutional networks and used it to refine GRNs during\npre-training, which generated more insights on gene relations and enhanced\nmodel performance. Additionally, we propose a robust estimator within our\nframework for the asymptotically efficient estimation of marginal perturbation\neffect, which is yet to be carried out in previous works. With extensive\nexperiments, we exhibited the advantage of our approach over state-of-the-art\ndeep learning models for individual response prediction.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN",
                "stat.ME",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2210.00116v2",
            "date": "2022-09-30 22:13:57+00:00"
        },
        {
            "title": "Deep learning forward and reverse primer design to detect SARS-CoV-2 emerging variants",
            "authors": [
                "Hanyu Wang",
                "Emmanuel K. Tsinda",
                "Anthony J. Dunn",
                "Francis Chikweto",
                "Nusreen Ahmed",
                "Emanuela Pelosi",
                "Alain B. Zemkoho"
            ],
            "abstract": "Surges that have been observed at different periods in the number of COVID-19\ncases are associated with the emergence of multiple SARS-CoV-2 (Severe Acute\nRespiratory Virus) variants. The design of methods to support laboratory\ndetection are crucial in the monitoring of these variants. Hence, in this\npaper, we develop a semi-automated method to design both forward and reverse\nprimer sets to detect SARS-CoV-2 variants. To proceed, we train deep\nConvolution Neural Networks (CNNs) to classify labelled SARS-CoV-2 variants and\nidentify partial genomic features needed for the forward and reverse Polymerase\nChain Reaction (PCR) primer design. Our proposed approach supplements existing\nones while promoting the emerging concept of neural network assisted primer\ndesign for PCR. Our CNN model was trained using a database of SARS-CoV-2\nfull-length genomes from GISAID and tested on a separate dataset from NCBI,\nwith 98\\% accuracy for the classification of variants. This result is based on\nthe development of three different methods of feature extraction, and the\nselected primer sequences for each SARS-CoV-2 variant detection (except\nOmicron) were present in more than 95 \\% of sequences in an independent set of\n5000 same variant sequences, and below 5 \\% in other independent datasets with\n5000 sequences of each variant. In total, we obtain 22 forward and reverse\nprimer pairs with flexible length sizes (18-25 base pairs) with an expected\namplicon length ranging between 42 and 3322 nucleotides. Besides the feature\nappearance, in-silico primer checks confirmed that the identified primer pairs\nare suitable for accurate SARS-CoV-2 variant detection by means of PCR tests.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2209.13591v1",
            "date": "2022-09-25 20:09:22+00:00"
        },
        {
            "title": "Highly Scalable Task Grouping for Deep Multi-Task Learning in Prediction of Epigenetic Events",
            "authors": [
                "Mohammad Shiri",
                "Jiangwen Sun"
            ],
            "abstract": "Deep neural networks trained for predicting cellular events from DNA sequence\nhave become emerging tools to help elucidate the biological mechanism\nunderlying the associations identified in genome-wide association studies. To\nenhance the training, multi-task learning (MTL) has been commonly exploited in\nprevious works where trained networks were needed for multiple profiles\ndiffering in either event modality or cell type. All existing works adopted a\nsimple MTL framework where all tasks share a single feature extraction network.\nSuch a strategy even though effective to certain extent leads to substantial\nnegative transfer, meaning the existence of large portion of tasks for which\nmodels obtained through MTL perform worse than those by single task learning.\nThere have been methods developed to address such negative transfer in other\ndomains, such as computer vision. However, these methods are generally\ndifficult to scale up to handle large amount of tasks. In this paper, we\npropose a highly scalable task grouping framework to address negative transfer\nby only jointly training tasks that are potentially beneficial to each other.\nThe proposed method exploits the network weights associated with task specific\nclassification heads that can be cheaply obtained by one-time joint training of\nall tasks. Our results using a dataset consisting of 367 epigenetic profiles\ndemonstrate the effectiveness of the proposed approach and its superiority over\nbaseline methods.",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2209.11892v1",
            "date": "2022-09-24 00:39:51+00:00"
        },
        {
            "title": "SGC: A semi-supervised pipeline for gene clustering using self-training approach in gene co-expression networks",
            "authors": [
                "Niloofar Aghaieabiane",
                "Ioannis Koutis"
            ],
            "abstract": "A widely used approach for extracting information from gene expression data\nemploy the construction of a gene co-expression network and the subsequent\napplication of algorithms that discover network structure. In particular, a\ncommon goal is the computational discovery of gene clusters, commonly called\nmodules. When applied on a novel gene expression dataset, the quality of the\ncomputed modules can be evaluated automatically, using Gene Ontology\nenrichment, a method that measures the frequencies of Gene Ontology terms in\nthe computed modules and evaluates their statistical likelihood. In this work\nwe propose SGC a novel pipeline for gene clustering based on relatively recent\nseminal work in the mathematics of spectral network theory. SGC consists of\nmultiple novel steps that enable the computation of highly enriched modules in\nan unsupervised manner. But unlike all existing frameworks, it further\nincorporates a novel step that leverages Gene Ontology information in a\nsemi-supervised clustering method that further improves the quality of the\ncomputed modules. Comparing with already well-known existing frameworks, we\nshow that SGC results in higher enrichment in real data. In particular, in 12\nreal gene expression datasets, SGC outperforms in all except one.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2209.10545v1",
            "date": "2022-09-21 14:51:08+00:00"
        },
        {
            "title": "Semi-supervised classification using a supervised autoencoder for biomedical applications",
            "authors": [
                "Cyprien Gille",
                "Frederic Guyard",
                "Michel Barlaud"
            ],
            "abstract": "In this paper we present a new approach to solve semi-supervised\nclassification tasks for biomedical applications, involving a supervised\nautoencoder network. We create a network architecture that encodes labels into\nthe latent space of an autoencoder, and define a global criterion combining\nclassification and reconstruction losses. We train the Semi-Supervised\nAutoEncoder (SSAE) on labelled data using a double descent algorithm. Then, we\nclassify unlabelled samples using the learned network thanks to a softmax\nclassifier applied to the latent space which provides a classification\nconfidence score for each class.\n  We implemented our SSAE method using the PyTorch framework for the model,\noptimizer, schedulers, and loss functions. We compare our semi-supervised\nautoencoder method (SSAE) with classical semi-supervised methods such as Label\nPropagation and Label Spreading, and with a Fully Connected Neural Network\n(FCNN). Experiments show that the SSAE outperforms Label Propagation and\nSpreading and the Fully Connected Neural Network both on a synthetic dataset\nand on two real-world biological datasets.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2208.10315v1",
            "date": "2022-08-22 13:51:00+00:00"
        },
        {
            "title": "CoViT: Real-time phylogenetics for the SARS-CoV-2 pandemic using Vision Transformers",
            "authors": [
                "Zuher Jahshan",
                "Can Alkan",
                "Leonid Yavits"
            ],
            "abstract": "Real-time viral genome detection, taxonomic classification and phylogenetic\nanalysis are critical for efficient tracking and control of viral pandemics\nsuch as Covid-19. However, the unprecedented and still growing amounts of viral\ngenome data create a computational bottleneck, which effectively prevents the\nreal-time pandemic tracking. For genomic tracing to work effectively, each new\nviral genome sequence must be placed in its pangenomic context. Re-inferring\nthe full phylogeny of SARS-CoV-2, with datasets containing millions of samples,\nis prohibitively slow even using powerful computational resources. We are\nattempting to alleviate the computational bottleneck by modifying and applying\nVision Transformer, a recently developed neural network model for image\nrecognition, to taxonomic classification and placement of viral genomes, such\nas SARS-CoV-2. Our solution, CoViT, places SARS-CoV-2 genome accessions onto\nSARS-CoV-2 phylogenetic tree with the accuracy of 94.2%. Since CoViT is a\nclassification neural network, it provides more than one likely placement.\nSpecifically, one of the two most likely placements suggested by CoViT is\ncorrect with the probability of 97.9%. The probability of the correct placement\nto be found among the five most likely placements generated by CoViT is 99.8%.\nThe placement time is 0.055s per individual genome running on NVIDIAs GeForce\nRTX 2080 Ti GPU. We make CoViT available to research community through GitHub:\nhttps://github.com/zuherJahshan/covit.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2208.05004v2",
            "date": "2022-08-09 19:13:41+00:00"
        },
        {
            "title": "Granger Causality using Neural Networks",
            "authors": [
                "Samuel Horvath",
                "Malik Shahid Sultan",
                "Hernando Ombao"
            ],
            "abstract": "The Granger Causality (GC) test is a famous statistical hypothesis test for\ninvestigating if the past of one time series affects the future of the other.\nIt helps in answering the question whether one time series is helpful in\nforecasting. Standard traditional approaches to Granger causality detection\ncommonly assume linear dynamics, but such simplification does not hold in many\nreal-world applications, e.g., neuroscience or genomics that are inherently\nnon-linear. In such cases, imposing linear models such as Vector Autoregressive\n(VAR) models can lead to inconsistent estimation of true Granger Causal\ninteractions. Machine Learning (ML) can learn the hidden patterns in the\ndatasets specifically Deep Learning (DL) has shown tremendous promise in\nlearning the non-linear dynamics of complex systems. Recent work of Tank et al\npropose to overcome the issue of linear simplification in VAR models by using\nneural networks combined with sparsity-inducing penalties on the learn-able\nweights. In this work, we build upon ideas introduced by Tank et al. We propose\nseveral new classes of models that can handle underlying non-linearity.\nFirstly, we present the Learned Kernal VAR(LeKVAR) model-an extension of VAR\nmodels that also learns kernel parametrized by a neural net. Secondly, we show\none can directly decouple lags and individual time series importance via\ndecoupled penalties. This decoupling provides better scaling and allows us to\nembed lag selection into RNNs. Lastly, we propose a new training algorithm that\nsupports mini-batching, and it is compatible with commonly used adaptive\noptimizers such as Adam.he proposed techniques are evaluated on several\nsimulated datasets inspired by real-world applications.We also apply these\nmethods to the Electro-Encephalogram (EEG) data for an epilepsy patient to\nstudy the evolution of GC before , during and after seizure across the 19 EEG\nchannels.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2208.03703v1",
            "date": "2022-08-07 12:02:48+00:00"
        },
        {
            "title": "Isoform Function Prediction Using a Deep Neural Network",
            "authors": [
                "Sara Ghazanfari",
                "Ali Rasteh",
                "Seyed Abolfazl Motahari",
                "Mahdieh Soleymani Baghshah"
            ],
            "abstract": "Isoforms are mRNAs produced from the same gene site in the phenomenon called\nAlternative Splicing. Studies have shown that more than 95% of human multi-exon\ngenes have undergone alternative splicing. Although there are few changes in\nmRNA sequence, They may have a systematic effect on cell function and\nregulation. It is widely reported that isoforms of a gene have distinct or even\ncontrasting functions. Most studies have shown that alternative splicing plays\na significant role in human health and disease. Despite the wide range of gene\nfunction studies, there is little information about isoforms' functionalities.\nRecently, some computational methods based on Multiple Instance Learning have\nbeen proposed to predict isoform function using gene function and gene\nexpression profile. However, their performance is not desirable due to the lack\nof labeled training data. In addition, probabilistic models such as Conditional\nRandom Field (CRF) have been used to model the relation between isoforms. This\nproject uses all the data and valuable information such as isoform sequences,\nexpression profiles, and gene ontology graphs and proposes a comprehensive\nmodel based on Deep Neural Networks. The UniProt Gene Ontology (GO) database is\nused as a standard reference for gene functions. The NCBI RefSeq database is\nused for extracting gene and isoform sequences, and the NCBI SRA database is\nused for expression profile data. Metrics such as Receiver Operating\nCharacteristic Area Under the Curve (ROC AUC) and Precision-Recall Under the\nCurve (PR AUC) are used to measure the prediction accuracy.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2208.03325v3",
            "date": "2022-08-05 09:31:25+00:00"
        },
        {
            "title": "Neuro-Symbolic Learning: Principles and Applications in Ophthalmology",
            "authors": [
                "Muhammad Hassan",
                "Haifei Guan",
                "Aikaterini Melliou",
                "Yuqi Wang",
                "Qianhui Sun",
                "Sen Zeng",
                "Wen Liang",
                "Yiwei Zhang",
                "Ziheng Zhang",
                "Qiuyue Hu",
                "Yang Liu",
                "Shunkai Shi",
                "Lin An",
                "Shuyue Ma",
                "Ijaz Gul",
                "Muhammad Akmal Rahee",
                "Zhou You",
                "Canyang Zhang",
                "Vijay Kumar Pandey",
                "Yuxing Han",
                "Yongbing Zhang",
                "Ming Xu",
                "Qiming Huang",
                "Jiefu Tan",
                "Qi Xing",
                "Peiwu Qin",
                "Dongmei Yu"
            ],
            "abstract": "Neural networks have been rapidly expanding in recent years, with novel\nstrategies and applications. However, challenges such as interpretability,\nexplainability, robustness, safety, trust, and sensibility remain unsolved in\nneural network technologies, despite the fact that they will unavoidably be\naddressed for critical applications. Attempts have been made to overcome the\nchallenges in neural network computing by representing and embedding domain\nknowledge in terms of symbolic representations. Thus, the neuro-symbolic\nlearning (NeSyL) notion emerged, which incorporates aspects of symbolic\nrepresentation and bringing common sense into neural networks (NeSyL). In\ndomains where interpretability, reasoning, and explainability are crucial, such\nas video and image captioning, question-answering and reasoning, health\ninformatics, and genomics, NeSyL has shown promising outcomes. This review\npresents a comprehensive survey on the state-of-the-art NeSyL approaches, their\nprinciples, advances in machine and deep learning algorithms, applications such\nas opthalmology, and most importantly, future perspectives of this emerging\nfield.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2208.00374v1",
            "date": "2022-07-31 06:48:19+00:00"
        },
        {
            "title": "Neural Design for Genetic Perturbation Experiments",
            "authors": [
                "Aldo Pacchiano",
                "Drausin Wulsin",
                "Robert A. Barton",
                "Luis Voloch"
            ],
            "abstract": "The problem of how to genetically modify cells in order to maximize a certain\ncellular phenotype has taken center stage in drug development over the last few\nyears (with, for example, genetically edited CAR-T, CAR-NK, and CAR-NKT cells\nentering cancer clinical trials). Exhausting the search space for all possible\ngenetic edits (perturbations) or combinations thereof is infeasible due to cost\nand experimental limitations. This work provides a theoretically sound\nframework for iteratively exploring the space of perturbations in pooled\nbatches in order to maximize a target phenotype under an experimental budget.\nInspired by this application domain, we study the problem of batch query bandit\noptimization and introduce the Optimistic Arm Elimination ($\\mathrm{OAE}$)\nprinciple designed to find an almost optimal arm under different functional\nrelationships between the queries (arms) and the outputs (rewards). We analyze\nthe convergence properties of $\\mathrm{OAE}$ by relating it to the Eluder\ndimension of the algorithm's function class and validate that $\\mathrm{OAE}$\noutperforms other strategies in finding optimal actions in experiments on\nsimulated problems, public datasets well-studied in bandit contexts, and in\ngenetic perturbation datasets when the regression model is a deep neural\nnetwork. OAE also outperforms the benchmark algorithms in 3 of 4 datasets in\nthe GeneDisco experimental planning challenge.",
            "categories": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2207.12805v2",
            "date": "2022-07-26 10:59:52+00:00"
        },
        {
            "title": "Inference of Regulatory Networks Through Temporally Sparse Data",
            "authors": [
                "Mohammad Alali",
                "Mahdi Imani"
            ],
            "abstract": "A major goal in genomics is to properly capture the complex dynamical\nbehaviors of gene regulatory networks (GRNs). This includes inferring the\ncomplex interactions between genes, which can be used for a wide range of\ngenomics analyses, including diagnosis or prognosis of diseases and finding\neffective treatments for chronic diseases such as cancer. Boolean networks have\nemerged as a successful class of models for capturing the behavior of GRNs. In\nmost practical settings, inference of GRNs should be achieved through limited\nand temporally sparse genomics data. A large number of genes in GRNs leads to a\nlarge possible topology candidate space, which often cannot be exhaustively\nsearched due to the limitation in computational resources. This paper develops\na scalable and efficient topology inference for GRNs using Bayesian\noptimization and kernel-based methods. Rather than an exhaustive search over\npossible topologies, the proposed method constructs a Gaussian Process (GP)\nwith a topology-inspired kernel function to account for correlation in the\nlikelihood function. Then, using the posterior distribution of the GP model,\nthe Bayesian optimization efficiently searches for the topology with the\nhighest likelihood value by optimally balancing between exploration and\nexploitation. The performance of the proposed method is demonstrated through\ncomprehensive numerical experiments using a well-known mammalian cell-cycle\nnetwork.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "stat.ME",
                "stat.ML",
                "62M05"
            ],
            "link": "http://arxiv.org/pdf/2207.12124v1",
            "date": "2022-07-21 22:48:12+00:00"
        },
        {
            "title": "Stacked Autoencoder Based Multi-Omics Data Integration for Cancer Survival Prediction",
            "authors": [
                "Xing Wu",
                "Qiulian Fang"
            ],
            "abstract": "Cancer survival prediction is important for developing personalized\ntreatments and inducing disease-causing mechanisms. Multi-omics data\nintegration is attracting widespread interest in cancer research for providing\ninformation for understanding cancer progression at multiple genetic levels.\nMany works, however, are limited because of the high dimensionality and\nheterogeneity of multi-omics data. In this paper, we propose a novel method to\nintegrate multi-omics data for cancer survival prediction, called Stacked\nAutoEncoder-based Survival Prediction Neural Network (SAEsurv-net). In the\ncancer survival prediction for TCGA cases, SAEsurv-net addresses the curse of\ndimensionality with a two-stage dimensionality reduction strategy and handles\nmulti-omics heterogeneity with a stacked autoencoder model. The two-stage\ndimensionality reduction strategy achieves a balance between computation\ncomplexity and information exploiting. The stacked autoencoder model removes\nmost heterogeneities such as data's type and size in the first group of\nautoencoders, and integrates multiple omics data in the second autoencoder. The\nexperiments show that SAEsurv-net outperforms models based on a single type of\ndata as well as other state-of-the-art methods.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.AP"
            ],
            "link": "http://arxiv.org/pdf/2207.04878v1",
            "date": "2022-07-08 13:53:11+00:00"
        },
        {
            "title": "MPClan: Protocol Suite for Privacy-Conscious Computations",
            "authors": [
                "Nishat Koti",
                "Shravani Patil",
                "Arpita Patra",
                "Ajith Suresh"
            ],
            "abstract": "The growing volumes of data being collected and its analysis to provide\nbetter services are creating worries about digital privacy. To address privacy\nconcerns and give practical solutions, the literature has relied on secure\nmultiparty computation. However, recent research has mostly focused on the\nsmall-party honest-majority setting of up to four parties, noting efficiency\nconcerns. In this work, we extend the strategies to support a larger number of\nparticipants in an honest-majority setting with efficiency at the center stage.\n  Cast in the preprocessing paradigm, our semi-honest protocol improves the\nonline complexity of the decade-old state-of-the-art protocol of Damg\\aa rd and\nNielson (CRYPTO'07). In addition to having an improved online communication\ncost, we can shut down almost half of the parties in the online phase, thereby\nsaving up to 50% in the system's operational costs. Our maliciously secure\nprotocol also enjoys similar benefits and requires only half of the parties,\nexcept for one-time verification, towards the end.\n  To showcase the practicality of the designed protocols, we benchmark popular\napplications such as deep neural networks, graph neural networks, genome\nsequence matching, and biometric matching using prototype implementations. Our\nimproved protocols aid in bringing up to 60-80% savings in monetary cost over\nprior work.",
            "categories": [
                "cs.CR",
                "cs.DC",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ],
            "link": "http://arxiv.org/pdf/2206.12224v1",
            "date": "2022-06-24 11:47:15+00:00"
        },
        {
            "title": "A Neural Network Based Method with Transfer Learning for Genetic Data Analysis",
            "authors": [
                "Jinghang Lin",
                "Shan Zhang",
                "Qing Lu"
            ],
            "abstract": "Transfer learning has emerged as a powerful technique in many application\nproblems, such as computer vision and natural language processing. However,\nthis technique is largely ignored in application to genetic data analysis. In\nthis paper, we combine transfer learning technique with a neural network based\nmethod(expectile neural networks). With transfer learning, instead of starting\nthe learning process from scratch, we start from one task that have been\nlearned when solving a different task. We leverage previous learnings and avoid\nstarting from scratch to improve the model performance by passing information\ngained in different but related task. To demonstrate the performance, we run\ntwo real data sets. By using transfer learning algorithm, the performance of\nexpectile neural networks is improved compared to expectile neural network\nwithout using transfer learning technique.",
            "categories": [
                "stat.AP",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2206.09872v1",
            "date": "2022-06-20 16:16:05+00:00"
        },
        {
            "title": "LogGENE: A smooth alternative to check loss for Deep Healthcare Inference Tasks",
            "authors": [
                "Aryaman Jeendgar",
                "Aditya Pola",
                "Soma S Dhavala",
                "Snehanshu Saha"
            ],
            "abstract": "High-throughput Genomics is ushering a new era in personalized health care,\nand targeted drug design and delivery. Mining these large datasets, and\nobtaining calibrated predictions is of immediate relevance and utility. In our\nwork, we develop methods for Gene Expression Inference based on Deep neural\nnetworks. However, unlike typical Deep learning methods, our inferential\ntechnique, while achieving state-of-the-art performance in terms of accuracy,\ncan also provide explanations, and report uncertainty estimates. We adopt the\nQuantile Regression framework to predict full conditional quantiles for a given\nset of house keeping gene expressions. Conditional quantiles, in addition to\nbeing useful in providing rich interpretations of the predictions, are also\nrobust to measurement noise. However, check loss, used in quantile regression\nto drive the estimation process is not differentiable. We propose log-cosh as a\nsmooth-alternative to the check loss. We apply our methods on GEO microarray\ndataset. We also extend the method to binary classification setting.\nFurthermore, we investigate other consequences of the smoothness of the loss in\nfaster convergence.",
            "categories": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2206.09333v1",
            "date": "2022-06-19 06:46:39+00:00"
        },
        {
            "title": "Transformer Neural Networks Attending to Both Sequence and Structure for Protein Prediction Tasks",
            "authors": [
                "Anowarul Kabir",
                "Amarda Shehu"
            ],
            "abstract": "The increasing number of protein sequences decoded from genomes is opening up\nnew avenues of research on linking protein sequence to function with\ntransformer neural networks. Recent research has shown that the number of known\nprotein sequences supports learning useful, task-agnostic sequence\nrepresentations via transformers. In this paper, we posit that learning joint\nsequence-structure representations yields better representations for\nfunction-related prediction tasks. We propose a transformer neural network that\nattends to both sequence and tertiary structure. We show that such joint\nrepresentations are more powerful than sequence-based representations only, and\nthey yield better performance on superfamily membership across various metrics.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2206.11057v1",
            "date": "2022-06-17 18:40:19+00:00"
        },
        {
            "title": "Learning to Untangle Genome Assembly with Graph Convolutional Networks",
            "authors": [
                "Lovro Vr\u010dek",
                "Xavier Bresson",
                "Thomas Laurent",
                "Martin Schmitz",
                "Mile \u0160iki\u0107"
            ],
            "abstract": "A quest to determine the complete sequence of a human DNA from telomere to\ntelomere started three decades ago and was finally completed in 2021. This\naccomplishment was a result of a tremendous effort of numerous experts who\nengineered various tools and performed laborious manual inspection to achieve\nthe first gapless genome sequence. However, such method can hardly be used as a\ngeneral approach to assemble different genomes, especially when the assembly\nspeed is critical given the large amount of data. In this work, we explore a\ndifferent approach to the central part of the genome assembly task that\nconsists of untangling a large assembly graph from which a genomic sequence\nneeds to be reconstructed. Our main motivation is to reduce human-engineered\nheuristics and use deep learning to develop more generalizable reconstruction\ntechniques. Precisely, we introduce a new learning framework to train a graph\nconvolutional network to resolve assembly graphs by finding a correct path\nthrough them. The training is supervised with a dataset generated from the\nresolved CHM13 human sequence and tested on assembly graphs built using real\nhuman PacBio HiFi reads. Experimental results show that a model, trained on\nsimulated graphs generated solely from a single chromosome, is able to\nremarkably resolve all other chromosomes. Moreover, the model outperforms\nhand-crafted heuristics from a state-of-the-art \\textit{de novo} assembler on\nthe same graphs. Reconstructed chromosomes with graph networks are more\naccurate on nucleotide level, report lower number of contigs, higher genome\nreconstructed fraction and NG50/NGA50 assessment metrics.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2206.00668v1",
            "date": "2022-06-01 04:14:25+00:00"
        },
        {
            "title": "A review of machine learning approaches, challenges and prospects for computational tumor pathology",
            "authors": [
                "Liangrui Pan",
                "Zhichao Feng",
                "Shaoliang Peng"
            ],
            "abstract": "Computational pathology is part of precision oncology medicine. The\nintegration of high-throughput data including genomics, transcriptomics,\nproteomics, metabolomics, pathomics, and radiomics into clinical practice\nimproves cancer treatment plans, treatment cycles, and cure rates, and helps\ndoctors open up innovative approaches to patient prognosis. In the past decade,\nrapid advances in artificial intelligence, chip design and manufacturing, and\nmobile computing have facilitated research in computational pathology and have\nthe potential to provide better-integrated solutions for whole-slide images,\nmulti-omics data, and clinical informatics. However, tumor computational\npathology now brings some challenges to the application of tumour screening,\ndiagnosis and prognosis in terms of data integration, hardware processing,\nnetwork sharing bandwidth and machine learning technology. This review\ninvestigates image preprocessing methods in computational pathology from a\npathological and technical perspective, machine learning-based methods, and\napplications of computational pathology in breast, colon, prostate, lung, and\nvarious tumour disease scenarios. Finally, the challenges and prospects of\nmachine learning in computational pathology applications are discussed.",
            "categories": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2206.01728v1",
            "date": "2022-05-31 14:56:01+00:00"
        },
        {
            "title": "N-ACT: An Interpretable Deep Learning Model for Automatic Cell Type and Salient Gene Identification",
            "authors": [
                "A. Ali Heydari",
                "Oscar A. Davalos",
                "Katrina K. Hoyer",
                "Suzanne S. Sindi"
            ],
            "abstract": "Single-cell RNA sequencing (scRNAseq) is rapidly advancing our understanding\nof cellular composition within complex tissues and organisms. A major\nlimitation in most scRNAseq analysis pipelines is the reliance on manual\nannotations to determine cell identities, which are time consuming, subjective,\nand require expertise. Given the surge in cell sequencing, supervised\nmethods-especially deep learning models-have been developed for automatic cell\ntype identification (ACTI), which achieve high accuracy and scalability.\nHowever, all existing deep learning frameworks for ACTI lack interpretability\nand are used as \"black-box\" models. We present N-ACT (Neural-Attention for Cell\nType identification): the first-of-its-kind interpretable deep neural network\nfor ACTI utilizing neural-attention to detect salient genes for use in\ncell-type identification. We compare N-ACT to conventional annotation methods\non two previously manually annotated data sets, demonstrating that N-ACT\naccurately identifies marker genes and cell types in an unsupervised manner,\nwhile performing comparably on multiple data sets to current state-of-the-art\nmodel in traditional supervised ACTI.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2206.04047v1",
            "date": "2022-05-08 18:13:28+00:00"
        },
        {
            "title": "Topological Data Analysis in Time Series: Temporal Filtration and Application to Single-Cell Genomics",
            "authors": [
                "Baihan Lin"
            ],
            "abstract": "The absence of a conventional association between the cell-cell cohabitation\nand its emergent dynamics into cliques during development has hindered our\nunderstanding of how cell populations proliferate, differentiate, and compete,\ni.e. the cell ecology. With the recent advancement of the single-cell\nRNA-sequencing (RNA-seq), we can potentially describe such a link by\nconstructing network graphs that characterize the similarity of the gene\nexpression profiles of the cell-specific transcriptional programs, and\nanalyzing these graphs systematically using the summary statistics informed by\nthe algebraic topology. We propose the single-cell topological simplicial\nanalysis (scTSA). Applying this approach to the single-cell gene expression\nprofiles from local networks of cells in different developmental stages with\ndifferent outcomes reveals a previously unseen topology of cellular ecology.\nThese networks contain an abundance of cliques of single-cell profiles bound\ninto cavities that guide the emergence of more complicated habitation forms. We\nvisualize these ecological patterns with topological simplicial architectures\nof these networks, compared with the null models. Benchmarked on the\nsingle-cell RNA-seq data of zebrafish embryogenesis spanning 38,731 cells, 25\ncell types and 12 time steps, our approach highlights the gastrulation as the\nmost critical stage, consistent with consensus in developmental biology. As a\nnonlinear, model-independent, and unsupervised framework, our approach can also\nbe applied to tracing multi-scale cell lineage, identifying critical stages, or\ncreating pseudo-time series.",
            "categories": [
                "cs.LG",
                "math.AT",
                "q-bio.GN",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2204.14048v2",
            "date": "2022-04-29 12:46:14+00:00"
        },
        {
            "title": "Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data",
            "authors": [
                "Sophie Peacock",
                "Etai Jacob",
                "Nikolay Burlutskiy"
            ],
            "abstract": "Genomics data such as RNA gene expression, methylation and micro RNA\nexpression are valuable sources of information for various clinical predictive\ntasks. For example, predicting survival outcomes, cancer histology type and\nother patients' related information is possible using not only clinical data\nbut molecular data as well. Moreover, using these data sources together, for\nexample in multitask learning, can boost the performance. However, in practice,\nthere are many missing data points which leads to significantly lower patient\nnumbers when analysing full cases, which in our setting refers to all\nmodalities being present.\n  In this paper we investigate how imputing data with missing values using deep\nlearning coupled with multitask learning can help to reach state-of-the-art\nperformance results using combined genomics modalities, RNA, micro RNA and\nmethylation. We propose a generalised deep imputation method to impute values\nwhere a patient has all modalities present except one. Interestingly enough,\ndeep imputation alone outperforms multitask learning alone for the\nclassification and regression tasks across most combinations of modalities. In\ncontrast, when using all modalities for survival prediction we observe that\nmultitask learning alone outperforms deep imputation alone with statistical\nsignificance (adjusted p-value 0.03). Thus, both approaches are complementary\nwhen optimising performance for downstream predictive tasks.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2204.13705v2",
            "date": "2022-04-28 09:48:15+00:00"
        },
        {
            "title": "RadioPathomics: Multimodal Learning in Non-Small Cell Lung Cancer for Adaptive Radiotherapy",
            "authors": [
                "Matteo Tortora",
                "Ermanno Cordelli",
                "Rosa Sicilia",
                "Lorenzo Nibid",
                "Edy Ippolito",
                "Giuseppe Perrone",
                "Sara Ramella",
                "Paolo Soda"
            ],
            "abstract": "The current cancer treatment practice collects multimodal data, such as\nradiology images, histopathology slides, genomics and clinical data. The\nimportance of these data sources taken individually has fostered the recent\nraise of radiomics and pathomics, i.e. the extraction of quantitative features\nfrom radiology and histopathology images routinely collected to predict\nclinical outcomes or to guide clinical decisions using artificial intelligence\nalgorithms. Nevertheless, how to combine them into a single multimodal\nframework is still an open issue. In this work we therefore develop a\nmultimodal late fusion approach that combines hand-crafted features computed\nfrom radiomics, pathomics and clinical data to predict radiation therapy\ntreatment outcomes for non-small-cell lung cancer patients. Within this\ncontext, we investigate eight different late fusion rules (i.e. product,\nmaximum, minimum, mean, decision template, Dempster-Shafer, majority voting,\nand confidence rule) and two patient-wise aggregation rules leveraging the\nrichness of information given by computer tomography images and whole-slide\nscans. The experiments in leave-one-patient-out cross-validation on an in-house\ncohort of 33 patients show that the proposed multimodal paradigm with an AUC\nequal to $90.9\\%$ outperforms each unimodal approach, suggesting that data\nintegration can advance precision medicine. As a further contribution, we also\ncompare the hand-crafted representations with features automatically computed\nby deep networks, and the late fusion paradigm with early fusion, another\npopular multimodal approach. In both cases, the experiments show that the\nproposed multimodal approach provides the best results.",
            "categories": [
                "cs.LG",
                "cs.CV"
            ],
            "link": "http://arxiv.org/pdf/2204.12423v1",
            "date": "2022-04-26 16:32:52+00:00"
        },
        {
            "title": "Graph Neural Networks for Microbial Genome Recovery",
            "authors": [
                "Andre Lamurias",
                "Alessandro Tibo",
                "Katja Hose",
                "Mads Albertsen",
                "Thomas Dyhre Nielsen"
            ],
            "abstract": "Microbes have a profound impact on our health and environment, but our\nunderstanding of the diversity and function of microbial communities is\nseverely limited. Through DNA sequencing of microbial communities\n(metagenomics), DNA fragments (reads) of the individual microbes can be\nobtained, which through assembly graphs can be combined into long contiguous\nDNA sequences (contigs). Given the complexity of microbial communities, single\ncontig microbial genomes are rarely obtained. Instead, contigs are eventually\nclustered into bins, with each bin ideally making up a full genome. This\nprocess is referred to as metagenomic binning.\n  Current state-of-the-art techniques for metagenomic binning rely only on the\nlocal features for the individual contigs. These techniques therefore fail to\nexploit the similarities between contigs as encoded by the assembly graph, in\nwhich the contigs are organized. In this paper, we propose to use Graph Neural\nNetworks (GNNs) to leverage the assembly graph when learning contig\nrepresentations for metagenomic binning. Our method, VaeG-Bin, combines\nvariational autoencoders for learning latent representations of the individual\ncontigs, with GNNs for refining these representations by taking into account\nthe neighborhood structure of the contigs in the assembly graph. We explore\nseveral types of GNNs and demonstrate that VaeG-Bin recovers more high-quality\ngenomes than other state-of-the-art binners on both simulated and real-world\ndatasets.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2204.12270v1",
            "date": "2022-04-26 12:49:51+00:00"
        },
        {
            "title": "Global Mapping of Gene/Protein Interactions in PubMed Abstracts: A Framework and an Experiment with P53 Interactions",
            "authors": [
                "Xin Li",
                "Hsinchun Chen",
                "Zan Huang",
                "Hua Su",
                "Jesse D. Martinez"
            ],
            "abstract": "Gene/protein interactions provide critical information for a thorough\nunderstanding of cellular processes. Recently, considerable interest and effort\nhas been focused on the construction and analysis of genome-wide gene networks.\nThe large body of biomedical literature is an important source of gene/protein\ninteraction information. Recent advances in text mining tools have made it\npossible to automatically extract such documented interactions from free-text\nliterature. In this paper, we propose a comprehensive framework for\nconstructing and analyzing large-scale gene functional networks based on the\ngene/protein interactions extracted from biomedical literature repositories\nusing text mining tools. Our proposed framework consists of analyses of the\nnetwork topology, network topology-gene function relationship, and temporal\nnetwork evolution to distill valuable information embedded in the gene\nfunctional interactions in literature. We demonstrate the application of the\nproposed framework using a testbed of P53-related PubMed abstracts, which shows\nthat literature-based P53 networks exhibit small-world and scale-free\nproperties. We also found that high degree genes in the literature-based\nnetworks have a high probability of appearing in the manually curated database\nand genes in the same pathway tend to form local clusters in our\nliterature-based networks. Temporal analysis showed that genes interacting with\nmany other genes tend to be involved in a large number of newly discovered\ninteractions.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "cs.SI",
                "stat.AP"
            ],
            "link": "http://arxiv.org/pdf/2204.10476v1",
            "date": "2022-04-22 03:04:19+00:00"
        },
        {
            "title": "Gene Function Prediction with Gene Interaction Networks: A Context Graph Kernel Approach",
            "authors": [
                "Xin Li",
                "Hsinchun Chen",
                "Jiexun Li",
                "Zhu Zhang"
            ],
            "abstract": "Predicting gene functions is a challenge for biologists in the post genomic\nera. Interactions among genes and their products compose networks that can be\nused to infer gene functions. Most previous studies adopt a linkage assumption,\ni.e., they assume that gene interactions indicate functional similarities\nbetween connected genes. In this study, we propose to use a gene's context\ngraph, i.e., the gene interaction network associated with the focal gene, to\ninfer its functions. In a kernel-based machine-learning framework, we design a\ncontext graph kernel to capture the information in context graphs. Our\nexperimental study on a testbed of p53-related genes demonstrates the advantage\nof using indirect gene interactions and shows the empirical superiority of the\nproposed approach over linkage-assumption-based methods, such as the algorithm\nto minimize inconsistent connected genes and diffusion kernels.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "q-bio.QM",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2204.10473v1",
            "date": "2022-04-22 02:54:01+00:00"
        },
        {
            "title": "BASiNETEntropy: an alignment-free method for classification of biological sequences through complex networks and entropy maximization",
            "authors": [
                "Murilo Montanini Breve",
                "Matheus Henrique Pimenta-Zanon",
                "Fabr\u00edcio Martins Lopes"
            ],
            "abstract": "The discovery of nucleic acids and the structure of DNA have brought\nconsiderable advances in the understanding of life. The development of\nnext-generation sequencing technologies has led to a large-scale generation of\ndata, for which computational methods have become essential for analysis and\nknowledge discovery. In particular, RNAs have received much attention because\nof the diversity of their functionalities in the organism and the discoveries\nof different classes with different functions in many biological processes.\nTherefore, the correct identification of RNA sequences is increasingly\nimportant to provide relevant information to understand the functioning of\norganisms. This work addresses this context by presenting a new method for the\nclassification of biological sequences through complex networks and entropy\nmaximization. The maximum entropy principle is proposed to identify the most\ninformative edges about the RNA class, generating a filtered complex network.\nThe proposed method was evaluated in the classification of different RNA\nclasses from 13 species. The proposed method was compared to PLEK, CPC2 and\nBASiNET methods, outperforming all compared methods. BASiNETEntropy classified\nall RNA sequences with high accuracy and low standard deviation in results,\nshowing assertiveness and robustness. The proposed method is implemented in an\nopen source in R language and is freely available at\nhttps://cran.r-project.org/web/packages/BASiNETEntropy.",
            "categories": [
                "q-bio.MN",
                "cs.CE",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2203.15635v1",
            "date": "2022-03-24 14:19:43+00:00"
        },
        {
            "title": "Bioplastic Design using Multitask Deep Neural Networks",
            "authors": [
                "Christopher Kuenneth",
                "Jessica Lalonde",
                "Babetta L. Marrone",
                "Carl N. Iverson",
                "Rampi Ramprasad",
                "Ghanshyam Pilania"
            ],
            "abstract": "Non-degradable plastic waste stays for decades on land and in water,\njeopardizing our environment; yet our modern lifestyle and current technologies\nare impossible to sustain without plastics. Bio-synthesized and biodegradable\nalternatives such as the polymer family of polyhydroxyalkanoates (PHAs) have\nthe potential to replace large portions of the world's plastic supply with\ncradle-to-cradle materials, but their chemical complexity and diversity limit\ntraditional resource-intensive experimentation. In this work, we develop\nmultitask deep neural network property predictors using available experimental\ndata for a diverse set of nearly 23000 homo- and copolymer chemistries. Using\nthe predictors, we identify 14 PHA-based bioplastics from a search space of\nalmost 1.4 million candidates which could serve as potential replacements for\nseven petroleum-based commodity plastics that account for 75% of the world's\nyearly plastic production. We discuss possible synthesis routes for these\nidentified promising materials. The developed multitask polymer property\npredictors are made available as a part of the Polymer Genome project at\nhttps://PolymerGenome.org.",
            "categories": [
                "cond-mat.mtrl-sci",
                "cond-mat.soft",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2203.12033v1",
            "date": "2022-03-22 20:49:13+00:00"
        },
        {
            "title": "Categorical Representation Learning and RG flow operators for algorithmic classifiers",
            "authors": [
                "Artan Sheshmani",
                "Yizhuang You",
                "Wenbo Fu",
                "Ahmadreza Azizi"
            ],
            "abstract": "Following the earlier formalism of the categorical representation learning\n(arXiv:2103.14770) by the first two authors, we discuss the construction of the\n\"RG-flow based categorifier\". Borrowing ideas from theory of renormalization\ngroup flows (RG) in quantum field theory, holographic duality, and hyperbolic\ngeometry, and mixing them with neural ODE's, we construct a new algorithmic\nnatural language processing (NLP) architecture, called the RG-flow categorifier\nor for short the RG categorifier, which is capable of data classification and\ngeneration in all layers. We apply our algorithmic platform to biomedical data\nsets and show its performance in the field of sequence-to-function mapping. In\nparticular we apply the RG categorifier to particular genomic sequences of flu\nviruses and show how our technology is capable of extracting the information\nfrom given genomic sequences, find their hidden symmetries and dominant\nfeatures, classify them and use the trained data to make stochastic prediction\nof new plausible generated sequences associated with new set of viruses which\ncould avoid the human immune system. The content of the current article is part\nof the recent US patent application submitted by first two authors (U.S. Patent\nApplication No.: 63/313.504).",
            "categories": [
                "cs.LG",
                "cond-mat.dis-nn",
                "cs.AI",
                "math.AG",
                "math.CT",
                "math.DG",
                "03B70, 03-04, 03D10, 11Y16"
            ],
            "link": "http://arxiv.org/pdf/2203.07975v1",
            "date": "2022-03-15 15:04:51+00:00"
        },
        {
            "title": "Topological data analysis of truncated contagion maps",
            "authors": [
                "Florian Klimm"
            ],
            "abstract": "The investigation of dynamical processes on networks has been one focus for\nthe study of contagion processes. It has been demonstrated that contagions can\nbe used to obtain information about the embedding of nodes in a Euclidean\nspace. Specifically, one can use the activation times of threshold contagions\nto construct contagion maps as a manifold-learning approach. One drawback of\ncontagion maps is their high computational cost. Here, we demonstrate that a\ntruncation of the threshold contagions may considerably speed up the\nconstruction of contagion maps. Finally, we show that contagion maps may be\nused to find an insightful low-dimensional embedding for single-cell\nRNA-sequencing data in the form of cell-similarity networks and so reveal\nbiological manifolds. Overall, our work makes the use of contagion maps as\nmanifold-learning approaches on empirical network data more viable.",
            "categories": [
                "math.AT",
                "cs.LG",
                "nlin.AO",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2203.01720v2",
            "date": "2022-03-03 14:08:05+00:00"
        },
        {
            "title": "SubOmiEmbed: Self-supervised Representation Learning of Multi-omics Data for Cancer Type Classification",
            "authors": [
                "Sayed Hashim",
                "Muhammad Ali",
                "Karthik Nandakumar",
                "Mohammad Yaqub"
            ],
            "abstract": "For personalized medicines, very crucial intrinsic information is present in\nhigh dimensional omics data which is difficult to capture due to the large\nnumber of molecular features and small number of available samples. Different\ntypes of omics data show various aspects of samples. Integration and analysis\nof multi-omics data give us a broad view of tumours, which can improve clinical\ndecision making. Omics data, mainly DNA methylation and gene expression\nprofiles are usually high dimensional data with a lot of molecular features. In\nrecent years, variational autoencoders (VAE) have been extensively used in\nembedding image and text data into lower dimensional latent spaces. In our\nproject, we extend the idea of using a VAE model for low dimensional latent\nspace extraction with the self-supervised learning technique of feature\nsubsetting. With VAEs, the key idea is to make the model learn meaningful\nrepresentations from different types of omics data, which could then be used\nfor downstream tasks such as cancer type classification. The main goals are to\novercome the curse of dimensionality and integrate methylation and expression\ndata to combine information about different aspects of same tissue samples, and\nhopefully extract biologically relevant features. Our extension involves\ntraining encoder and decoder to reconstruct the data from just a subset of it.\nBy doing this, we force the model to encode most important information in the\nlatent representation. We also added an identity to the subsets so that the\nmodel knows which subset is being fed into it during training and testing. We\nexperimented with our approach and found that SubOmiEmbed produces comparable\nresults to the baseline OmiEmbed with a much smaller network and by using just\na subset of the data. This work can be improved to integrate mutation-based\ngenomic data as well.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2202.01672v1",
            "date": "2022-02-03 16:39:09+00:00"
        },
        {
            "title": "A Multi-modal Fusion Framework Based on Multi-task Correlation Learning for Cancer Prognosis Prediction",
            "authors": [
                "Kaiwen Tan",
                "Weixian Huang",
                "Xiaofeng Liu",
                "Jinlong Hu",
                "Shoubin Dong"
            ],
            "abstract": "Morphological attributes from histopathological images and molecular profiles\nfrom genomic data are important information to drive diagnosis, prognosis, and\ntherapy of cancers. By integrating these heterogeneous but complementary data,\nmany multi-modal methods are proposed to study the complex mechanisms of\ncancers, and most of them achieve comparable or better results from previous\nsingle-modal methods. However, these multi-modal methods are restricted to a\nsingle task (e.g., survival analysis or grade classification), and thus neglect\nthe correlation between different tasks. In this study, we present a\nmulti-modal fusion framework based on multi-task correlation learning\n(MultiCoFusion) for survival analysis and cancer grade classification, which\ncombines the power of multiple modalities and multiple tasks. Specifically, a\npre-trained ResNet-152 and a sparse graph convolutional network (SGCN) are used\nto learn the representations of histopathological images and mRNA expression\ndata respectively. Then these representations are fused by a fully connected\nneural network (FCNN), which is also a multi-task shared network. Finally, the\nresults of survival analysis and cancer grade classification output\nsimultaneously. The framework is trained by an alternate scheme. We\nsystematically evaluate our framework using glioma datasets from The Cancer\nGenome Atlas (TCGA). Results demonstrate that MultiCoFusion learns better\nrepresentations than traditional feature extraction methods. With the help of\nmulti-task alternating learning, even simple multi-modal concatenation can\nachieve better performance than other deep learning and traditional methods.\nMulti-task learning can improve the performance of multiple tasks not just one\nof them, and it is effective in both single-modal and multi-modal data.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ],
            "link": "http://arxiv.org/pdf/2201.10353v1",
            "date": "2022-01-22 15:16:24+00:00"
        },
        {
            "title": "AlphaFold Accelerates Artificial Intelligence Powered Drug Discovery: Efficient Discovery of a Novel Cyclin-dependent Kinase 20 (CDK20) Small Molecule Inhibitor",
            "authors": [
                "Feng Ren",
                "Xiao Ding",
                "Min Zheng",
                "Mikhail Korzinkin",
                "Xin Cai",
                "Wei Zhu",
                "Alexey Mantsyzov",
                "Alex Aliper",
                "Vladimir Aladinskiy",
                "Zhongying Cao",
                "Shanshan Kong",
                "Xi Long",
                "Bonnie Hei Man Liu",
                "Yingtao Liu",
                "Vladimir Naumov",
                "Anastasia Shneyderman",
                "Ivan V. Ozerov",
                "Ju Wang",
                "Frank W. Pun",
                "Alan Aspuru-Guzik",
                "Michael Levitt",
                "Alex Zhavoronkov"
            ],
            "abstract": "The AlphaFold computer program predicted protein structures for the whole\nhuman genome, which has been considered as a remarkable breakthrough both in\nartificial intelligence (AI) application and structural biology. Despite the\nvarying confidence level, these predicted structures still could significantly\ncontribute to structure-based drug design of novel targets, especially the ones\nwith no or limited structural information. In this work, we successfully\napplied AlphaFold in our end-to-end AI-powered drug discovery engines\nconstituted of a biocomputational platform PandaOmics and a generative\nchemistry platform Chemistry42, to identify a first-in-class hit molecule of a\nnovel target without an experimental structure starting from target selection\ntowards hit identification in a cost- and time-efficient manner. PandaOmics\nprovided the targets of interest and Chemistry42 generated the molecules based\non the AlphaFold predicted structure, and the selected molecules were\nsynthesized and tested in biological assays. Through this approach, we\nidentified a small molecule hit compound for CDK20 with a Kd value of 8.9 +/-\n1.6 uM (n = 4) within 30 days from target selection and after only synthesizing\n7 compounds. Based on the available data, the second round of AI-powered\ncompound generation was conducted and through which, a more potent hit\nmolecule, ISM042-2 048, was discovered with a Kd value of 210.0 +/- 42.4 nM (n\n= 2), within 30 days and after synthesizing 6 compounds from the discovery of\nthe first hit ISM042-2-001. To the best of our knowledge, this is the first\nreported small molecule targeting CDK20 and more importantly, this work is the\nfirst demonstration of AlphaFold application in the hit identification process\nin early drug discovery.",
            "categories": [
                "q-bio.BM",
                "cs.AI",
                "cs.LG",
                "q-bio.MN"
            ],
            "link": "http://arxiv.org/pdf/2201.09647v2",
            "date": "2022-01-21 07:35:24+00:00"
        },
        {
            "title": "RepBin: Constraint-based Graph Representation Learning for Metagenomic Binning",
            "authors": [
                "Hansheng Xue",
                "Vijini Mallawaarachchi",
                "Yujia Zhang",
                "Vaibhav Rajan",
                "Yu Lin"
            ],
            "abstract": "Mixed communities of organisms are found in many environments (from the human\ngut to marine ecosystems) and can have profound impact on human health and the\nenvironment. Metagenomics studies the genomic material of such communities\nthrough high-throughput sequencing that yields DNA subsequences for subsequent\nanalysis. A fundamental problem in the standard workflow, called binning, is to\ndiscover clusters, of genomic subsequences, associated with the unknown\nconstituent organisms. Inherent noise in the subsequences, various biological\nconstraints that need to be imposed on them and the skewed cluster size\ndistribution exacerbate the difficulty of this unsupervised learning problem.\nIn this paper, we present a new formulation using a graph where the nodes are\nsubsequences and edges represent homophily information. In addition, we model\nbiological constraints providing heterophilous signal about nodes that cannot\nbe clustered together. We solve the binning problem by developing new\nalgorithms for (i) graph representation learning that preserves both homophily\nrelations and heterophily constraints (ii) constraint-based graph clustering\nmethod that addresses the problems of skewed cluster size distribution.\nExtensive experiments, on real and synthetic datasets, demonstrate that our\napproach, called RepBin, outperforms a wide variety of competing methods. Our\nconstraint-based graph representation learning and clustering methods, that may\nbe useful in other domains as well, advance the state-of-the-art in both\nmetagenomics binning and graph representation learning.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "cs.SI"
            ],
            "link": "http://arxiv.org/pdf/2112.11696v1",
            "date": "2021-12-22 07:01:01+00:00"
        },
        {
            "title": "HampDTI: a heterogeneous graph automatic meta-path learning method for drug-target interaction prediction",
            "authors": [
                "Hongzhun Wang",
                "Feng Huang",
                "Wen Zhang"
            ],
            "abstract": "Motivation: Identifying drug-target interactions (DTIs) is a key step in drug\nrepositioning. In recent years, the accumulation of a large number of genomics\nand pharmacology data has formed mass drug and target related heterogeneous\nnetworks (HNs), which provides new opportunities of developing HN-based\ncomputational models to accurately predict DTIs. The HN implies lots of useful\ninformation about DTIs but also contains irrelevant data, and how to make the\nbest of heterogeneous networks remains a challenge. Results: In this paper, we\npropose a heterogeneous graph automatic meta-path learning based DTI prediction\nmethod (HampDTI). HampDTI automatically learns the important meta-paths between\ndrugs and targets from the HN, and generates meta-path graphs. For each\nmeta-path graph, the features learned from drug molecule graphs and target\nprotein sequences serve as the node attributes, and then a node-type specific\ngraph convolutional network (NSGCN) which efficiently considers node type\ninformation (drugs or targets) is designed to learn embeddings of drugs and\ntargets. Finally, the embeddings from multiple meta-path graphs are combined to\npredict novel DTIs. The experiments on benchmark datasets show that our\nproposed HampDTI achieves superior performance compared with state-of-the-art\nDTI prediction methods. More importantly, HampDTI identifies the important\nmeta-paths for DTI prediction, which could explain how drugs connect with\ntargets in HNs.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.MN"
            ],
            "link": "http://arxiv.org/pdf/2112.08567v1",
            "date": "2021-12-16 02:12:03+00:00"
        },
        {
            "title": "AGMI: Attention-Guided Multi-omics Integration for Drug Response Prediction with Graph Neural Networks",
            "authors": [
                "Ruiwei Feng",
                "Yufeng Xie",
                "Minshan Lai",
                "Danny Z. Chen",
                "Ji Cao",
                "Jian Wu"
            ],
            "abstract": "Accurate drug response prediction (DRP) is a crucial yet challenging task in\nprecision medicine. This paper presents a novel Attention-Guided Multi-omics\nIntegration (AGMI) approach for DRP, which first constructs a Multi-edge Graph\n(MeG) for each cell line, and then aggregates multi-omics features to predict\ndrug response using a novel structure, called Graph edge-aware Network (GeNet).\nFor the first time, our AGMI approach explores gene constraint based\nmulti-omics integration for DRP with the whole-genome using GNNs. Empirical\nexperiments on the CCLE and GDSC datasets show that our AGMI largely\noutperforms state-of-the-art DRP methods by 8.3%--34.2% on four metrics. Our\ndata and code are available at https://github.com/yivan-WYYGDSG/AGMI.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2112.08366v2",
            "date": "2021-12-15 07:42:46+00:00"
        },
        {
            "title": "OmiTrans: generative adversarial networks based omics-to-omics translation framework",
            "authors": [
                "Xiaoyu Zhang",
                "Yike Guo"
            ],
            "abstract": "With the rapid development of high-throughput experimental technologies,\ndifferent types of omics (e.g., genomics, epigenomics, transcriptomics,\nproteomics, and metabolomics) data can be produced from clinical samples. The\ncorrelations between different omics types attracts a lot of research interest,\nwhereas the stduy on genome-wide omcis data translation (i.e, generation and\nprediction of one type of omics data from another type of omics data) is almost\nblank. Generative adversarial networks and the variants are one of the most\nstate-of-the-art deep learning technologies, which have shown great success in\nimage-to-image translation, text-to-image translation, etc. Here we proposed\nOmiTrans, a deep learning framework adopted the idea of generative adversarial\nnetworks to achieve omics-to-omics translation with promising results. OmiTrans\nwas able to faithfully reconstruct gene expression profiles from DNA\nmethylation data with high accuracy and great model generalisation, as\ndemonstrated in the experiments.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2111.13785v1",
            "date": "2021-11-27 00:45:10+00:00"
        },
        {
            "title": "Machine Learning for Genomic Data",
            "authors": [
                "Akankshita Dash"
            ],
            "abstract": "This report explores the application of machine learning techniques on short\ntimeseries gene expression data. Although standard machine learning algorithms\nwork well on longer time-series', they often fail to find meaningful insights\nfrom fewer timepoints. In this report, we explore model-based clustering\ntechniques. We combine popular unsupervised learning techniques like K-Means,\nGaussian Mixture Models, Bayesian Networks, Hidden Markov Models with the\nwell-known Expectation Maximization algorithm. K-Means and Gaussian Mixture\nModels are fairly standard, while Hidden Markov Model and Bayesian Networks\nclustering are more novel ideas that suit time-series gene expression data.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "62F15",
                "G.3"
            ],
            "link": "http://arxiv.org/pdf/2111.08507v1",
            "date": "2021-11-15 14:34:20+00:00"
        },
        {
            "title": "Using Deep Learning Sequence Models to Identify SARS-CoV-2 Divergence",
            "authors": [
                "Yanyi Ding",
                "Zhiyi Kuang",
                "Yuxin Pei",
                "Jeff Tan",
                "Ziyu Zhang",
                "Joseph Konan"
            ],
            "abstract": "SARS-CoV-2 is an upper respiratory system RNA virus that has caused over 3\nmillion deaths and infecting over 150 million worldwide as of May 2021. With\nthousands of strains sequenced to date, SARS-CoV-2 mutations pose significant\nchallenges to scientists on keeping pace with vaccine development and public\nhealth measures. Therefore, an efficient method of identifying the divergence\nof lab samples from patients would greatly aid the documentation of SARS-CoV-2\ngenomics. In this study, we propose a neural network model that leverages\nrecurrent and convolutional units to directly take in amino acid sequences of\nspike proteins and classify corresponding clades. We also compared our model's\nperformance with Bidirectional Encoder Representations from Transformers (BERT)\npre-trained on protein database. Our approach has the potential of providing a\nmore computationally efficient alternative to current homology based\nintra-species differentiation.",
            "categories": [
                "q-bio.QM",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2111.06593v1",
            "date": "2021-11-12 07:52:11+00:00"
        },
        {
            "title": "On minimizers and convolutional filters: a partial justification for the effectiveness of CNNs in categorical sequence analysis",
            "authors": [
                "Yun William Yu"
            ],
            "abstract": "Minimizers and convolutional neural networks (CNNs) are two quite distinct\npopular techniques that have both been employed to analyze categorical\nbiological sequences. At face value, the methods seem entirely dissimilar.\nMinimizers use min-wise hashing on a rolling window to extract a single\nimportant k-mer feature per window. CNNs start with a wide array of randomly\ninitialized convolutional filters, paired with a pooling operation, and then\nmultiple additional neural layers to learn both the filters themselves and how\nthose filters can be used to classify the sequence. In this manuscript, we\ndemonstrate through a careful mathematical analysis of hash function properties\nthat for sequences over a categorical alphabet, random Gaussian initialization\nof convolutional filters with max-pooling is equivalent to choosing a minimizer\nordering such that selected k-mers are (in Hamming distance) far from the\nk-mers within the sequence but close to other minimizers. In empirical\nexperiments, we find that this property manifests as decreased density in\nrepetitive regions, both in simulation and on real human telomeres. This\nprovides a partial explanation for the effectiveness of CNNs in categorical\nsequence analysis.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2111.08452v4",
            "date": "2021-11-09 19:02:04+00:00"
        },
        {
            "title": "High-dimensional multi-trait GWAS by reverse prediction of genotypes",
            "authors": [
                "Muhammad Ammar Malik",
                "Adriaan-Alexander Ludl",
                "Tom Michoel"
            ],
            "abstract": "Multi-trait genome-wide association studies (GWAS) use multi-variate\nstatistical methods to identify associations between genetic variants and\nmultiple correlated traits simultaneously, and have higher statistical power\nthan independent univariate analyses of traits. Reverse regression, where\ngenotypes of genetic variants are regressed on multiple traits simultaneously,\nhas emerged as a promising approach to perform multi-trait GWAS in\nhigh-dimensional settings where the number of traits exceeds the number of\nsamples. We analyzed different machine learning methods (ridge regression,\nnaive Bayes/independent univariate, random forests and support vector machines)\nfor reverse regression in multi-trait GWAS, using genotypes, gene expression\ndata and ground-truth transcriptional regulatory networks from the DREAM5\nSysGen Challenge and from a cross between two yeast strains to evaluate\nmethods. We found that genotype prediction performance, in terms of root mean\nsquared error (RMSE), allowed to distinguish between genomic regions with high\nand low transcriptional activity. Moreover, model feature coefficients\ncorrelated with the strength of association between variants and individual\ntraits, and were predictive of true trans-eQTL target genes, with complementary\nfindings across methods. Code to reproduce the analysis is available at\nhttps://github.com/michoel-lab/Reverse-Pred-GWAS",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "q-bio.QM",
                "stat.ME"
            ],
            "link": "http://arxiv.org/pdf/2111.00108v2",
            "date": "2021-10-29 22:34:35+00:00"
        },
        {
            "title": "Deciphering the Language of Nature: A transformer-based language model for deleterious mutations in proteins",
            "authors": [
                "Theodore Jiang",
                "Li Fang",
                "Kai Wang"
            ],
            "abstract": "Various machine-learning models, including deep neural network models, have\nalready been developed to predict deleteriousness of missense (non-synonymous)\nmutations. Potential improvements to the current state of the art, however, may\nstill benefit from a fresh look at the biological problem using more\nsophisticated self-adaptive machine-learning approaches. Recent advances in the\nnatural language processing field show transformer models-a type of deep neural\nnetwork-to be particularly powerful at modeling sequence information with\ncontext dependence. In this study, we introduce MutFormer, a transformer-based\nmodel for the prediction of deleterious missense mutations, which uses\nreference and mutated protein sequences from the human genome as the primary\nfeatures. MutFormer takes advantage of a combination of self-attention layers\nand convolutional layers to learn both long-range and short-range dependencies\nbetween amino acid mutations in a protein sequence. In this study, we first\npre-trained MutFormer on reference protein sequences and mutated protein\nsequences resulting from common genetic variants observed in human populations.\nWe next examined different fine-tuning methods to successfully apply the model\nto deleteriousness prediction of missense mutations. Finally, we evaluated\nMutFormer's performance on multiple testing data sets. We found that MutFormer\nshowed similar or improved performance over a variety of existing tools,\nincluding those that used conventional machine-learning approaches. We conclude\nthat MutFormer successfully considers sequence features that are not explored\nin previous studies and could potentially complement existing computational\npredictions or empirically generated functional scores to improve our\nunderstanding of disease variants.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2110.14746v4",
            "date": "2021-10-27 20:17:35+00:00"
        },
        {
            "title": "A Precision Diagnostic Framework of Renal Cell Carcinoma on Whole-Slide Images using Deep Learning",
            "authors": [
                "Jialun Wu",
                "Haichuan Zhang",
                "Zeyu Gao",
                "Xinrui Bao",
                "Tieliang Gong",
                "Chunbao Wang",
                "Chen Li"
            ],
            "abstract": "Diagnostic pathology, which is the basis and gold standard of cancer\ndiagnosis, provides essential information on the prognosis of the disease and\nvital evidence for clinical treatment. Tumor region detection, subtype and\ngrade classification are the fundamental diagnostic indicators for renal cell\ncarcinoma (RCC) in whole-slide images (WSIs). However, pathological diagnosis\nis subjective, differences in observation and diagnosis between pathologists is\ncommon in hospitals with inadequate diagnostic capacity. The main challenge for\ndeveloping deep learning based RCC diagnostic system is the lack of large-scale\ndatasets with precise annotations. In this work, we proposed a deep\nlearning-based framework for analyzing histopathological images of patients\nwith renal cell carcinoma, which has the potential to achieve pathologist-level\naccuracy in diagnosis. A deep convolutional neural network (InceptionV3) was\ntrained on the high-quality annotated dataset of The Cancer Genome Atlas (TCGA)\nwhole-slide histopathological image for accurate tumor area detection,\nclassification of RCC subtypes, and ISUP grades classification of clear cell\ncarcinoma subtypes. These results suggest that our framework can help\npathologists in the detection of cancer region and classification of subtypes\nand grades, which could be applied to any cancer type, providing auxiliary\ndiagnosis and promoting clinical consensus.",
            "categories": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2110.13652v1",
            "date": "2021-10-26 12:53:25+00:00"
        },
        {
            "title": "SGEN: Single-cell Sequencing Graph Self-supervised Embedding Network",
            "authors": [
                "Ziyi Liu",
                "Minghui Liao",
                "Fulin luo",
                "Bo Du"
            ],
            "abstract": "Single-cell sequencing has a significant role to explore biological processes\nsuch as embryonic development, cancer evolution, and cell differentiation.\nThese biological properties can be presented by a two-dimensional scatter plot.\nHowever, single-cell sequencing data generally has very high dimensionality.\nTherefore, dimensionality reduction should be used to process the high\ndimensional sequencing data for 2D visualization and subsequent biological\nanalysis. The traditional dimensionality reduction methods, which do not\nconsider the structure characteristics of single-cell sequencing data, are\ndifficult to reveal the data structure in the 2D representation. In this paper,\nwe develop a 2D feature representation method based on graph convolutional\nnetworks (GCN) for the visualization of single-cell data, termed single-cell\nsequencing graph embedding networks (SGEN). This method constructs the graph by\nthe similarity relationship between cells and adopts GCN to analyze the\nneighbor embedding information of samples, which makes the similar cell closer\nto each other on the 2D scatter plot. The results show SGEN achieves obvious 2D\ndistribution and preserves the high-dimensional relationship of different\ncells. Meanwhile, similar cell clusters have spatial continuity rather than\nrelying heavily on random initialization, which can reflect the trajectory of\ncell development in this scatter plot.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2110.09413v1",
            "date": "2021-10-15 13:59:58+00:00"
        },
        {
            "title": "A Field Guide to Scientific XAI: Transparent and Interpretable Deep Learning for Bioinformatics Research",
            "authors": [
                "Thomas P Quinn",
                "Sunil Gupta",
                "Svetha Venkatesh",
                "Vuong Le"
            ],
            "abstract": "Deep learning has become popular because of its potential to achieve high\naccuracy in prediction tasks. However, accuracy is not always the only goal of\nstatistical modelling, especially for models developed as part of scientific\nresearch. Rather, many scientific models are developed to facilitate scientific\ndiscovery, by which we mean to abstract a human-understandable representation\nof the natural world. Unfortunately, the opacity of deep neural networks limit\ntheir role in scientific discovery, creating a new demand for models that are\ntransparently interpretable. This article is a field guide to transparent model\ndesign. It provides a taxonomy of transparent model design concepts, a\npractical workflow for putting design concepts into practice, and a general\ntemplate for reporting design choices. We hope this field guide will help\nresearchers more effectively design transparently interpretable models, and\nthus enable them to use deep learning for scientific discovery.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2110.08253v1",
            "date": "2021-10-13 07:02:58+00:00"
        },
        {
            "title": "SlideGraph+: Whole Slide Image Level Graphs to Predict HER2Status in Breast Cancer",
            "authors": [
                "Wenqi Lu",
                "Michael Toss",
                "Emad Rakha",
                "Nasir Rajpoot",
                "Fayyaz Minhas"
            ],
            "abstract": "Human epidermal growth factor receptor 2 (HER2) is an important prognostic\nand predictive factor which is overexpressed in 15-20% of breast cancer (BCa).\nThe determination of its status is a key clinical decision making step for\nselection of treatment regimen and prognostication. HER2 status is evaluated\nusing transcroptomics or immunohistochemistry (IHC) through situ hybridisation\n(ISH) which require additional costs and tissue burden in addition to\nanalytical variabilities in terms of manual observational biases in scoring. In\nthis study, we propose a novel graph neural network (GNN) based model (termed\nSlideGraph+) to predict HER2 status directly from whole-slide images of routine\nHaematoxylin and Eosin (H&E) slides. The network was trained and tested on\nslides from The Cancer Genome Atlas (TCGA) in addition to two independent test\ndatasets. We demonstrate that the proposed model outperforms the\nstate-of-the-art methods with area under the ROC curve (AUC) values > 0.75 on\nTCGA and 0.8 on independent test sets. Our experiments show that the proposed\napproach can be utilised for case triaging as well as pre-ordering diagnostic\ntests in a diagnostic setting. It can also be used for other weakly supervised\nprediction problems in computational pathology. The SlideGraph+ code is\navailable at https://github.com/wenqi006/SlideGraph.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2110.06042v1",
            "date": "2021-10-12 14:40:15+00:00"
        },
        {
            "title": "Deep neural networks with controlled variable selection for the identification of putative causal genetic variants",
            "authors": [
                "Peyman H. Kassani",
                "Fred Lu",
                "Yann Le Guen",
                "Zihuai He"
            ],
            "abstract": "Deep neural networks (DNN) have been used successfully in many scientific\nproblems for their high prediction accuracy, but their application to genetic\nstudies remains challenging due to their poor interpretability. In this paper,\nwe consider the problem of scalable, robust variable selection in DNN for the\nidentification of putative causal genetic variants in genome sequencing\nstudies. We identified a pronounced randomness in feature selection in DNN due\nto its stochastic nature, which may hinder interpretability and give rise to\nmisleading results. We propose an interpretable neural network model,\nstabilized using ensembling, with controlled variable selection for genetic\nstudies. The merit of the proposed method includes: (1) flexible modelling of\nthe non-linear effect of genetic variants to improve statistical power; (2)\nmultiple knockoffs in the input layer to rigorously control false discovery\nrate; (3) hierarchical layers to substantially reduce the number of weight\nparameters and activations to improve computational efficiency; (4)\nde-randomized feature selection to stabilize identified signals. We evaluated\nthe proposed method in extensive simulation studies and applied it to the\nanalysis of Alzheimer disease genetics. We showed that the proposed method,\nwhen compared to conventional linear and nonlinear methods, can lead to\nsubstantially more discoveries.",
            "categories": [
                "cs.LG",
                "stat.AP",
                "stat.CO",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2109.14719v1",
            "date": "2021-09-29 20:57:48+00:00"
        },
        {
            "title": "Pattern Inversion as a Pattern Recognition Method for Machine Learning",
            "authors": [
                "Alexei Mikhailov",
                "Mikhail Karavay"
            ],
            "abstract": "Artificial neural networks use a lot of coefficients that take a great deal\nof computing power for their adjustment, especially if deep learning networks\nare employed. However, there exist coefficients-free extremely fast\nindexing-based technologies that work, for instance, in Google search engines,\nin genome sequencing, etc. The paper discusses the use of indexing-based\nmethods for pattern recognition. It is shown that for pattern recognition\napplications such indexing methods replace with inverse patterns the fully\ninverted files, which are typically employed in search engines. Not only such\ninversion provide automatic feature extraction, which is a distinguishing mark\nof deep learning, but, unlike deep learning, pattern inversion supports almost\ninstantaneous learning, which is a consequence of absence of coefficients. The\npaper discusses a pattern inversion formalism that makes use on a novel pattern\ntransform and its application for unsupervised instant learning. Examples\ndemonstrate a view-angle independent recognition of three-dimensional objects,\nsuch as cars, against arbitrary background, prediction of remaining useful life\nof aircraft engines, and other applications. In conclusion, it is noted that,\nin neurophysiology, the function of the neocortical mini-column has been widely\ndebated since 1957. This paper hypothesize that, mathematically, the cortical\nmini-column can be described as an inverse pattern, which physically serves as\na connection multiplier expanding associations of inputs with relevant pattern\nclasses.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "cs.NE",
                "C.3; I.2; I.5"
            ],
            "link": "http://arxiv.org/pdf/2108.10242v1",
            "date": "2021-08-15 10:25:51+00:00"
        },
        {
            "title": "TRAPDOOR: Repurposing backdoors to detect dataset bias in machine learning-based genomic analysis",
            "authors": [
                "Esha Sarkar",
                "Michail Maniatakos"
            ],
            "abstract": "Machine Learning (ML) has achieved unprecedented performance in several\napplications including image, speech, text, and data analysis. Use of ML to\nunderstand underlying patterns in gene mutations (genomics) has far-reaching\nresults, not only in overcoming diagnostic pitfalls, but also in designing\ntreatments for life-threatening diseases like cancer. Success and\nsustainability of ML algorithms depends on the quality and diversity of data\ncollected and used for training. Under-representation of groups (ethnic groups,\ngender groups, etc.) in such a dataset can lead to inaccurate predictions for\ncertain groups, which can further exacerbate systemic discrimination issues.\n  In this work, we propose TRAPDOOR, a methodology for identification of biased\ndatasets by repurposing a technique that has been mostly proposed for nefarious\npurposes: Neural network backdoors. We consider a typical collaborative\nlearning setting of the genomics supply chain, where data may come from\nhospitals, collaborative projects, or research institutes to a central cloud\nwithout awareness of bias against a sensitive group. In this context, we\ndevelop a methodology to leak potential bias information of the collective data\nwithout hampering the genuine performance using ML backdooring catered for\ngenomic applications. Using a real-world cancer dataset, we analyze the dataset\nwith the bias that already existed towards white individuals and also\nintroduced biases in datasets artificially, and our experimental result show\nthat TRAPDOOR can detect the presence of dataset bias with 100% accuracy, and\nfurthermore can also extract the extent of bias by recovering the percentage\nwith a small error.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "link": "http://arxiv.org/pdf/2108.10132v2",
            "date": "2021-08-14 17:02:02+00:00"
        },
        {
            "title": "Graph2MDA: a multi-modal variational graph embedding model for predicting microbe-drug associations",
            "authors": [
                "Lei Deng",
                "Yibiao Huang",
                "Xuejun Liu",
                "Hui Liu"
            ],
            "abstract": "Accumulated clinical studies show that microbes living in humans interact\nclosely with human hosts, and get involved in modulating drug efficacy and drug\ntoxicity. Microbes have become novel targets for the development of\nantibacterial agents. Therefore, screening of microbe-drug associations can\nbenefit greatly drug research and development. With the increase of microbial\ngenomic and pharmacological datasets, we are greatly motivated to develop an\neffective computational method to identify new microbe-drug associations. In\nthis paper, we proposed a novel method, Graph2MDA, to predict microbe-drug\nassociations by using variational graph autoencoder (VGAE). We constructed\nmulti-modal attributed graphs based on multiple features of microbes and drugs,\nsuch as molecular structures, microbe genetic sequences, and function\nannotations. Taking as input the multi-modal attribute graphs, VGAE was trained\nto learn the informative and interpretable latent representations of each node\nand the whole graph, and then a deep neural network classifier was used to\npredict microbe-drug associations. The hyperparameter analysis and model\nablation studies showed the sensitivity and robustness of our model. We\nevaluated our method on three independent datasets and the experimental results\nshowed that our proposed method outperformed six existing state-of-the-art\nmethods. We also explored the meaningness of the learned latent representations\nof drugs and found that the drugs show obvious clustering patterns that are\nsignificantly consistent with drug ATC classification. Moreover, we conducted\ncase studies on two microbes and two drugs and found 75\\%-95\\% predicted\nassociations have been reported in PubMed literature. Our extensive performance\nevaluations validated the effectiveness of our proposed method.\\",
            "categories": [
                "q-bio.QM",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2108.06338v1",
            "date": "2021-08-14 07:33:05+00:00"
        },
        {
            "title": "Simple, Fast, and Flexible Framework for Matrix Completion with Infinite Width Neural Networks",
            "authors": [
                "Adityanarayanan Radhakrishnan",
                "George Stefanakis",
                "Mikhail Belkin",
                "Caroline Uhler"
            ],
            "abstract": "Matrix completion problems arise in many applications including\nrecommendation systems, computer vision, and genomics. Increasingly larger\nneural networks have been successful in many of these applications, but at\nconsiderable computational costs. Remarkably, taking the width of a neural\nnetwork to infinity allows for improved computational performance. In this\nwork, we develop an infinite width neural network framework for matrix\ncompletion that is simple, fast, and flexible. Simplicity and speed come from\nthe connection between the infinite width limit of neural networks and kernels\nknown as neural tangent kernels (NTK). In particular, we derive the NTK for\nfully connected and convolutional neural networks for matrix completion. The\nflexibility stems from a feature prior, which allows encoding relationships\nbetween coordinates of the target matrix, akin to semi-supervised learning. The\neffectiveness of our framework is demonstrated through competitive results for\nvirtual drug screening and image inpainting/reconstruction. We also provide an\nimplementation in Python to make our framework accessible on standard hardware\nto a broad audience.",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2108.00131v2",
            "date": "2021-07-31 02:40:50+00:00"
        },
        {
            "title": "Graph Representation Learning on Tissue-Specific Multi-Omics",
            "authors": [
                "Amine Amor",
                "Pietro Lio'",
                "Vikash Singh",
                "Ramon Vi\u00f1as Torn\u00e9",
                "Helena Andres Terre"
            ],
            "abstract": "Combining different modalities of data from human tissues has been critical\nin advancing biomedical research and personalised medical care. In this study,\nwe leverage a graph embedding model (i.e VGAE) to perform link prediction on\ntissue-specific Gene-Gene Interaction (GGI) networks. Through ablation\nexperiments, we prove that the combination of multiple biological modalities\n(i.e multi-omics) leads to powerful embeddings and better link prediction\nperformances. Our evaluation shows that the integration of gene methylation\nprofiles and RNA-sequencing data significantly improves the link prediction\nperformance. Overall, the combination of RNA-sequencing and gene methylation\ndata leads to a link prediction accuracy of 71% on GGI networks. By harnessing\ngraph representation learning on multi-omics data, our work brings novel\ninsights to the current literature on multi-omics integration in\nbioinformatics.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.AP"
            ],
            "link": "http://arxiv.org/pdf/2107.11856v1",
            "date": "2021-07-25 17:38:45+00:00"
        },
        {
            "title": "TargetNet: Functional microRNA Target Prediction with Deep Neural Networks",
            "authors": [
                "Seonwoo Min",
                "Byunghan Lee",
                "Sungroh Yoon"
            ],
            "abstract": "Motivation: MicroRNAs (miRNAs) play pivotal roles in gene expression\nregulation by binding to target sites of messenger RNAs (mRNAs). While\nidentifying functional targets of miRNAs is of utmost importance, their\nprediction remains a great challenge. Previous computational algorithms have\nmajor limitations. They use conservative candidate target site (CTS) selection\ncriteria mainly focusing on canonical site types, rely on laborious and\ntime-consuming manual feature extraction, and do not fully capitalize on the\ninformation underlying miRNA-CTS interactions. Results: In this paper, we\nintroduce TargetNet, a novel deep learning-based algorithm for functional miRNA\ntarget prediction. To address the limitations of previous approaches, TargetNet\nhas three key components: (1) relaxed CTS selection criteria accommodating\nirregularities in the seed region, (2) a novel miRNA-CTS sequence encoding\nscheme incorporating extended seed region alignments, and (3) a deep residual\nnetwork-based prediction model. The proposed model was trained with miRNA-CTS\npair datasets and evaluated with miRNA-mRNA pair datasets. TargetNet advances\nthe previous state-of-the-art algorithms used in functional miRNA target\nclassification. Furthermore, it demonstrates great potential for distinguishing\nhigh-functional miRNA targets.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2107.11381v2",
            "date": "2021-07-23 07:31:23+00:00"
        },
        {
            "title": "Learning complex dependency structure of gene regulatory networks from high dimensional micro-array data with Gaussian Bayesian networks",
            "authors": [
                "Catharina Elisabeth Graafland",
                "Jos\u00e9 Manuel Guti\u00e9rrez"
            ],
            "abstract": "Gene expression datasets consist of thousand of genes with relatively small\nsamplesizes (i.e. are large-$p$-small-$n$). Moreover, dependencies of various\norders co-exist in the datasets. In the Undirected probabilistic Graphical\nModel (UGM) framework the Glasso algorithm has been proposed to deal with high\ndimensional micro-array datasets forcing sparsity. Also, modifications of the\ndefault Glasso algorithm are developed to overcome the problem of complex\ninteraction structure. In this work we advocate the use of a simple score-based\nHill Climbing algorithm (HC) that learns Gaussian Bayesian Networks (BNs)\nleaning on Directed Acyclic Graphs (DAGs). We compare HC with Glasso and its\nmodifications in the UGM framework on their capability to reconstruct GRNs from\nmicro-array data belonging to the Escherichia Coli genome. We benefit from the\nanalytical properties of the Joint Probability Density (JPD) function on which\nboth directed and undirected PGMs build to convert DAGs to UGMs.\n  We conclude that dependencies in complex data are learned best by the HC\nalgorithm, presenting them most accurately and efficiently, simultaneously\nmodelling strong local and weaker but significant global connections coexisting\nin the gene expression dataset. The HC algorithm adapts intrinsically to the\ncomplex dependency structure of the dataset, without forcing a specific\nstructure in advance. On the contrary, Glasso and modifications model\nunnecessary dependencies at the expense of the probabilistic information in the\nnetwork and of a structural bias in the JPD function that can only be relieved\nincluding many parameters.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2106.15365v2",
            "date": "2021-06-28 15:04:35+00:00"
        },
        {
            "title": "A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection",
            "authors": [
                "Jie Ren",
                "Stanislav Fort",
                "Jeremiah Liu",
                "Abhijit Guha Roy",
                "Shreyas Padhy",
                "Balaji Lakshminarayanan"
            ],
            "abstract": "Mahalanobis distance (MD) is a simple and popular post-processing method for\ndetecting out-of-distribution (OOD) inputs in neural networks. We analyze its\nfailure modes for near-OOD detection and propose a simple fix called relative\nMahalanobis distance (RMD) which improves performance and is more robust to\nhyperparameter choice. On a wide selection of challenging vision, language, and\nbiology OOD benchmarks (CIFAR-100 vs CIFAR-10, CLINC OOD intent detection,\nGenomics OOD), we show that RMD meaningfully improves upon MD performance (by\nup to 15% AUROC on genomics OOD).",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2106.09022v1",
            "date": "2021-06-16 20:43:56+00:00"
        },
        {
            "title": "Learning-based Support Estimation in Sublinear Time",
            "authors": [
                "Talya Eden",
                "Piotr Indyk",
                "Shyam Narayanan",
                "Ronitt Rubinfeld",
                "Sandeep Silwal",
                "Tal Wagner"
            ],
            "abstract": "We consider the problem of estimating the number of distinct elements in a\nlarge data set (or, equivalently, the support size of the distribution induced\nby the data set) from a random sample of its elements. The problem occurs in\nmany applications, including biology, genomics, computer systems and\nlinguistics. A line of research spanning the last decade resulted in algorithms\nthat estimate the support up to $ \\pm \\varepsilon n$ from a sample of size\n$O(\\log^2(1/\\varepsilon) \\cdot n/\\log n)$, where $n$ is the data set size.\nUnfortunately, this bound is known to be tight, limiting further improvements\nto the complexity of this problem. In this paper we consider estimation\nalgorithms augmented with a machine-learning-based predictor that, given any\nelement, returns an estimation of its frequency. We show that if the predictor\nis correct up to a constant approximation factor, then the sample complexity\ncan be reduced significantly, to \\[ \\ \\log (1/\\varepsilon) \\cdot\nn^{1-\\Theta(1/\\log(1/\\varepsilon))}. \\] We evaluate the proposed algorithms on\na collection of data sets, using the neural-network based estimators from {Hsu\net al, ICLR'19} as predictors. Our experiments demonstrate substantial (up to\n3x) improvements in the estimation accuracy compared to the state of the art\nalgorithm.",
            "categories": [
                "cs.LG",
                "cs.DS",
                "math.ST",
                "stat.TH"
            ],
            "link": "http://arxiv.org/pdf/2106.08396v1",
            "date": "2021-06-15 19:53:12+00:00"
        },
        {
            "title": "Principled Hyperedge Prediction with Structural Spectral Features and Neural Networks",
            "authors": [
                "Changlin Wan",
                "Muhan Zhang",
                "Wei Hao",
                "Sha Cao",
                "Pan Li",
                "Chi Zhang"
            ],
            "abstract": "Hypergraph offers a framework to depict the multilateral relationships in\nreal-world complex data. Predicting higher-order relationships, i.e hyperedge,\nbecomes a fundamental problem for the full understanding of complicated\ninteractions. The development of graph neural network (GNN) has greatly\nadvanced the analysis of ordinary graphs with pair-wise relations. However,\nthese methods could not be easily extended to the case of hypergraph. In this\npaper, we generalize the challenges of GNN in representing higher-order data in\nprinciple, which are edge- and node-level ambiguities. To overcome the\nchallenges, we present SNALS that utilizes bipartite graph neural network with\nstructural features to collectively tackle the two ambiguity issues. SNALS\ncaptures the joint interactions of a hyperedge by its local environment, which\nis retrieved by collecting the spectrum information of their connections. As a\nresult, SNALS achieves nearly 30% performance increase compared with most\nrecent GNN-based models. In addition, we applied SNALS to predict genetic\nhigher-order interactions on 3D genome organization data. SNALS showed\nconsistently high prediction accuracy across different chromosomes, and\ngenerated novel findings on 4-way gene interaction, which is further validated\nby existing literature.",
            "categories": [
                "cs.SI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2106.04292v4",
            "date": "2021-06-08 12:43:17+00:00"
        },
        {
            "title": "Exploring the Limits of Out-of-Distribution Detection",
            "authors": [
                "Stanislav Fort",
                "Jie Ren",
                "Balaji Lakshminarayanan"
            ],
            "abstract": "Near out-of-distribution detection (OOD) is a major challenge for deep neural\nnetworks. We demonstrate that large-scale pre-trained transformers can\nsignificantly improve the state-of-the-art (SOTA) on a range of near OOD tasks\nacross different data modalities. For instance, on CIFAR-100 vs CIFAR-10 OOD\ndetection, we improve the AUROC from 85% (current SOTA) to more than 96% using\nVision Transformers pre-trained on ImageNet-21k. On a challenging genomics OOD\ndetection benchmark, we improve the AUROC from 66% to 77% using transformers\nand unsupervised pre-training. To further improve performance, we explore the\nfew-shot outlier exposure setting where a few examples from outlier classes may\nbe available; we show that pre-trained transformers are particularly\nwell-suited for outlier exposure, and that the AUROC of OOD detection on\nCIFAR-100 vs CIFAR-10 can be improved to 98.7% with just 1 image per OOD class,\nand 99.46% with 10 images per OOD class. For multi-modal image-text pre-trained\ntransformers such as CLIP, we explore a new way of using just the names of\noutlier classes as a sole source of information without any accompanying\nimages, and show that this outperforms previous SOTA on standard vision OOD\nbenchmark tasks.",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2106.03004v3",
            "date": "2021-06-06 01:45:11+00:00"
        },
        {
            "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training",
            "authors": [
                "Gowthami Somepalli",
                "Micah Goldblum",
                "Avi Schwarzschild",
                "C. Bayan Bruss",
                "Tom Goldstein"
            ],
            "abstract": "Tabular data underpins numerous high-impact applications of machine learning\nfrom fraud detection to genomics and healthcare. Classical approaches to\nsolving tabular problems, such as gradient boosting and random forests, are\nwidely used by practitioners. However, recent deep learning methods have\nachieved a degree of performance competitive with popular techniques. We devise\na hybrid deep learning approach to solving tabular data problems. Our method,\nSAINT, performs attention over both rows and columns, and it includes an\nenhanced embedding method. We also study a new contrastive self-supervised\npre-training method for use when labels are scarce. SAINT consistently improves\nperformance over previous deep learning methods, and it even outperforms\ngradient boosting methods, including XGBoost, CatBoost, and LightGBM, on\naverage over a variety of benchmark tasks.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2106.01342v1",
            "date": "2021-06-02 17:51:05+00:00"
        },
        {
            "title": "DNA-GCN: Graph convolutional networks for predicting DNA-protein binding",
            "authors": [
                "Yuhang Guo",
                "Xiao Luo",
                "Liang Chen",
                "Minghua Deng"
            ],
            "abstract": "Predicting DNA-protein binding is an important and classic problem in\nbioinformatics. Convolutional neural networks have outperformed conventional\nmethods in modeling the sequence specificity of DNA-protein binding. However,\nnone of the studies has utilized graph convolutional networks for motif\ninference. In this work, we propose to use graph convolutional networks for\nmotif inference. We build a sequence k-mer graph for the whole dataset based on\nk-mer co-occurrence and k-mer sequence relationship and then learn DNA Graph\nConvolutional Network (DNA-GCN) for the whole dataset. Our DNA-GCN is\ninitialized with a one-hot representation for all nodes, and it then jointly\nlearns the embeddings for both k-mers and sequences, as supervised by the known\nlabels of sequences. We evaluate our model on 50 datasets from ENCODE. DNA-GCN\nshows its competitive performance compared with the baseline model. Besides, we\nanalyze our model and design several different architectures to help fit\ndifferent datasets.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2106.01836v1",
            "date": "2021-06-02 07:36:11+00:00"
        },
        {
            "title": "Predicting the hosts of prokaryotic viruses using GCN-based semi-supervised learning",
            "authors": [
                "Jiayu Shang",
                "Yanni Sun"
            ],
            "abstract": "Background: Prokaryotic viruses, which infect bacteria and archaea, are the\nmost abundant and diverse biological entities in the biosphere. To understand\ntheir regulatory roles in various ecosystems and to harness the potential of\nbacteriophages for use in therapy, more knowledge of viral-host relationships\nis required. High-throughput sequencing and its application to the microbiome\nhave offered new opportunities for computational approaches for predicting\nwhich hosts particular viruses can infect. However, there are two main\nchallenges for computational host prediction. First, the empirically known\nvirus-host relationships are very limited. Second, although sequence similarity\nbetween viruses and their prokaryote hosts have been used as a major feature\nfor host prediction, the alignment is either missing or ambiguous in many\ncases. Thus, there is still a need to improve the accuracy of host prediction.\nResults: In this work, we present a semi-supervised learning model, named\nHostG, to conduct host prediction for novel viruses. We construct a knowledge\ngraph by utilizing both virus-virus protein similarity and virus-host DNA\nsequence similarity. Then graph convolutional network (GCN) is adopted to\nexploit viruses with or without known hosts in training to enhance the learning\nability. During the GCN training, we minimize the expected calibrated error\n(ECE) to ensure the confidence of the predictions. We tested HostG on both\nsimulated and real sequencing data and compared its performance with other\nstate-of-the-art methods specifcally designed for virus host classification\n(VHM-net, WIsH, PHP, HoPhage, RaFAH, vHULK, and VPF-Class). Conclusion: HostG\noutperforms other popular methods, demonstrating the efficacy of using a\nGCN-based semi-supervised learning approach. A particular advantage of HostG is\nits ability to predict hosts from new taxa.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2105.13570v3",
            "date": "2021-05-28 03:29:31+00:00"
        },
        {
            "title": "XOmiVAE: an interpretable deep learning model for cancer classification using high-dimensional omics data",
            "authors": [
                "Eloise Withnell",
                "Xiaoyu Zhang",
                "Kai Sun",
                "Yike Guo"
            ],
            "abstract": "The lack of explainability is one of the most prominent disadvantages of deep\nlearning applications in omics. This \"black box\" problem can undermine the\ncredibility and limit the practical implementation of biomedical deep learning\nmodels. Here we present XOmiVAE, a variational autoencoder (VAE) based\ninterpretable deep learning model for cancer classification using\nhigh-dimensional omics data. XOmiVAE is capable of revealing the contribution\nof each gene and latent dimension for each classification prediction, and the\ncorrelation between each gene and each latent dimension. It is also\ndemonstrated that XOmiVAE can explain not only the supervised classification\nbut the unsupervised clustering results from the deep learning network. To the\nbest of our knowledge, XOmiVAE is one of the first activation level-based\ninterpretable deep learning models explaining novel clusters generated by VAE.\nThe explainable results generated by XOmiVAE were validated by both the\nperformance of downstream tasks and the biomedical knowledge. In our\nexperiments, XOmiVAE explanations of deep learning based cancer classification\nand clustering aligned with current domain knowledge including biological\nannotation and academic literature, which shows great potential for novel\nbiomedical knowledge discovery from deep learning models.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2105.12807v2",
            "date": "2021-05-26 19:55:12+00:00"
        },
        {
            "title": "Comparison of machine learning and deep learning techniques in promoter prediction across diverse species",
            "authors": [
                "Nikita Bhandari",
                "Satyajeet Khare",
                "Rahee Walambe",
                "Ketan Kotecha"
            ],
            "abstract": "Gene promoters are the key DNA regulatory elements positioned around the\ntranscription start sites and are responsible for regulating gene transcription\nprocess. Various alignment-based, signal-based and content-based approaches are\nreported for the prediction of promoters. However, since all promoter sequences\ndo not show explicit features, the prediction performance of these techniques\nis poor. Therefore, many machine learning and deep learning models have been\nproposed for promoter prediction. In this work, we studied methods for vector\nencoding and promoter classification using genome sequences of three distinct\nhigher eukaryotes viz. yeast (Saccharomyces cerevisiae), A. thaliana (plant)\nand human (Homo sapiens). We compared one-hot vector encoding method with\nfrequency-based tokenization (FBT) for data pre-processing on 1-D Convolutional\nNeural Network (CNN) model. We found that FBT gives a shorter input dimension\nreducing the training time without affecting the sensitivity and specificity of\nclassification. We employed the deep learning techniques, mainly CNN and\nrecurrent neural network with Long Short Term Memory (LSTM) and random forest\n(RF) classifier for promoter classification at k-mer sizes of 2, 4 and 8. We\nfound CNN to be superior in classification of promoters from non-promoter\nsequences (binary classification) as well as species-specific classification of\npromoter sequences (multiclass classification). In summary, the contribution of\nthis work lies in the use of synthetic shuffled negative dataset and\nfrequency-based tokenization for pre-processing. This study provides a\ncomprehensive and generic framework for classification tasks in genomic\napplications and can be extended to various classification problems.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2105.07659v1",
            "date": "2021-05-17 08:15:41+00:00"
        },
        {
            "title": "Dynamic Pooling Improves Nanopore Base Calling Accuracy",
            "authors": [
                "Vladim\u00edr Bo\u017ea",
                "Peter Pere\u0161\u00edni",
                "Bro\u0148a Brejov\u00e1",
                "Tom\u00e1\u0161 Vina\u0159"
            ],
            "abstract": "In nanopore sequencing, electrical signal is measured as DNA molecules pass\nthrough the sequencing pores. Translating these signals into DNA bases (base\ncalling) is a highly non-trivial task, and its quality has a large impact on\nthe sequencing accuracy. The most successful nanopore base callers to date use\nconvolutional neural networks (CNN) to accomplish the task.\n  Convolutional layers in CNNs are typically composed of filters with constant\nwindow size, performing best in analysis of signals with uniform speed.\nHowever, the speed of nanopore sequencing varies greatly both within reads and\nbetween sequencing runs. Here, we present dynamic pooling, a novel neural\nnetwork component, which addresses this problem by adaptively adjusting the\npooling ratio. To demonstrate the usefulness of dynamic pooling, we developed\ntwo base callers: Heron and Osprey. Heron improves the accuracy beyond the\nexperimental high-accuracy base caller Bonito developed by Oxford Nanopore.\nOsprey is a fast base caller that can compete in accuracy with Guppy\nhigh-accuracy mode, but does not require GPU acceleration and achieves a near\nreal-time speed on common desktop CPUs.\n  Availability: https://github.com/fmfi-compbio/osprey,\nhttps://github.com/fmfi-compbio/heron\n  Keywords: nanopore sequencing, base calling, convolutional neural networks,\npooling",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2105.07520v1",
            "date": "2021-05-16 21:39:17+00:00"
        },
        {
            "title": "Mosaic Flows: A Transferable Deep Learning Framework for Solving PDEs on Unseen Domains",
            "authors": [
                "Hengjie Wang",
                "Robert Planas",
                "Aparna Chandramowlishwaran",
                "Ramin Bostanabad"
            ],
            "abstract": "Physics-informed neural networks (PINNs) are increasingly employed to\nreplace/augment traditional numerical methods in solving partial differential\nequations (PDEs). While state-of-the-art PINNs have many attractive features,\nthey approximate a specific realization of a PDE system and hence are\nproblem-specific. That is, the model needs to be re-trained each time the\nboundary conditions (BCs) and domain shape/size change. This limitation\nprohibits the application of PINNs to realistic or large-scale engineering\nproblems especially since the costs and efforts associated with their training\nare considerable. We introduce a transferable framework for solving boundary\nvalue problems (BVPs) via deep neural networks which can be trained once and\nused forever for various unseen domains and BCs. We first introduce genomic\nflow network(GFNet), a neural network that can infer the solution of a BVP\nacross arbitrary BCson a small square domain called genome. Then, we proposed\nmosaic flow(MF) predictor, a novel iterative algorithm that assembles the\nGFNet's inferences for BVPs on large domains with unseen sizes/shapes and BCs\nwhile preserving the spatial regularity of the solution. We demonstrate that\nour framework can estimate the solution of Laplace and Navier-Stokes equations\nin domains of unseen shapes and BCs that are, respectively, 1200 and 12 times\nlarger than the training domains. Since our framework eliminates the need to\nre-train models for unseen domains and BCs, it demonstrates up to 3\norders-of-magnitude speedups compared to the state-of-the-art.",
            "categories": [
                "cs.LG",
                "cs.PF",
                "physics.comp-ph",
                "I.2.6"
            ],
            "link": "http://arxiv.org/pdf/2104.10873v2",
            "date": "2021-04-22 05:20:27+00:00"
        },
        {
            "title": "Efficient and Generic 1D Dilated Convolution Layer for Deep Learning",
            "authors": [
                "Narendra Chaudhary",
                "Sanchit Misra",
                "Dhiraj Kalamkar",
                "Alexander Heinecke",
                "Evangelos Georganas",
                "Barukh Ziv",
                "Menachem Adelman",
                "Bharat Kaul"
            ],
            "abstract": "Convolutional neural networks (CNNs) have found many applications in tasks\ninvolving two-dimensional (2D) data, such as image classification and image\nprocessing. Therefore, 2D convolution layers have been heavily optimized on\nCPUs and GPUs. However, in many applications - for example genomics and speech\nrecognition, the data can be one-dimensional (1D). Such applications can\nbenefit from optimized 1D convolution layers. In this work, we introduce our\nefficient implementation of a generic 1D convolution layer covering a wide\nrange of parameters. It is optimized for x86 CPU architectures, in particular,\nfor architectures containing Intel AVX-512 and AVX-512 BFloat16 instructions.\nWe use the LIBXSMM library's batch-reduce General Matrix Multiplication\n(BRGEMM) kernel for FP32 and BFloat16 precision. We demonstrate that our\nimplementation can achieve up to 80% efficiency on Intel Xeon Cascade Lake and\nCooper Lake CPUs. Additionally, we show the generalization capability of our\nBRGEMM based approach by achieving high efficiency across a range of\nparameters. We consistently achieve higher efficiency than the 1D convolution\nlayer with Intel oneDNN library backend for varying input tensor widths, filter\nwidths, number of channels, filters, and dilation parameters. Finally, we\ndemonstrate the performance of our optimized 1D convolution layer by utilizing\nit in the end-to-end neural network training with real genomics datasets and\nachieve up to 6.86x speedup over the oneDNN library-based implementation on\nCascade Lake CPUs. We also demonstrate the scaling with 16 sockets of\nCascade/Cooper Lake CPUs and achieve significant speedup over eight V100 GPUs\nusing a similar power envelop. In the end-to-end training, we get a speedup of\n1.41x on Cascade Lake with FP32, 1.57x on Cooper Lake with FP32, and 2.27x on\nCooper Lake with BFloat16 over eight V100 GPUs with FP32.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ],
            "link": "http://arxiv.org/pdf/2104.08002v1",
            "date": "2021-04-16 09:54:30+00:00"
        },
        {
            "title": "Graph Representation Learning in Biomedicine",
            "authors": [
                "Michelle M. Li",
                "Kexin Huang",
                "Marinka Zitnik"
            ],
            "abstract": "Biomedical networks (or graphs) are universal descriptors for systems of\ninteracting elements, from molecular interactions and disease co-morbidity to\nhealthcare systems and scientific knowledge. Advances in artificial\nintelligence, specifically deep learning, have enabled us to model, analyze,\nand learn with such networked data. In this review, we put forward an\nobservation that long-standing principles of systems biology and medicine --\nwhile often unspoken in machine learning research -- provide the conceptual\ngrounding for representation learning on graphs, explain its current successes\nand limitations, and even inform future advancements. We synthesize a spectrum\nof algorithmic approaches that, at their core, leverage graph topology to embed\nnetworks into compact vector spaces. We also capture the breadth of ways in\nwhich representation learning has dramatically improved the state-of-the-art in\nbiomedical machine learning. Exemplary domains covered include identifying\nvariants underlying complex traits, disentangling behaviors of single cells and\ntheir effects on health, assisting in diagnosis and treatment of patients, and\ndeveloping safe and effective medicines.",
            "categories": [
                "cs.LG",
                "cs.SI",
                "q-bio.BM",
                "q-bio.GN",
                "q-bio.MN"
            ],
            "link": "http://arxiv.org/pdf/2104.04883v3",
            "date": "2021-04-11 00:20:00+00:00"
        },
        {
            "title": "Meta-Learning Bidirectional Update Rules",
            "authors": [
                "Mark Sandler",
                "Max Vladymyrov",
                "Andrey Zhmoginov",
                "Nolan Miller",
                "Andrew Jackson",
                "Tom Madams",
                "Blaise Aguera y Arcas"
            ],
            "abstract": "In this paper, we introduce a new type of generalized neural network where\nneurons and synapses maintain multiple states. We show that classical\ngradient-based backpropagation in neural networks can be seen as a special case\nof a two-state network where one state is used for activations and another for\ngradients, with update rules derived from the chain rule. In our generalized\nframework, networks have neither explicit notion of nor ever receive gradients.\nThe synapses and neurons are updated using a bidirectional Hebb-style update\nrule parameterized by a shared low-dimensional \"genome\". We show that such\ngenomes can be meta-learned from scratch, using either conventional\noptimization techniques, or evolutionary strategies, such as CMA-ES. Resulting\nupdate rules generalize to unseen tasks and train faster than gradient descent\nbased optimizers for several standard computer vision and synthetic tasks.",
            "categories": [
                "cs.LG",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/2104.04657v2",
            "date": "2021-04-10 00:56:35+00:00"
        },
        {
            "title": "Bio-JOIE: Joint Representation Learning of Biological Knowledge Bases",
            "authors": [
                "Junheng Hao",
                "Chelsea Ju",
                "Muhao Chen",
                "Yizhou Sun",
                "Carlo Zaniolo",
                "Wei Wang"
            ],
            "abstract": "The widespread of Coronavirus has led to a worldwide pandemic with a high\nmortality rate. Currently, the knowledge accumulated from different studies\nabout this virus is very limited. Leveraging a wide-range of biological\nknowledge, such as gene ontology and protein-protein interaction (PPI) networks\nfrom other closely related species presents a vital approach to infer the\nmolecular impact of a new species. In this paper, we propose the transferred\nmulti-relational embedding model Bio-JOIE to capture the knowledge of gene\nontology and PPI networks, which demonstrates superb capability in modeling the\nSARS-CoV-2-human protein interactions. Bio-JOIE jointly trains two model\ncomponents. The knowledge model encodes the relational facts from the protein\nand GO domains into separated embedding spaces, using a hierarchy-aware\nencoding technique employed for the GO terms. On top of that, the transfer\nmodel learns a non-linear transformation to transfer the knowledge of PPIs and\ngene ontology annotations across their embedding spaces. By leveraging only\nstructured knowledge, Bio-JOIE significantly outperforms existing\nstate-of-the-art methods in PPI type prediction on multiple species.\nFurthermore, we also demonstrate the potential of leveraging the learned\nrepresentations on clustering proteins with enzymatic function into enzyme\ncommission families. Finally, we show that Bio-JOIE can accurately identify\nPPIs between the SARS-CoV-2 proteins and human proteins, providing valuable\ninsights for advancing research on this new disease.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "q-bio.BM",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2103.04283v1",
            "date": "2021-03-07 07:06:53+00:00"
        },
        {
            "title": "RNA Alternative Splicing Prediction with Discrete Compositional Energy Network",
            "authors": [
                "Alvin Chan",
                "Anna Korsakova",
                "Yew-Soon Ong",
                "Fernaldo Richtia Winnerdy",
                "Kah Wai Lim",
                "Anh Tuan Phan"
            ],
            "abstract": "A single gene can encode for different protein versions through a process\ncalled alternative splicing. Since proteins play major roles in cellular\nfunctions, aberrant splicing profiles can result in a variety of diseases,\nincluding cancers. Alternative splicing is determined by the gene's primary\nsequence and other regulatory factors such as RNA-binding protein levels. With\nthese as input, we formulate the prediction of RNA splicing as a regression\ntask and build a new training dataset (CAPD) to benchmark learned models. We\npropose discrete compositional energy network (DCEN) which leverages the\nhierarchical relationships between splice sites, junctions and transcripts to\napproach this task. In the case of alternative splicing prediction, DCEN models\nmRNA transcript probabilities through its constituent splice junctions' energy\nvalues. These transcript probabilities are subsequently mapped to relative\nabundance values of key nucleotides and trained with ground-truth experimental\nmeasurements. Through our experiments on CAPD, we show that DCEN outperforms\nbaselines and ablation variants.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2103.04246v1",
            "date": "2021-03-07 03:15:10+00:00"
        },
        {
            "title": "Bacteriophage classification for assembled contigs using Graph Convolutional Network",
            "authors": [
                "Jiayu Shang",
                "Jingzhe Jiang",
                "Yanni Sun"
            ],
            "abstract": "Motivation: Bacteriophages (aka phages), which mainly infect bacteria, play\nkey roles in the biology of microbes. As the most abundant biological entities\non the planet, the number of discovered phages is only the tip of the iceberg.\nRecently, many new phages have been revealed using high throughput sequencing,\nparticularly metagenomic sequencing. Compared to the fast accumulation of\nphage-like sequences, there is a serious lag in taxonomic classification of\nphages. High diversity, abundance, and limited known phages pose great\nchallenges for taxonomic analysis. In particular, alignment-based tools have\ndifficulty in classifying fast accumulating contigs assembled from metagenomic\ndata. Results: In this work, we present a novel semi-supervised learning model,\nnamed PhaGCN, to conduct taxonomic classification for phage contigs. In this\nlearning model, we construct a knowledge graph by combining the DNA sequence\nfeatures learned by convolutional neural network (CNN) and protein sequence\nsimilarity gained from gene-sharing network. Then we apply graph convolutional\nnetwork (GCN) to utilize both the labeled and unlabeled samples in training to\nenhance the learning ability. We tested PhaGCN on both simulated and real\nsequencing data. The results clearly show that our method competes favorably\nagainst available phage classification tools.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2102.03746v2",
            "date": "2021-02-07 08:58:35+00:00"
        },
        {
            "title": "Motif Identification using CNN-based Pairwise Subsequence Alignment Score Prediction",
            "authors": [
                "Ethan Jacob Moyer",
                "Anup Das"
            ],
            "abstract": "A common problem in bioinformatics is related to identifying gene regulatory\nregions marked by relatively high frequencies of motifs, or deoxyribonucleic\nacid sequences that often code for transcription and enhancer proteins.\nPredicting alignment scores between subsequence k-mers and a given motif\nenables the identification of candidate regulatory regions in a gene, which\ncorrespond to the transcription of these proteins. We propose a one-dimensional\n(1-D) Convolution Neural Network trained on k-mer formatted sequences\ninterspaced with the given motif pattern to predict pairwise alignment scores\nbetween the consensus motif and subsequence k-mers. Our model consists of\nfifteen layers with three rounds of a one-dimensional convolution layer, a\nbatch normalization layer, a dense layer, and a 1-D maximum pooling layer. We\ntrain the model using mean squared error loss on four different data sets each\nwith a different motif pattern randomly inserted in DNA sequences: the first\nthree data sets have zero, one, and two mutations applied on each inserted\nmotif, and the fourth data set represents the inserted motif as a\nposition-specific probability matrix. We use a novel proposed metric in order\nto evaluate the model's performance, $S_{\\alpha}$, which is based on the\nJaccard Index. We use 10-fold cross validation to evaluate out model. Using\n$S_{\\alpha}$, we measure the accuracy of the model by identifying the 15\nhighest-scoring 15-mer indices of the predicted scores that agree with that of\nthe actual scores within a selected $\\alpha$ region. For the best performing\ndata set, our results indicate on average 99.3% of the top 15 motifs were\nidentified correctly within a one base pair stride ($\\alpha = 1$) in the out of\nsample data. To the best of our knowledge, this is a novel approach that\nillustrates how data formatted in an intelligent way can be extrapolated using\nmachine learning.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2101.08385v1",
            "date": "2021-01-21 01:27:42+00:00"
        },
        {
            "title": "A Tutorial on the Mathematical Model of Single Cell Variational Inference",
            "authors": [
                "Songting Shi"
            ],
            "abstract": "As the large amount of sequencing data accumulated in past decades and it is\nstill accumulating, we need to handle the more and more sequencing data. As the\nfast development of the computing technologies, we now can handle a large\namount of data by a reasonable of time using the neural network based model.\nThis tutorial will introduce the the mathematical model of the single cell\nvariational inference (scVI), which use the variational auto-encoder (building\non the neural networks) to learn the distribution of the data to gain insights.\nIt was written for beginners in the simple and intuitive way with many\ndeduction details to encourage more researchers into this field.",
            "categories": [
                "q-bio.OT",
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2101.00650v1",
            "date": "2021-01-03 16:02:36+00:00"
        },
        {
            "title": "Deep Unsupervised Identification of Selected SNPs between Adapted Populations on Pool-seq Data",
            "authors": [
                "Julia Siekiera",
                "Stefan Kramer"
            ],
            "abstract": "The exploration of selected single nucleotide polymorphisms (SNPs) to\nidentify genetic diversity between different sequencing population pools\n(Pool-seq) is a fundamental task in genetic research. As underlying sequence\nreads and their alignment are error-prone and univariate statistical solutions\nonly take individual positions of the genome into account, the identification\nof selected SNPs remains a challenging process. Deep learning models like\nconvolutional neural networks (CNNs) are able to consider large input areas in\ntheir decisions. We suggest an unsupervised pipeline to be independent of a\nrarely known ground truth. We train a supervised discriminator CNN to\ndistinguish alignments from different populations and utilize the model for\nunsupervised SNP calling by applying explainable artificial intelligence\nmethods. Our proposed multivariate method is based on two main assumptions: We\nassume (i) that instances having a high predictive certainty of being\ndistinguishable are likely to contain genetic variants, and (ii) that selected\nSNPs are located at regions with input features having the highest influence on\nthe model's decision process. We directly compare our method with statistical\nresults on two different Pool-seq datasets and show that our solution is able\nto extend statistical results.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2101.00004v1",
            "date": "2020-12-28 22:28:44+00:00"
        },
        {
            "title": "A Survey on Neural Network Interpretability",
            "authors": [
                "Yu Zhang",
                "Peter Ti\u0148o",
                "Ale\u0161 Leonardis",
                "Ke Tang"
            ],
            "abstract": "Along with the great success of deep neural networks, there is also growing\nconcern about their black-box nature. The interpretability issue affects\npeople's trust on deep learning systems. It is also related to many ethical\nproblems, e.g., algorithmic discrimination. Moreover, interpretability is a\ndesired property for deep networks to become powerful tools in other research\nfields, e.g., drug discovery and genomics. In this survey, we conduct a\ncomprehensive review of the neural network interpretability research. We first\nclarify the definition of interpretability as it has been used in many\ndifferent contexts. Then we elaborate on the importance of interpretability and\npropose a novel taxonomy organized along three dimensions: type of engagement\n(passive vs. active interpretation approaches), the type of explanation, and\nthe focus (from local to global interpretability). This taxonomy provides a\nmeaningful 3D view of distribution of papers from the relevant literature as\ntwo of the dimensions are not simply categorical but allow ordinal\nsubcategories. Finally, we summarize the existing interpretability evaluation\nmethods and suggest possible research directions inspired by our new taxonomy.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "link": "http://arxiv.org/pdf/2012.14261v3",
            "date": "2020-12-28 15:09:50+00:00"
        },
        {
            "title": "Evolutionary Variational Optimization of Generative Models",
            "authors": [
                "Jakob Drefs",
                "Enrico Guiraud",
                "J\u00f6rg L\u00fccke"
            ],
            "abstract": "We combine two popular optimization approaches to derive learning algorithms\nfor generative models: variational optimization and evolutionary algorithms.\nThe combination is realized for generative models with discrete latents by\nusing truncated posteriors as the family of variational distributions. The\nvariational parameters of truncated posteriors are sets of latent states. By\ninterpreting these states as genomes of individuals and by using the\nvariational lower bound to define a fitness, we can apply evolutionary\nalgorithms to realize the variational loop. The used variational distributions\nare very flexible and we show that evolutionary algorithms can effectively and\nefficiently optimize the variational bound. Furthermore, the variational loop\nis generally applicable (\"black box\") with no analytical derivations required.\nTo show general applicability, we apply the approach to three generative models\n(we use noisy-OR Bayes Nets, Binary Sparse Coding, and Spike-and-Slab Sparse\nCoding). To demonstrate effectiveness and efficiency of the novel variational\napproach, we use the standard competitive benchmarks of image denoising and\ninpainting. The benchmarks allow quantitative comparisons to a wide range of\nmethods including probabilistic approaches, deep deterministic and generative\nnetworks, and non-local image processing methods. In the category of\n\"zero-shot\" learning (when only the corrupted image is used for training), we\nobserved the evolutionary variational algorithm to significantly improve the\nstate-of-the-art in many benchmark settings. For one well-known inpainting\nbenchmark, we also observed state-of-the-art performance across all categories\nof algorithms although we only train on the corrupted image. In general, our\ninvestigations highlight the importance of research on optimization methods for\ngenerative models to achieve performance improvements.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "cs.NE",
                "65C20, 68W50",
                "G.3.0; I.2.6; I.4.0; I.5.1"
            ],
            "link": "http://arxiv.org/pdf/2012.12294v2",
            "date": "2020-12-22 19:06:33+00:00"
        },
        {
            "title": "SimpleChrome: Encoding of Combinatorial Effects for Predicting Gene Expression",
            "authors": [
                "Wei Cheng",
                "Ghulam Murtaza",
                "Aaron Wang"
            ],
            "abstract": "Due to recent breakthroughs in state-of-the-art DNA sequencing technology,\ngenomics data sets have become ubiquitous. The emergence of large-scale data\nsets provides great opportunities for better understanding of genomics,\nespecially gene regulation. Although each cell in the human body contains the\nsame set of DNA information, gene expression controls the functions of these\ncells by either turning genes on or off, known as gene expression levels. There\nare two important factors that control the expression level of each gene: (1)\nGene regulation such as histone modifications can directly regulate gene\nexpression. (2) Neighboring genes that are functionally related to or interact\nwith each other that can also affect gene expression level. Previous efforts\nhave tried to address the former using Attention-based model. However,\naddressing the second problem requires the incorporation of all potentially\nrelated gene information into the model. Though modern machine learning and\ndeep learning models have been able to capture gene expression signals when\napplied to moderately sized data, they have struggled to recover the underlying\nsignals of the data due to the nature of the data's higher dimensionality. To\nremedy this issue, we present SimpleChrome, a deep learning model that learns\nthe latent histone modification representations of genes. The features learned\nfrom the model allow us to better understand the combinatorial effects of\ncross-gene interactions and direct gene regulation on the target gene\nexpression. The results of this paper show outstanding improvements on the\npredictive capabilities of downstream models and greatly relaxes the need for a\nlarge data set to learn a robust, generalized neural network. These results\nhave immediate downstream effects in epigenomics research and drug development.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2012.08671v2",
            "date": "2020-12-15 23:30:36+00:00"
        },
        {
            "title": "General Multi-label Image Classification with Transformers",
            "authors": [
                "Jack Lanchantin",
                "Tianlu Wang",
                "Vicente Ordonez",
                "Yanjun Qi"
            ],
            "abstract": "Multi-label image classification is the task of predicting a set of labels\ncorresponding to objects, attributes or other entities present in an image. In\nthis work we propose the Classification Transformer (C-Tran), a general\nframework for multi-label image classification that leverages Transformers to\nexploit the complex dependencies among visual features and labels. Our approach\nconsists of a Transformer encoder trained to predict a set of target labels\ngiven an input set of masked labels, and visual features from a convolutional\nneural network. A key ingredient of our method is a label mask training\nobjective that uses a ternary encoding scheme to represent the state of the\nlabels as positive, negative, or unknown during training. Our model shows\nstate-of-the-art performance on challenging datasets such as COCO and Visual\nGenome. Moreover, because our model explicitly represents the uncertainty of\nlabels during training, it is more general by allowing us to produce improved\nresults for images with partial or extra label annotations during inference. We\ndemonstrate this additional capability in the COCO, Visual Genome, News500, and\nCUB image datasets.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2011.14027v1",
            "date": "2020-11-27 23:20:35+00:00"
        },
        {
            "title": "Active Learning in CNNs via Expected Improvement Maximization",
            "authors": [
                "Udai G. Nagpal",
                "David A Knowles"
            ],
            "abstract": "Deep learning models such as Convolutional Neural Networks (CNNs) have\ndemonstrated high levels of effectiveness in a variety of domains, including\ncomputer vision and more recently, computational biology. However, training\neffective models often requires assembling and/or labeling large datasets,\nwhich may be prohibitively time-consuming or costly. Pool-based active learning\ntechniques have the potential to mitigate these issues, leveraging models\ntrained on limited data to selectively query unlabeled data points from a pool\nin an attempt to expedite the learning process. Here we present \"Dropout-based\nExpected IMprOvementS\" (DEIMOS), a flexible and computationally-efficient\napproach to active learning that queries points that are expected to maximize\nthe model's improvement across a representative sample of points. The proposed\nframework enables us to maintain a prediction covariance matrix capturing model\nuncertainty, and to dynamically update this matrix in order to generate diverse\nbatches of points in the batch-mode setting. Our active learning results\ndemonstrate that DEIMOS outperforms several existing baselines across multiple\nregression and classification tasks taken from computer vision and genomics.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "I.2.6; I.5.4; I.4.9"
            ],
            "link": "http://arxiv.org/pdf/2011.14015v1",
            "date": "2020-11-27 22:06:52+00:00"
        },
        {
            "title": "Using ontology embeddings for structural inductive bias in gene expression data analysis",
            "authors": [
                "Maja Tr\u0119bacz",
                "Zohreh Shams",
                "Mateja Jamnik",
                "Paul Scherer",
                "Nikola Simidjievski",
                "Helena Andres Terre",
                "Pietro Li\u00f2"
            ],
            "abstract": "Stratifying cancer patients based on their gene expression levels allows\nimproving diagnosis, survival analysis and treatment planning. However, such\ndata is extremely highly dimensional as it contains expression values for over\n20000 genes per patient, and the number of samples in the datasets is low. To\ndeal with such settings, we propose to incorporate prior biological knowledge\nabout genes from ontologies into the machine learning system for the task of\npatient classification given their gene expression data. We use ontology\nembeddings that capture the semantic similarities between the genes to direct a\nGraph Convolutional Network, and therefore sparsify the network connections. We\nshow this approach provides an advantage for predicting clinical targets from\nhigh-dimensional low-sample data.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2011.10998v1",
            "date": "2020-11-22 12:13:29+00:00"
        },
        {
            "title": "Nanopore Base Calling on the Edge",
            "authors": [
                "Peter Pere\u0161\u00edni",
                "Vladim\u00edr Bo\u017ea",
                "Bro\u0148a Brejov\u00e1",
                "Tom\u00e1\u0161 Vina\u0159"
            ],
            "abstract": "We developed a new base caller DeepNano-coral for nanopore sequencing, which\nis optimized to run on the Coral Edge Tensor Processing Unit, a small\nUSB-attached hardware accelerator. To achieve this goal, we have designed new\nversions of two key components used in convolutional neural networks for speech\nrecognition and base calling. In our components, we propose a new way of\nfactorization of a full convolution into smaller operations, which decreases\nmemory access operations, memory access being a bottleneck on this device.\nDeepNano-coral achieves real-time base calling during sequencing with the\naccuracy slightly better than the fast mode of the Guppy base caller and is\nextremely energy efficient, using only 10W of power. Availability:\nhttps://github.com/fmfi-compbio/coral-basecaller",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2011.04312v1",
            "date": "2020-11-09 10:36:43+00:00"
        },
        {
            "title": "Machine learning applications to DNA subsequence and restriction site analysis",
            "authors": [
                "Ethan J. Moyer",
                "Anup Das"
            ],
            "abstract": "Based on the BioBricks standard, restriction synthesis is a novel catabolic\niterative DNA synthesis method that utilizes endonucleases to synthesize a\nquery sequence from a reference sequence. In this work, the reference sequence\nis built from shorter subsequences by classifying them as applicable or\ninapplicable for the synthesis method using three different machine learning\nmethods: Support Vector Machines (SVMs), random forest, and Convolution Neural\nNetworks (CNNs). Before applying these methods to the data, a series of feature\nselection, curation, and reduction steps are applied to create an accurate and\nrepresentative feature space. Following these preprocessing steps, three\ndifferent pipelines are proposed to classify subsequences based on their\nnucleotide sequence and other relevant features corresponding to the\nrestriction sites of over 200 endonucleases. The sensitivity using SVMs, random\nforest, and CNNs are 94.9%, 92.7%, 91.4%, respectively. Moreover, each method\nscores lower in specificity with SVMs, random forest, and CNNs resulting in\n77.4%, 85.7%, and 82.4%, respectively. In addition to analyzing these results,\nthe misclassifications in SVMs and CNNs are investigated. Across these two\nmodels, different features with a derived nucleotide specificity visually\ncontribute more to classification compared to other features. This observation\nis an important factor when considering new nucleotide sensitivity features for\nfuture studies.",
            "categories": [
                "eess.SP",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2011.03544v5",
            "date": "2020-11-07 13:37:10+00:00"
        },
        {
            "title": "A deep learning classifier for local ancestry inference",
            "authors": [
                "Matthew Aguirre",
                "Jan Sokol",
                "Guhan Venkataraman",
                "Alexander Ioannidis"
            ],
            "abstract": "Local ancestry inference (LAI) identifies the ancestry of each segment of an\nindividual's genome and is an important step in medical and population genetic\nstudies of diverse cohorts. Several techniques have been used for LAI,\nincluding Hidden Markov Models and Random Forests. Here, we formulate the LAI\ntask as an image segmentation problem and develop a new LAI tool using a deep\nconvolutional neural network with an encoder-decoder architecture. We train our\nmodel using complete genome sequences from 982 unadmixed individuals from each\nof five continental ancestry groups, and we evaluate it using simulated admixed\ndata derived from an additional 279 individuals selected from the same\npopulations. We show that our model is able to learn admixture as a zero-shot\ntask, yielding ancestry assignments that are nearly as accurate as those from\nthe existing gold standard tool, RFMix.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/2011.02081v1",
            "date": "2020-11-04 00:42:01+00:00"
        },
        {
            "title": "Comparing Machine Learning Algorithms with or without Feature Extraction for DNA Classification",
            "authors": [
                "Xiangxie Zhang",
                "Ben Beinke",
                "Berlian Al Kindhi",
                "Marco Wiering"
            ],
            "abstract": "The classification of DNA sequences is a key research area in bioinformatics\nas it enables researchers to conduct genomic analysis and detect possible\ndiseases. In this paper, three state-of-the-art algorithms, namely\nConvolutional Neural Networks, Deep Neural Networks, and N-gram Probabilistic\nModels, are used for the task of DNA classification. Furthermore, we introduce\na novel feature extraction method based on the Levenshtein distance and\nrandomly generated DNA sub-sequences to compute information-rich features from\nthe DNA sequences. We also use an existing feature extraction method based on\n3-grams to represent amino acids and combine both feature extraction methods\nwith a multitude of machine learning algorithms. Four different data sets, each\nconcerning viral diseases such as Covid-19, AIDS, Influenza, and Hepatitis C,\nare used for evaluating the different approaches. The results of the\nexperiments show that all methods obtain high accuracies on the different DNA\ndatasets. Furthermore, the domain-specific 3-gram feature extraction method\nleads in general to the best results in the experiments, while the newly\nproposed technique outperforms all other methods on the smallest Covid-19\ndataset",
            "categories": [
                "q-bio.OT",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2011.00485v1",
            "date": "2020-11-01 12:04:54+00:00"
        },
        {
            "title": "Mycorrhiza: Genotype Assignment usingPhylogenetic Networks",
            "authors": [
                "Jeremy Georges-Filteau",
                "Richard C. Hamelin",
                "Mathieu Blanchette"
            ],
            "abstract": "Motivation The genotype assignment problem consists of predicting, from the\ngenotype of an individual, which of a known set of populations it originated\nfrom. The problem arises in a variety of contexts, including wildlife\nforensics, invasive species detection and biodiversity monitoring. Existing\napproaches perform well under ideal conditions but are sensitive to a variety\nof common violations of the assumptions they rely on. Results In this article,\nwe introduce Mycorrhiza, a machine learning approach for the genotype\nassignment problem. Our algorithm makes use of phylogenetic networks to\nengineer features that encode the evolutionary relationships among samples.\nThose features are then used as input to a Random Forests classifier. The\nclassification accuracy was assessed on multiple published empirical SNP,\nmicrosatellite or consensus sequence datasets with wide ranges of size,\ngeographical distribution and population structure and on simulated datasets.\nIt compared favorably against widely used assessment tests or mixture analysis\nmethods such as STRUCTURE and Admixture, and against another machine-learning\nbased approach using principal component analysis for dimensionality reduction.\nMycorrhiza yields particularly significant gains on datasets with a large\naverage fixation index (FST) or deviation from the Hardy-Weinberg equilibrium.\nMoreover, the phylogenetic network approach estimates mixture proportions with\ngood accuracy.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "q-bio.GN",
                "q-bio.PE",
                "68T07, 92B20, 90C35, 68R05",
                "J.3; I.2.6"
            ],
            "link": "http://arxiv.org/pdf/2010.09483v1",
            "date": "2020-10-14 02:36:27+00:00"
        },
        {
            "title": "A Neurochaos Learning Architecture for Genome Classification",
            "authors": [
                "Harikrishnan NB",
                "Pranay SY",
                "Nithin Nagaraj"
            ],
            "abstract": "There has been empirical evidence of presence of non-linearity and chaos at\nthe level of single neurons in biological neural networks. The properties of\nchaotic neurons inspires us to employ them in artificial learning systems.\nHere, we propose a Neurochaos Learning (NL) architecture, where the neurons\nused to extract features from data are 1D chaotic maps. ChaosFEX+SVM, an\ninstance of this NL architecture, is proposed as a hybrid combination of chaos\nand classical machine learning algorithm. We formally prove that a single layer\nof NL with a finite number of 1D chaotic neurons satisfies the Universal\nApproximation Theorem with an exact value for the number of chaotic neurons\nneeded to approximate a discrete real valued function with finite support. This\nis made possible due to the topological transitivity property of chaos and the\nexistence of uncountably infinite number of dense orbits for the chosen 1D\nchaotic map. The chaotic neurons in NL get activated under the presence of an\ninput stimulus (data) and output a chaotic firing trajectory. From such chaotic\nfiring trajectories of individual neurons of NL, we extract Firing Time, Firing\nRate, Energy and Entropy that constitute ChaosFEX features. These ChaosFEX\nfeatures are then fed to a Support Vector Machine with linear kernel for\nclassification. The effectiveness of chaotic feature engineering performed by\nNL (ChaosFEX+SVM) is demonstrated for synthetic and real world datasets in the\nlow and high training sample regimes. Specifically, we consider the problem of\nclassification of genome sequences of SARS-CoV-2 from other coronaviruses\n(SARS-CoV-1, MERS-CoV and others). With just one training sample per class for\n1000 random trials of training, we report an average macro F1-score > 0.99 for\nthe classification of SARS-CoV-2 from SARS-CoV-1 genome sequences. Robustness\nof ChaosFEX features to additive noise is also demonstrated.",
            "categories": [
                "cs.NE",
                "cs.LG",
                "q-bio.NC"
            ],
            "link": "http://arxiv.org/pdf/2010.10995v1",
            "date": "2020-10-12 19:07:02+00:00"
        },
        {
            "title": "BayReL: Bayesian Relational Learning for Multi-omics Data Integration",
            "authors": [
                "Ehsan Hajiramezanali",
                "Arman Hasanzadeh",
                "Nick Duffield",
                "Krishna R Narayanan",
                "Xiaoning Qian"
            ],
            "abstract": "High-throughput molecular profiling technologies have produced\nhigh-dimensional multi-omics data, enabling systematic understanding of living\nsystems at the genome scale. Studying molecular interactions across different\ndata types helps reveal signal transduction mechanisms across different classes\nof molecules. In this paper, we develop a novel Bayesian representation\nlearning method that infers the relational interactions across multi-omics data\ntypes. Our method, Bayesian Relational Learning (BayReL) for multi-omics data\nintegration, takes advantage of a priori known relationships among the same\nclass of molecules, modeled as a graph at each corresponding view, to learn\nview-specific latent variables as well as a multi-partite graph that encodes\nthe interactions across views. Our experiments on several real-world datasets\ndemonstrate enhanced performance of BayReL in inferring meaningful interactions\ncompared to existing baselines.",
            "categories": [
                "cs.LG",
                "q-bio.MN",
                "stat.AP",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2010.05895v3",
            "date": "2020-10-12 17:43:07+00:00"
        },
        {
            "title": "A Cross-Level Information Transmission Network for Predicting Phenotype from New Genotype: Application to Cancer Precision Medicine",
            "authors": [
                "Di He",
                "Lei Xie"
            ],
            "abstract": "An unsolved fundamental problem in biology and ecology is to predict\nobservable traits (phenotypes) from a new genetic constitution (genotype) of an\norganism under environmental perturbations (e.g., drug treatment). The\nemergence of multiple omics data provides new opportunities but imposes great\nchallenges in the predictive modeling of genotype-phenotype associations.\nFirstly, the high-dimensionality of genomics data and the lack of labeled data\noften make the existing supervised learning techniques less successful.\nSecondly, it is a challenging task to integrate heterogeneous omics data from\ndifferent resources. Finally, the information transmission from DNA to\nphenotype involves multiple intermediate levels of RNA, protein, metabolite,\netc. The higher-level features (e.g., gene expression) usually have stronger\ndiscriminative power than the lower level features (e.g., somatic mutation). To\naddress above issues, we proposed a novel Cross-LEvel Information Transmission\nnetwork (CLEIT) framework. CLEIT aims to explicitly model the asymmetrical\nmulti-level organization of the biological system. Inspired by domain\nadaptation, CLEIT first learns the latent representation of high-level domain\nthen uses it as ground-truth embedding to improve the representation learning\nof the low-level domain in the form of contrastive loss. In addition, we adopt\na pre-training-fine-tuning approach to leveraging the unlabeled heterogeneous\nomics data to improve the generalizability of CLEIT. We demonstrate the\neffectiveness and performance boost of CLEIT in predicting anti-cancer drug\nsensitivity from somatic mutations via the assistance of gene expressions when\ncompared with state-of-the-art methods.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2010.04824v1",
            "date": "2020-10-09 22:01:00+00:00"
        },
        {
            "title": "Computational analysis of pathological image enables interpretable prediction for microsatellite instability",
            "authors": [
                "Jin Zhu",
                "Wangwei Wu",
                "Yuting Zhang",
                "Shiyun Lin",
                "Yukang Jiang",
                "Ruixian Liu",
                "Xueqin Wang"
            ],
            "abstract": "Microsatellite instability (MSI) is associated with several tumor types and\nits status has become increasingly vital in guiding patient treatment\ndecisions. However, in clinical practice, distinguishing MSI from its\ncounterpart is challenging since the diagnosis of MSI requires additional\ngenetic or immunohistochemical tests. In this study, interpretable pathological\nimage analysis strategies are established to help medical experts to\nautomatically identify MSI. The strategies only require ubiquitous Haematoxylin\nand eosin-stained whole-slide images and can achieve decent performance in the\nthree cohorts collected from The Cancer Genome Atlas. The strategies provide\ninterpretability in two aspects. On the one hand, the image-level\ninterpretability is achieved by generating localization heat maps of important\nregions based on the deep learning network; on the other hand, the\nfeature-level interpretability is attained through feature importance and\npathological feature interaction analysis. More interestingly, both from the\nimage-level and feature-level interpretability, color features and texture\ncharacteristics are shown to contribute the most to the MSI predictions.\nTherefore, the classification models under the proposed strategies can not only\nserve as an efficient tool for predicting the MSI status of patients, but also\nprovide more insights to pathologists with clinical understanding.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2010.03130v1",
            "date": "2020-10-07 03:05:05+00:00"
        },
        {
            "title": "Recovering Causal Structures from Low-Order Conditional Independencies",
            "authors": [
                "Marcel Wien\u00f6bst",
                "Maciej Li\u015bkiewicz"
            ],
            "abstract": "One of the common obstacles for learning causal models from data is that\nhigh-order conditional independence (CI) relationships between random variables\nare difficult to estimate. Since CI tests with conditioning sets of low order\ncan be performed accurately even for a small number of observations, a\nreasonable approach to determine casual structures is to base merely on the\nlow-order CIs. Recent research has confirmed that, e.g. in the case of sparse\ntrue causal models, structures learned even from zero- and first-order\nconditional independencies yield good approximations of the models. However, a\nchallenging task here is to provide methods that faithfully explain a given set\nof low-order CIs. In this paper, we propose an algorithm which, for a given set\nof conditional independencies of order less or equal to $k$, where $k$ is a\nsmall fixed number, computes a faithful graphical representation of the given\nset. Our results complete and generalize the previous work on learning from\npairwise marginal independencies. Moreover, they enable to improve upon the 0-1\ngraph model which, e.g. is heavily used in the estimation of genome networks.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2010.02675v1",
            "date": "2020-10-06 12:47:20+00:00"
        },
        {
            "title": "ProDOMA: improve PROtein DOMAin classification for third-generation sequencing reads using deep learning",
            "authors": [
                "Du Nan",
                "Jiayu Shang",
                "Yanni Sun"
            ],
            "abstract": "Motivation: With the development of third-generation sequencing technologies,\npeople are able to obtain DNA sequences with lengths from 10s to 100s of kb.\nThese long reads allow protein domain annotation without assembly, thus can\nproduce important insights into the biological functions of the underlying\ndata. However, the high error rate in third-generation sequencing data raises a\nnew challenge to established domain analysis pipelines. The state-of-the-art\nmethods are not optimized for noisy reads and have shown unsatisfactory\naccuracy of domain classification in third-generation sequencing data. New\ncomputational methods are still needed to improve the performance of domain\nprediction in long noisy reads. Results: In this work, we introduce ProDOMA, a\ndeep learning model that conducts domain classification for third-generation\nsequencing reads. It uses deep neural networks with 3-frame translation\nencoding to learn conserved features from partially correct translations. In\naddition, we formulate our problem as an open-set problem and thus our model\ncan reject unrelated DNA reads such as those from noncoding regions. In the\nexperiments on simulated reads of protein coding sequences and real reads from\nthe human genome, our model outperforms HMMER and DeepFam on protein domain\nclassification. In summary, ProDOMA is a useful end-to-end protein domain\nanalysis tool for long noisy reads without relying on error correction.\nAvailability: The source code and the trained model are freely available at\nhttps://github.com/strideradu/ProDOMA. Contact: yannisun@cityu.edu.hk",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2009.12591v1",
            "date": "2020-09-26 13:30:54+00:00"
        },
        {
            "title": "3D Facial Matching by Spiral Convolutional Metric Learning and a Biometric Fusion-Net of Demographic Properties",
            "authors": [
                "Soha Sadat Mahdi",
                "Nele Nauwelaers",
                "Philip Joris",
                "Giorgos Bouritsas",
                "Shunwang Gong",
                "Sergiy Bokhnyak",
                "Susan Walsh",
                "Mark D. Shriver",
                "Michael Bronstein",
                "Peter Claes",
                "."
            ],
            "abstract": "Face recognition is a widely accepted biometric verification tool, as the\nface contains a lot of information about the identity of a person. In this\nstudy, a 2-step neural-based pipeline is presented for matching 3D facial shape\nto multiple DNA-related properties (sex, age, BMI and genomic background). The\nfirst step consists of a triplet loss-based metric learner that compresses\nfacial shape into a lower dimensional embedding while preserving information\nabout the property of interest. Most studies in the field of metric learning\nhave only focused on 2D Euclidean data. In this work, geometric deep learning\nis employed to learn directly from 3D facial meshes. To this end, spiral\nconvolutions are used along with a novel mesh-sampling scheme that retains\nuniformly sampled 3D points at different levels of resolution. The second step\nis a multi-biometric fusion by a fully connected neural network. The network\ntakes an ensemble of embeddings and property labels as input and returns\ngenuine and imposter scores. Since embeddings are accepted as an input, there\nis no need to train classifiers for the different properties and available data\ncan be used more efficiently. Results obtained by a 10-fold cross-validation\nfor biometric verification show that combining multiple properties leads to\nstronger biometric systems. Furthermore, the proposed neural-based pipeline\noutperforms a linear baseline, which consists of principal component analysis,\nfollowed by classification with linear support vector machines and a Naive\nBayes-based score-fuser.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ],
            "link": "http://arxiv.org/pdf/2009.04746v2",
            "date": "2020-09-10 09:31:47+00:00"
        },
        {
            "title": "Select-ProtoNet: Learning to Select for Few-Shot Disease Subtype Prediction",
            "authors": [
                "Ziyi Yang",
                "Jun Shu",
                "Yong Liang",
                "Deyu Meng",
                "Zongben Xu"
            ],
            "abstract": "Current machine learning has made great progress on computer vision and many\nother fields attributed to the large amount of high-quality training samples,\nwhile it does not work very well on genomic data analysis, since they are\nnotoriously known as small data. In our work, we focus on few-shot disease\nsubtype prediction problem, identifying subgroups of similar patients that can\nguide treatment decisions for a specific individual through training on small\ndata. In fact, doctors and clinicians always address this problem by studying\nseveral interrelated clinical variables simultaneously. We attempt to simulate\nsuch clinical perspective, and introduce meta learning techniques to develop a\nnew model, which can extract the common experience or knowledge from\ninterrelated clinical tasks and transfer it to help address new tasks. Our new\nmodel is built upon a carefully designed meta-learner, called Prototypical\nNetwork, that is a simple yet effective meta learning machine for few-shot\nimage classification. Observing that gene expression data have specifically\nhigh dimensionality and high noise properties compared with image data, we\nproposed a new extension of it by appending two modules to address these\nissues. Concretely, we append a feature selection layer to automatically filter\nout the disease-irrelated genes and incorporate a sample reweighting strategy\nto adaptively remove noisy data, and meanwhile the extended model is capable of\nlearning from a limited number of training examples and generalize well.\nSimulations and real gene expression data experiments substantiate the\nsuperiority of the proposed method for predicting the subtypes of disease and\nidentifying potential disease-related genes.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2009.00792v2",
            "date": "2020-09-02 02:50:30+00:00"
        },
        {
            "title": "Assigning function to protein-protein interactions: a weakly supervised BioBERT based approach using PubMed abstracts",
            "authors": [
                "Aparna Elangovan",
                "Melissa Davis",
                "Karin Verspoor"
            ],
            "abstract": "Motivation: Protein-protein interactions (PPI) are critical to the function\nof proteins in both normal and diseased cells, and many critical protein\nfunctions are mediated by interactions.Knowledge of the nature of these\ninteractions is important for the construction of networks to analyse\nbiological data. However, only a small percentage of PPIs captured in protein\ninteraction databases have annotations of function available, e.g. only 4% of\nPPI are functionally annotated in the IntAct database. Here, we aim to label\nthe function type of PPIs by extracting relationships described in PubMed\nabstracts.\n  Method: We create a weakly supervised dataset from the IntAct PPI database\ncontaining interacting protein pairs with annotated function and associated\nabstracts from the PubMed database. We apply a state-of-the-art deep learning\ntechnique for biomedical natural language processing tasks, BioBERT, to build a\nmodel - dubbed PPI-BioBERT - for identifying the function of PPIs. In order to\nextract high quality PPI functions at large scale, we use an ensemble of\nPPI-BioBERT models to improve uncertainty estimation and apply an interaction\ntype-specific threshold to counteract the effects of variations in the number\nof training samples per interaction type.\n  Results: We scan 18 million PubMed abstracts to automatically identify 3253\nnew typed PPIs, including phosphorylation and acetylation interactions, with an\noverall precision of 46% (87% for acetylation) based on a human-reviewed\nsample. This work demonstrates that analysis of biomedical abstracts for PPI\nfunction extraction is a feasible approach to substantially increasing the\nnumber of interactions annotated with function captured in online databases.",
            "categories": [
                "cs.CL",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2008.08727v3",
            "date": "2020-08-20 01:42:28+00:00"
        },
        {
            "title": "Helix: Algorithm/Architecture Co-design for Accelerating Nanopore Genome Base-calling",
            "authors": [
                "Qian Lou",
                "Sarath Janga",
                "Lei Jiang"
            ],
            "abstract": "Nanopore genome sequencing is the key to enabling personalized medicine,\nglobal food security, and virus surveillance. The state-of-the-art base-callers\nadopt deep neural networks (DNNs) to translate electrical signals generated by\nnanopore sequencers to digital DNA symbols. A DNN-based base-caller consumes\n$44.5\\%$ of total execution time of a nanopore sequencing pipeline. However, it\nis difficult to quantize a base-caller and build a power-efficient\nprocessing-in-memory (PIM) to run the quantized base-caller. In this paper, we\npropose a novel algorithm/architecture co-designed PIM, Helix, to\npower-efficiently and accurately accelerate nanopore base-calling. From\nalgorithm perspective, we present systematic error aware training to minimize\nthe number of systematic errors in a quantized base-caller. From architecture\nperspective, we propose a low-power SOT-MRAM-based ADC array to process\nanalog-to-digital conversion operations and improve power efficiency of prior\nDNN PIMs. Moreover, we revised a traditional NVM-based dot-product engine to\naccelerate CTC decoding operations, and create a SOT-MRAM binary comparator\narray to process read voting. Compared to state-of-the-art PIMs, Helix improves\nbase-calling throughput by $6\\times$, throughput per Watt by $11.9\\times$ and\nper $mm^2$ by $7.5\\times$ without degrading base-calling accuracy.",
            "categories": [
                "cs.AR",
                "cs.ET",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2008.03107v1",
            "date": "2020-08-04 22:17:19+00:00"
        },
        {
            "title": "Genome Sequence Classification for Animal Diagnostics with Graph Representations and Deep Neural Networks",
            "authors": [
                "Sai Narayanan",
                "Akhilesh Ramachandran",
                "Sathyanarayanan N. Aakur",
                "Arunkumar Bagavathi"
            ],
            "abstract": "Bovine Respiratory Disease Complex (BRDC) is a complex respiratory disease in\ncattle with multiple etiologies, including bacterial and viral. It is estimated\nthat mortality, morbidity, therapy, and quarantine resulting from BRDC account\nfor significant losses in the cattle industry. Early detection and management\nof BRDC are crucial in mitigating economic losses. Current animal disease\ndiagnostics is based on traditional tests such as bacterial culture, serolog,\nand Polymerase Chain Reaction (PCR) tests. Even though these tests are\nvalidated for several diseases, their main challenge is their limited ability\nto detect the presence of multiple pathogens simultaneously. Advancements of\ndata analytics and machine learning and applications over metagenome sequencing\nare setting trends on several applications. In this work, we demonstrate a\nmachine learning approach to identify pathogen signatures present in bovine\nmetagenome sequences using k-mer-based network embedding followed by a deep\nlearning-based classification task. With experiments conducted on two different\nsimulated datasets, we show that networks-based machine learning approaches can\ndetect pathogen signature with up to 89.7% accuracy. We will make the data\navailable publicly upon request to tackle this important problem in a difficult\ndomain.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2007.12791v1",
            "date": "2020-07-24 22:30:18+00:00"
        },
        {
            "title": "i6mA-CNN: a convolution based computational approach towards identification of DNA N6-methyladenine sites in rice genome",
            "authors": [
                "Ruhul Amin",
                "Chowdhury Rafeed Rahman",
                "Md. Sadrul Islam Toaha",
                "Swakkhar Shatabda"
            ],
            "abstract": "DNA N6-methylation (6mA) in Adenine nucleotide is a post replication\nmodification and is responsible for many biological functions. Experimental\nmethods for genome wide 6mA site detection is an expensive and manual labour\nintensive process. Automated and accurate computational methods can help to\nidentify 6mA sites in long genomes saving significant time and money. Our study\ndevelops a convolutional neural network based tool i6mA-CNN capable of\nidentifying 6mA sites in the rice genome. Our model coordinates among multiple\ntypes of features such as PseAAC inspired customized feature vector, multiple\none hot representations and dinucleotide physicochemical properties. It\nachieves area under the receiver operating characteristic curve of 0.98 with an\noverall accuracy of 0.94 using 5 fold cross validation on benchmark dataset.\nFinally, we evaluate our model on two other plant genome 6mA site\nidentification datasets besides rice. Results suggest that our proposed tool is\nable to generalize its ability of 6mA site identification on plant genomes\nirrespective of plant species. Web tool for this research can be found at:\nhttps://cutt.ly/Co6KuWG. Supplementary data (benchmark dataset, independent\ntest dataset, comparison purpose dataset, trained model, physicochemical\nproperty values, attention mechanism details for motif finding) are available\nat https://cutt.ly/PpDdeDH.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2007.10458v2",
            "date": "2020-07-20 20:37:01+00:00"
        },
        {
            "title": "Recent Advances in Network-based Methods for Disease Gene Prediction",
            "authors": [
                "Sezin Kircali Ata",
                "Min Wu",
                "Yuan Fang",
                "Le Ou-Yang",
                "Chee Keong Kwoh",
                "Xiao-Li Li"
            ],
            "abstract": "Disease-gene association through Genome-wide association study (GWAS) is an\narduous task for researchers. Investigating single nucleotide polymorphisms\n(SNPs) that correlate with specific diseases needs statistical analysis of\nassociations. Considering the huge number of possible mutations, in addition to\nits high cost, another important drawback of GWAS analysis is the large number\nof false-positives. Thus, researchers search for more evidence to cross-check\ntheir results through different sources. To provide the researchers with\nalternative low-cost disease-gene association evidence, computational\napproaches come into play. Since molecular networks are able to capture complex\ninterplay among molecules in diseases, they become one of the most extensively\nused data for disease-gene association prediction. In this survey, we aim to\nprovide a comprehensive and an up-to-date review of network-based methods for\ndisease gene prediction. We also conduct an empirical analysis on 14\nstate-of-the-art methods. To summarize, we first elucidate the task definition\nfor disease gene prediction. Secondly, we categorize existing network-based\nefforts into network diffusion methods, traditional machine learning methods\nwith handcrafted graph features and graph representation learning methods.\nThirdly, an empirical analysis is conducted to evaluate the performance of the\nselected methods across seven diseases. We also provide distinguishing findings\nabout the discussed methods based on our empirical analysis. Finally, we\nhighlight potential research directions for future studies on disease gene\nprediction.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "q-bio.MN"
            ],
            "link": "http://arxiv.org/pdf/2007.10848v2",
            "date": "2020-07-19 14:13:38+00:00"
        },
        {
            "title": "EPGAT: Gene Essentiality Prediction With Graph Attention Networks",
            "authors": [
                "Jo\u00e3o Schapke",
                "Anderson Tavares",
                "Mariana Recamonde-Mendoza"
            ],
            "abstract": "The identification of essential genes/proteins is a critical step towards a\nbetter understanding of human biology and pathology. Computational approaches\nhelped to mitigate experimental constraints by exploring machine learning (ML)\nmethods and the correlation of essentiality with biological information,\nespecially protein-protein interaction (PPI) networks, to predict essential\ngenes. Nonetheless, their performance is still limited, as network-based\ncentralities are not exclusive proxies of essentiality, and traditional ML\nmethods are unable to learn from non-Euclidean domains such as graphs. Given\nthese limitations, we proposed EPGAT, an approach for essentiality prediction\nbased on Graph Attention Networks (GATs), which are attention-based Graph\nNeural Networks (GNNs) that operate on graph-structured data. Our model\ndirectly learns patterns of gene essentiality from PPI networks, integrating\nadditional evidence from multiomics data encoded as node attributes. We\nbenchmarked EPGAT for four organisms, including humans, accurately predicting\ngene essentiality with AUC score ranging from 0.78 to 0.97. Our model\nsignificantly outperformed network-based and shallow ML-based methods and\nachieved a very competitive performance against the state-of-the-art node2vec\nembedding method. Notably, EPGAT was the most robust approach in scenarios with\nlimited and imbalanced training data. Thus, the proposed approach offers a\npowerful and effective way to identify essential genes and proteins.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2007.09671v1",
            "date": "2020-07-19 13:47:15+00:00"
        },
        {
            "title": "Automated Detection and Forecasting of COVID-19 using Deep Learning Techniques: A Review",
            "authors": [
                "Afshin Shoeibi",
                "Marjane Khodatars",
                "Roohallah Alizadehsani",
                "Navid Ghassemi",
                "Mahboobeh Jafari",
                "Parisa Moridian",
                "Ali Khadem",
                "Delaram Sadeghi",
                "Sadiq Hussain",
                "Assef Zare",
                "Zahra Alizadeh Sani",
                "Javad Bazeli",
                "Fahime Khozeimeh",
                "Abbas Khosravi",
                "Saeid Nahavandi",
                "U. Rajendra Acharya",
                "Juan M. Gorriz"
            ],
            "abstract": "Coronavirus, or COVID-19, is a hazardous disease that has endangered the\nhealth of many people around the world by directly affecting the lungs.\nCOVID-19 is a medium-sized, coated virus with a single-stranded RNA, and also\nhas one of the largest RNA genomes and is approximately 120 nm. The X-Ray and\ncomputed tomography (CT) imaging modalities are widely used to obtain a fast\nand accurate medical diagnosis. Identifying COVID-19 from these medical images\nis extremely challenging as it is time-consuming and prone to human errors.\nHence, artificial intelligence (AI) methodologies can be used to obtain\nconsistent high performance. Among the AI methods, deep learning (DL) networks\nhave gained popularity recently compared to conventional machine learning (ML).\nUnlike ML, all stages of feature extraction, feature selection, and\nclassification are accomplished automatically in DL models. In this paper, a\ncomplete survey of studies on the application of DL techniques for COVID-19\ndiagnostic and segmentation of lungs is discussed, concentrating on works that\nused X-Ray and CT images. Additionally, a review of papers on the forecasting\nof coronavirus prevalence in different parts of the world with DL is presented.\nLastly, the challenges faced in the detection of COVID-19 using DL techniques\nand directions for future research are discussed.",
            "categories": [
                "cs.LG",
                "eess.IV"
            ],
            "link": "http://arxiv.org/pdf/2007.10785v5",
            "date": "2020-07-16 16:04:17+00:00"
        },
        {
            "title": "Generative Compositional Augmentations for Scene Graph Prediction",
            "authors": [
                "Boris Knyazev",
                "Harm de Vries",
                "C\u0103t\u0103lina Cangea",
                "Graham W. Taylor",
                "Aaron Courville",
                "Eugene Belilovsky"
            ],
            "abstract": "Inferring objects and their relationships from an image in the form of a\nscene graph is useful in many applications at the intersection of vision and\nlanguage. We consider a challenging problem of compositional generalization\nthat emerges in this task due to a long tail data distribution. Current scene\ngraph generation models are trained on a tiny fraction of the distribution\ncorresponding to the most frequent compositions, e.g. <cup, on, table>.\nHowever, test images might contain zero- and few-shot compositions of objects\nand relationships, e.g. <cup, on, surfboard>. Despite each of the object\ncategories and the predicate (e.g. 'on') being frequent in the training data,\nthe models often fail to properly understand such unseen or rare compositions.\nTo improve generalization, it is natural to attempt increasing the diversity of\nthe training distribution. However, in the graph domain this is non-trivial. To\nthat end, we propose a method to synthesize rare yet plausible scene graphs by\nperturbing real ones. We then propose and empirically study a model based on\nconditional generative adversarial networks (GANs) that allows us to generate\nvisual features of perturbed scene graphs and learn from them in a joint\nfashion. When evaluated on the Visual Genome dataset, our approach yields\nmarginal, but consistent improvements in zero- and few-shot metrics. We analyze\nthe limitations of our approach indicating promising directions for future\nresearch.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2007.05756v3",
            "date": "2020-07-11 12:11:53+00:00"
        },
        {
            "title": "Deep interpretability for GWAS",
            "authors": [
                "Deepak Sharma",
                "Audrey Durand",
                "Marc-Andr\u00e9 Legault",
                "Louis-Philippe Lemieux Perreault",
                "Audrey Lema\u00e7on",
                "Marie-Pierre Dub\u00e9",
                "Joelle Pineau"
            ],
            "abstract": "Genome-Wide Association Studies are typically conducted using linear models\nto find genetic variants associated with common diseases. In these studies,\nassociation testing is done on a variant-by-variant basis, possibly missing out\non non-linear interaction effects between variants. Deep networks can be used\nto model these interactions, but they are difficult to train and interpret on\nlarge genetic datasets. We propose a method that uses the gradient based deep\ninterpretability technique named DeepLIFT to show that known diabetes genetic\nrisk factors can be identified using deep models along with possibly novel\nassociations.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.AP",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2007.01516v1",
            "date": "2020-07-03 06:49:31+00:00"
        },
        {
            "title": "A Semi-Supervised Generative Adversarial Network for Prediction of Genetic Disease Outcomes",
            "authors": [
                "Caio Davi",
                "Ulisses Braga-Neto"
            ],
            "abstract": "For most diseases, building large databases of labeled genetic data is an\nexpensive and time-demanding task. To address this, we introduce genetic\nGenerative Adversarial Networks (gGAN), a semi-supervised approach based on an\ninnovative GAN architecture to create large synthetic genetic data sets\nstarting with a small amount of labeled data and a large amount of unlabeled\ndata. Our goal is to determine the propensity of a new individual to develop\nthe severe form of the illness from their genetic profile alone. The proposed\nmodel achieved satisfactory results using real genetic data from different\ndatasets and populations, in which the test populations may not have the same\ngenetic profiles. The proposed model is self-aware and capable of determining\nwhether a new genetic profile has enough compatibility with the data on which\nthe network was trained and is thus suitable for prediction. The code and\ndatasets used can be found at https://github.com/caio-davi/gGAN.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML",
                "I.5"
            ],
            "link": "http://arxiv.org/pdf/2007.01200v1",
            "date": "2020-07-02 15:35:14+00:00"
        },
        {
            "title": "Neural Decomposition: Functional ANOVA with Variational Autoencoders",
            "authors": [
                "Kaspar M\u00e4rtens",
                "Christopher Yau"
            ],
            "abstract": "Variational Autoencoders (VAEs) have become a popular approach for\ndimensionality reduction. However, despite their ability to identify latent\nlow-dimensional structures embedded within high-dimensional data, these latent\nrepresentations are typically hard to interpret on their own. Due to the\nblack-box nature of VAEs, their utility for healthcare and genomics\napplications has been limited. In this paper, we focus on characterising the\nsources of variation in Conditional VAEs. Our goal is to provide a\nfeature-level variance decomposition, i.e. to decompose variation in the data\nby separating out the marginal additive effects of latent variables z and fixed\ninputs c from their non-linear interactions. We propose to achieve this through\nwhat we call Neural Decomposition - an adaptation of the well-known concept of\nfunctional ANOVA variance decomposition from classical statistics to deep\nlearning models. We show how identifiability can be achieved by training models\nsubject to constraints on the marginal properties of the decoder networks. We\ndemonstrate the utility of our Neural Decomposition on a series of synthetic\nexamples as well as high-dimensional genomics data.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2006.14293v2",
            "date": "2020-06-25 10:29:13+00:00"
        },
        {
            "title": "Self-supervised edge features for improved Graph Neural Network training",
            "authors": [
                "Arijit Sehanobish",
                "Neal G. Ravindra",
                "David van Dijk"
            ],
            "abstract": "Graph Neural Networks (GNN) have been extensively used to extract meaningful\nrepresentations from graph structured data and to perform predictive tasks such\nas node classification and link prediction. In recent years, there has been a\nlot of work incorporating edge features along with node features for prediction\ntasks. One of the main difficulties in using edge features is that they are\noften handcrafted, hard to get, specific to a particular domain, and may\ncontain redundant information. In this work, we present a framework for\ncreating new edge features, applicable to any domain, via a combination of\nself-supervised and unsupervised learning. In addition to this, we use\nForman-Ricci curvature as an additional edge feature to encapsulate the local\ngeometry of the graph. We then encode our edge features via a Set Transformer\nand combine them with node features extracted from popular GNN architectures\nfor node classification in an end-to-end training scheme. We validate our work\non three biological datasets comprising of single-cell RNA sequencing data of\nneurological disease, \\textit{in vitro} SARS-CoV-2 infection, and human\nCOVID-19 patients. We demonstrate that our method achieves better performance\non node classification tasks over baseline Graph Attention Network (GAT) and\nGraph Convolutional Network (GCN) models. Furthermore, given the attention\nmechanism on edge and node features, we are able to interpret the cell types\nand genes that determine the course and severity of COVID-19, contributing to a\ngrowing list of potential disease biomarkers and therapeutic targets.",
            "categories": [
                "eess.IV",
                "cs.LG",
                "q-bio.GN",
                "stat.ML",
                "I.2.4; J.3"
            ],
            "link": "http://arxiv.org/pdf/2007.04777v1",
            "date": "2020-06-23 20:18:22+00:00"
        },
        {
            "title": "Gaining Insight into SARS-CoV-2 Infection and COVID-19 Severity Using Self-supervised Edge Features and Graph Neural Networks",
            "authors": [
                "Arijit Sehanobish",
                "Neal G. Ravindra",
                "David van Dijk"
            ],
            "abstract": "A molecular and cellular understanding of how SARS-CoV-2 variably infects and\ncauses severe COVID-19 remains a bottleneck in developing interventions to end\nthe pandemic. We sought to use deep learning to study the biology of SARS-CoV-2\ninfection and COVID-19 severity by identifying transcriptomic patterns and cell\ntypes associated with SARS-CoV-2 infection and COVID-19 severity. To do this,\nwe developed a new approach to generating self-supervised edge features. We\npropose a model that builds on Graph Attention Networks (GAT), creates edge\nfeatures using self-supervised learning, and ingests these edge features via a\nSet Transformer. This model achieves significant improvements in predicting the\ndisease state of individual cells, given their transcriptome. We apply our\nmodel to single-cell RNA sequencing datasets of SARS-CoV-2 infected lung\norganoids and bronchoalveolar lavage fluid samples of patients with COVID-19,\nachieving state-of-the-art performance on both datasets with our model. We then\nborrow from the field of explainable AI (XAI) to identify the features (genes)\nand cell types that discriminate bystander vs. infected cells across time and\nmoderate vs. severe COVID-19 disease. To the best of our knowledge, this\nrepresents the first application of deep learning to identifying the molecular\nand cellular determinants of SARS-CoV-2 infection and COVID-19 severity using\nsingle-cell omics data.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2006.12971v2",
            "date": "2020-06-23 13:22:16+00:00"
        },
        {
            "title": "A Comparative Study of U-Net Topologies for Background Removal in Histopathology Images",
            "authors": [
                "Abtin Riasatian",
                "Maral Rasoolijaberi",
                "Morteza Babaei",
                "H. R. Tizhoosh"
            ],
            "abstract": "During the last decade, the digitization of pathology has gained considerable\nmomentum. Digital pathology offers many advantages including more efficient\nworkflows, easier collaboration as well as a powerful venue for telepathology.\nAt the same time, applying Computer-Aided Diagnosis (CAD) on Whole Slide Images\n(WSIs) has received substantial attention as a direct result of the\ndigitization. The first step in any image analysis is to extract the tissue.\nHence, background removal is an essential prerequisite for efficient and\naccurate results for many algorithms. In spite of the obvious discrimination\nfor human operators, the identification of tissue regions in WSIs could be\nchallenging for computers, mainly due to the existence of color variations and\nartifacts. Moreover, some cases such as alveolar tissue types, fatty tissues,\nand tissues with poor staining are difficult to detect. In this paper, we\nperform experiments on U-Net architecture with different network backbones\n(different topologies) to remove the background as well as artifacts from WSIs\nin order to extract the tissue regions. We compare a wide range of backbone\nnetworks including MobileNet, VGG16, EfficientNet-B3, ResNet50, ResNext101 and\nDenseNet121. We trained and evaluated the network on a manually labeled subset\nof The Cancer Genome Atlas (TCGA) Dataset. EfficientNet-B3 and MobileNet by\nalmost 99% sensitivity and specificity reached the best results.",
            "categories": [
                "eess.IV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2006.06531v1",
            "date": "2020-06-08 16:41:44+00:00"
        },
        {
            "title": "What needles do sparse neural networks find in nonlinear haystacks",
            "authors": [
                "Sylvain Sardy",
                "Nicolas W Hengartner",
                "Nikolai Bonenko",
                "Yen Ting Lin"
            ],
            "abstract": "Using a sparsity inducing penalty in artificial neural networks (ANNs) avoids\nover-fitting, especially in situations where noise is high and the training set\nis small in comparison to the number of features. For linear models, such an\napproach provably also recovers the important features with high probability in\nregimes for a well-chosen penalty parameter. The typical way of setting the\npenalty parameter is by splitting the data set and performing the\ncross-validation, which is (1) computationally expensive and (2) not desirable\nwhen the data set is already small to be further split (for example,\nwhole-genome sequence data). In this study, we establish the theoretical\nfoundation to select the penalty parameter without cross-validation based on\nbounding with a high probability the infinite norm of the gradient of the loss\nfunction at zero under the zero-feature assumption. Our approach is a\ngeneralization of the universal threshold of Donoho and Johnstone (1994) to\nnonlinear ANN learning. We perform a set of comprehensive Monte Carlo\nsimulations on a simple model, and the numerical results show the effectiveness\nof the proposed approach.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "physics.data-an"
            ],
            "link": "http://arxiv.org/pdf/2006.04041v1",
            "date": "2020-06-07 04:46:55+00:00"
        },
        {
            "title": "Geodesics in fibered latent spaces: A geometric approach to learning correspondences between conditions",
            "authors": [
                "Tariq Daouda",
                "Reda Chhaibi",
                "Prudencio Tossou",
                "Alexandra-Chlo\u00e9 Villani"
            ],
            "abstract": "This work introduces a geometric framework and a novel network architecture\nfor creating correspondences between samples of different conditions. Under\nthis formalism, the latent space is a fiber bundle stratified into a base space\nencoding conditions, and a fiber space encoding the variations within\nconditions. Furthermore, this latent space is endowed with a natural pull-back\nmetric. The correspondences between conditions are obtained by minimizing an\nenergy functional, resulting in diffeomorphism flows between fibers.\n  We illustrate this approach using MNIST and Olivetti and benchmark its\nperformances on the task of batch correction, which is the problem of\nintegrating multiple biological datasets together.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "math.DG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2005.07852v3",
            "date": "2020-05-16 03:14:52+00:00"
        },
        {
            "title": "Interpretable Deep Representation Learning from Temporal Multi-view Data",
            "authors": [
                "Lin Qiu",
                "Vernon M. Chinchilli",
                "Lin Lin"
            ],
            "abstract": "In many scientific problems such as video surveillance, modern genomics, and\nfinance, data are often collected from diverse measurements across time that\nexhibit time-dependent heterogeneous properties. Thus, it is important to not\nonly integrate data from multiple sources (called multi-view data), but also to\nincorporate time dependency for deep understanding of the underlying system. We\npropose a generative model based on variational autoencoder and a recurrent\nneural network to infer the latent dynamics for multi-view temporal data. This\napproach allows us to identify the disentangled latent embeddings across views\nwhile accounting for the time factor. We invoke our proposed model for\nanalyzing three datasets on which we demonstrate the effectiveness and the\ninterpretability of the model.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2005.05210v3",
            "date": "2020-05-11 15:59:06+00:00"
        },
        {
            "title": "The scalable Birth-Death MCMC Algorithm for Mixed Graphical Model Learning with Application to Genomic Data Integration",
            "authors": [
                "Nanwei Wang",
                "Laurent Briollais",
                "Helene Massam"
            ],
            "abstract": "Recent advances in biological research have seen the emergence of\nhigh-throughput technologies with numerous applications that allow the study of\nbiological mechanisms at an unprecedented depth and scale. A large amount of\ngenomic data is now distributed through consortia like The Cancer Genome Atlas\n(TCGA), where specific types of biological information on specific type of\ntissue or cell are available. In cancer research, the challenge is now to\nperform integrative analyses of high-dimensional multi-omic data with the goal\nto better understand genomic processes that correlate with cancer outcomes,\ne.g. elucidate gene networks that discriminate a specific cancer subgroups\n(cancer sub-typing) or discovering gene networks that overlap across different\ncancer types (pan-cancer studies). In this paper, we propose a novel mixed\ngraphical model approach to analyze multi-omic data of different types\n(continuous, discrete and count) and perform model selection by extending the\nBirth-Death MCMC (BDMCMC) algorithm initially proposed by\n\\citet{stephens2000bayesian} and later developed by\n\\cite{mohammadi2015bayesian}. We compare the performance of our method to the\nLASSO method and the standard BDMCMC method using simulations and find that our\nmethod is superior in terms of both computational efficiency and the accuracy\nof the model selection results. Finally, an application to the TCGA breast\ncancer data shows that integrating genomic information at different levels\n(mutation and expression data) leads to better subtyping of breast cancers.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ],
            "link": "http://arxiv.org/pdf/2005.04139v1",
            "date": "2020-05-08 16:34:58+00:00"
        },
        {
            "title": "Cell Type Identification from Single-Cell Transcriptomic Data via Semi-supervised Learning",
            "authors": [
                "Xishuang Dong",
                "Shanta Chowdhury",
                "Uboho Victor",
                "Xiangfang Li",
                "Lijun Qian"
            ],
            "abstract": "Cell type identification from single-cell transcriptomic data is a common\ngoal of single-cell RNA sequencing (scRNAseq) data analysis. Neural networks\nhave been employed to identify cell types from scRNAseq data with high\nperformance. However, it requires a large mount of individual cells with\naccurate and unbiased annotated types to build the identification models.\nUnfortunately, labeling the scRNAseq data is cumbersome and time-consuming as\nit involves manual inspection of marker genes. To overcome this challenge, we\npropose a semi-supervised learning model to use unlabeled scRNAseq cells and\nlimited amount of labeled scRNAseq cells to implement cell identification.\nFirstly, we transform the scRNAseq cells to \"gene sentences\", which is inspired\nby similarities between natural language system and gene system. Then genes in\nthese sentences are represented as gene embeddings to reduce data sparsity.\nWith these embeddings, we implement a semi-supervised learning model based on\nrecurrent convolutional neural networks (RCNN), which includes a shared\nnetwork, a supervised network and an unsupervised network. The proposed model\nis evaluated on macosko2015, a large scale single-cell transcriptomic dataset\nwith ground truth of individual cell types. It is observed that the proposed\nmodel is able to achieve encouraging performance by learning on very limited\namount of labeled scRNAseq cells together with a large number of unlabeled\nscRNAseq cells.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2005.03994v1",
            "date": "2020-05-06 19:15:43+00:00"
        },
        {
            "title": "A Systematic Approach to Featurization for Cancer Drug Sensitivity Predictions with Deep Learning",
            "authors": [
                "Austin Clyde",
                "Tom Brettin",
                "Alexander Partin",
                "Maulik Shaulik",
                "Hyunseung Yoo",
                "Yvonne Evrard",
                "Yitan Zhu",
                "Fangfang Xia",
                "Rick Stevens"
            ],
            "abstract": "By combining various cancer cell line (CCL) drug screening panels, the size\nof the data has grown significantly to begin understanding how advances in deep\nlearning can advance drug response predictions. In this paper we train >35,000\nneural network models, sweeping over common featurization techniques. We found\nthe RNA-seq to be highly redundant and informative even with subsets larger\nthan 128 features. We found the inclusion of single nucleotide polymorphisms\n(SNPs) coded as count matrices improved model performance significantly, and no\nsubstantial difference in model performance with respect to molecular\nfeaturization between the common open source MOrdred descriptors and Dragon7\ndescriptors. Alongside this analysis, we outline data integration between CCL\nscreening datasets and present evidence that new metrics and imbalanced data\ntechniques, as well as advances in data standardization, need to be developed.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/2005.00095v2",
            "date": "2020-04-30 20:42:17+00:00"
        },
        {
            "title": "Beyond Data Samples: Aligning Differential Networks Estimation with Scientific Knowledge",
            "authors": [
                "Arshdeep Sekhon",
                "Zhe Wang",
                "Yanjun Qi"
            ],
            "abstract": "Learning the differential statistical dependency network between two contexts\nis essential for many real-life applications, mostly in the high dimensional\nlow sample regime. In this paper, we propose a novel differential network\nestimator that allows integrating various sources of knowledge beyond data\nsamples. The proposed estimator is scalable to a large number of variables and\nachieves a sharp asymptotic convergence rate. Empirical experiments on\nextensive simulated data and four real-world applications (one on neuroimaging\nand three from functional genomics) show that our approach achieves improved\ndifferential network estimation and provides better supports to downstream\ntasks like classification. Our results highlight significant benefits of\nintegrating group, spatial and anatomic knowledge during differential genetic\nnetwork identification and brain connectome change discovery.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2004.11494v2",
            "date": "2020-04-24 00:01:15+00:00"
        },
        {
            "title": "Representation Learning of Histopathology Images using Graph Neural Networks",
            "authors": [
                "Mohammed Adnan",
                "Shivam Kalra",
                "Hamid R. Tizhoosh"
            ],
            "abstract": "Representation learning for Whole Slide Images (WSIs) is pivotal in\ndeveloping image-based systems to achieve higher precision in diagnostic\npathology. We propose a two-stage framework for WSI representation learning. We\nsample relevant patches using a color-based method and use graph neural\nnetworks to learn relations among sampled patches to aggregate the image\ninformation into a single vector representation. We introduce attention via\ngraph pooling to automatically infer patches with higher relevance. We\ndemonstrate the performance of our approach for discriminating two sub-types of\nlung cancers, Lung Adenocarcinoma (LUAD) & Lung Squamous Cell Carcinoma (LUSC).\nWe collected 1,026 lung cancer WSIs with the 40$\\times$ magnification from The\nCancer Genome Atlas (TCGA) dataset, the largest public repository of\nhistopathology images and achieved state-of-the-art accuracy of 88.8% and AUC\nof 0.89 on lung cancer sub-type classification by extracting features from a\npre-trained DenseNet",
            "categories": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2004.07399v2",
            "date": "2020-04-16 00:09:20+00:00"
        },
        {
            "title": "Locality Sensitive Hashing-based Sequence Alignment Using Deep Bidirectional LSTM Models",
            "authors": [
                "Neda Tavakoli"
            ],
            "abstract": "Bidirectional Long Short-Term Memory (LSTM) is a special kind of Recurrent\nNeural Network (RNN) architecture which is designed to model sequences and\ntheir long-range dependencies more precisely than RNNs. This paper proposes to\nuse deep bidirectional LSTM for sequence modeling as an approach to perform\nlocality-sensitive hashing (LSH)-based sequence alignment. In particular, we\nuse the deep bidirectional LSTM to learn features of LSH. The obtained LSH is\nthen can be utilized to perform sequence alignment. We demonstrate the\nfeasibility of the modeling sequences using the proposed LSTM-based model by\naligning the short read queries over the reference genome. We use the human\nreference genome as our training dataset, in addition to a set of short reads\ngenerated using Illumina sequencing technology. The ultimate goal is to align\nquery sequences into a reference genome. We first decompose the reference\ngenome into multiple sequences. These sequences are then fed into the\nbidirectional LSTM model and then mapped into fixed-length vectors. These\nvectors are what we call the trained LSH, which can then be used for sequence\nalignment. The case study shows that using the introduced LSTM-based model, we\nachieve higher accuracy with the number of epochs.",
            "categories": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2004.02094v1",
            "date": "2020-04-05 05:13:06+00:00"
        },
        {
            "title": "Object-Centric Image Generation from Layouts",
            "authors": [
                "Tristan Sylvain",
                "Pengchuan Zhang",
                "Yoshua Bengio",
                "R Devon Hjelm",
                "Shikhar Sharma"
            ],
            "abstract": "Despite recent impressive results on single-object and single-domain image\ngeneration, the generation of complex scenes with multiple objects remains\nchallenging. In this paper, we start with the idea that a model must be able to\nunderstand individual objects and relationships between objects in order to\ngenerate complex scenes well. Our layout-to-image-generation method, which we\ncall Object-Centric Generative Adversarial Network (or OC-GAN), relies on a\nnovel Scene-Graph Similarity Module (SGSM). The SGSM learns representations of\nthe spatial relationships between objects in the scene, which lead to our\nmodel's improved layout-fidelity. We also propose changes to the conditioning\nmechanism of the generator that enhance its object instance-awareness. Apart\nfrom improving image quality, our contributions mitigate two failure modes in\nprevious approaches: (1) spurious objects being generated without corresponding\nbounding boxes in the layout, and (2) overlapping bounding boxes in the layout\nleading to merged objects in images. Extensive quantitative evaluation and\nablation studies demonstrate the impact of our contributions, with our model\noutperforming previous state-of-the-art approaches on both the COCO-Stuff and\nVisual Genome datasets. Finally, we address an important limitation of\nevaluation metrics used in previous works by introducing SceneFID -- an\nobject-centric adaptation of the popular Fr{\\'e}chet Inception Distance metric,\nthat is better suited for multi-object images.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ],
            "link": "http://arxiv.org/pdf/2003.07449v2",
            "date": "2020-03-16 21:40:09+00:00"
        },
        {
            "title": "BasisVAE: Translation-invariant feature-level clustering with Variational Autoencoders",
            "authors": [
                "Kaspar M\u00e4rtens",
                "Christopher Yau"
            ],
            "abstract": "Variational Autoencoders (VAEs) provide a flexible and scalable framework for\nnon-linear dimensionality reduction. However, in application domains such as\ngenomics where data sets are typically tabular and high-dimensional, a\nblack-box approach to dimensionality reduction does not provide sufficient\ninsights. Common data analysis workflows additionally use clustering techniques\nto identify groups of similar features. This usually leads to a two-stage\nprocess, however, it would be desirable to construct a joint modelling\nframework for simultaneous dimensionality reduction and clustering of features.\nIn this paper, we propose to achieve this through the BasisVAE: a combination\nof the VAE and a probabilistic clustering prior, which lets us learn a one-hot\nbasis function representation as part of the decoder network. Furthermore, for\nscenarios where not all features are aligned, we develop an extension to handle\ntranslation-invariant basis functions. We show how a collapsed variational\ninference scheme leads to scalable and efficient inference for BasisVAE,\ndemonstrated on various toy examples as well as on single-cell gene expression\ndata.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2003.03462v1",
            "date": "2020-03-06 23:10:52+00:00"
        },
        {
            "title": "An Optimal Statistical and Computational Framework for Generalized Tensor Estimation",
            "authors": [
                "Rungang Han",
                "Rebecca Willett",
                "Anru R. Zhang"
            ],
            "abstract": "This paper describes a flexible framework for generalized low-rank tensor\nestimation problems that includes many important instances arising from\napplications in computational imaging, genomics, and network analysis. The\nproposed estimator consists of finding a low-rank tensor fit to the data under\ngeneralized parametric models. To overcome the difficulty of non-convexity in\nthese problems, we introduce a unified approach of projected gradient descent\nthat adapts to the underlying low-rank structure. Under mild conditions on the\nloss function, we establish both an upper bound on statistical error and the\nlinear rate of computational convergence through a general deterministic\nanalysis. Then we further consider a suite of generalized tensor estimation\nproblems, including sub-Gaussian tensor PCA, tensor regression, and Poisson and\nbinomial tensor PCA. We prove that the proposed algorithm achieves the minimax\noptimal rate of convergence in estimation error. Finally, we demonstrate the\nsuperiority of the proposed framework via extensive experiments on both\nsimulated and real data.",
            "categories": [
                "math.ST",
                "cs.LG",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ],
            "link": "http://arxiv.org/pdf/2002.11255v2",
            "date": "2020-02-26 01:54:35+00:00"
        },
        {
            "title": "Disease State Prediction From Single-Cell Data Using Graph Attention Networks",
            "authors": [
                "Neal G. Ravindra",
                "Arijit Sehanobish",
                "Jenna L. Pappalardo",
                "David A. Hafler",
                "David van Dijk"
            ],
            "abstract": "Single-cell RNA sequencing (scRNA-seq) has revolutionized biological\ndiscovery, providing an unbiased picture of cellular heterogeneity in tissues.\nWhile scRNA-seq has been used extensively to provide insight into both healthy\nsystems and diseases, it has not been used for disease prediction or\ndiagnostics. Graph Attention Networks (GAT) have proven to be versatile for a\nwide range of tasks by learning from both original features and graph\nstructures. Here we present a graph attention model for predicting disease\nstate from single-cell data on a large dataset of Multiple Sclerosis (MS)\npatients. MS is a disease of the central nervous system that can be difficult\nto diagnose. We train our model on single-cell data obtained from blood and\ncerebrospinal fluid (CSF) for a cohort of seven MS patients and six healthy\nadults (HA), resulting in 66,667 individual cells. We achieve 92 % accuracy in\npredicting MS, outperforming other state-of-the-art methods such as a graph\nconvolutional network and a random forest classifier. Further, we use the\nlearned graph attention model to get insight into the features (cell types and\ngenes) that are important for this prediction. The graph attention model also\nallow us to infer a new feature space for the cells that emphasizes the\ndifferences between the two conditions. Finally we use the attention weights to\nlearn a new low-dimensional embedding that can be visualized. To the best of\nour knowledge, this is the first effort to use graph attention, and deep\nlearning in general, to predict disease state from single-cell data. We\nenvision applying this method to single-cell data for other diseases.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML",
                "J.3; I.2.6"
            ],
            "link": "http://arxiv.org/pdf/2002.07128v2",
            "date": "2020-02-14 16:08:30+00:00"
        },
        {
            "title": "High Performance Logistic Regression for Privacy-Preserving Genome Analysis",
            "authors": [
                "Martine De Cock",
                "Rafael Dowsley",
                "Anderson C. A. Nascimento",
                "Davis Railsback",
                "Jianwei Shen",
                "Ariel Todoki"
            ],
            "abstract": "In this paper, we present a secure logistic regression training protocol and\nits implementation, with a new subprotocol to securely compute the activation\nfunction. To the best of our knowledge, we present the fastest existing secure\nMulti-Party Computation implementation for training logistic regression models\non high dimensional genome data distributed across a local area network.",
            "categories": [
                "cs.CR",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/2002.05377v2",
            "date": "2020-02-13 07:37:08+00:00"
        },
        {
            "title": "Multimodal fusion of imaging and genomics for lung cancer recurrence prediction",
            "authors": [
                "Vaishnavi Subramanian",
                "Minh N. Do",
                "Tanveer Syeda-Mahmood"
            ],
            "abstract": "Lung cancer has a high rate of recurrence in early-stage patients. Predicting\nthe post-surgical recurrence in lung cancer patients has traditionally been\napproached using single modality information of genomics or radiology images.\nWe investigate the potential of multimodal fusion for this task. By combining\ncomputed tomography (CT) images and genomics, we demonstrate improved\nprediction of recurrence using linear Cox proportional hazards models with\nelastic net regularization. We work on a recent non-small cell lung cancer\n(NSCLC) radiogenomics dataset of 130 patients and observe an increase in\nconcordance-index values of up to 10%. Employing non-linear methods from the\nneural network literature, such as multi-layer perceptrons and visual-question\nanswering fusion modules, did not improve performance consistently. This\nindicates the need for larger multimodal datasets and fusion techniques better\nadapted to this biological setting.",
            "categories": [
                "eess.IV",
                "cs.LG",
                "eess.SP",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/2002.01982v1",
            "date": "2020-02-05 20:32:36+00:00"
        },
        {
            "title": "Biophysical models of cis-regulation as interpretable neural networks",
            "authors": [
                "Ammar Tareen",
                "Justin B. Kinney"
            ],
            "abstract": "The adoption of deep learning techniques in genomics has been hindered by the\ndifficulty of mechanistically interpreting the models that these techniques\nproduce. In recent years, a variety of post-hoc attribution methods have been\nproposed for addressing this neural network interpretability problem in the\ncontext of gene regulation. Here we describe a complementary way of approaching\nthis problem. Our strategy is based on the observation that two large classes\nof biophysical models of cis-regulatory mechanisms can be expressed as deep\nneural networks in which nodes and weights have explicit physiochemical\ninterpretations. We also demonstrate how such biophysical networks can be\nrapidly inferred, using modern deep learning frameworks, from the data produced\nby certain types of massively parallel reporter assays (MPRAs). These results\nsuggest a scalable strategy for using MPRAs to systematically characterize the\nbiophysical basis of gene regulation in a wide range of biological contexts.\nThey also highlight gene regulation as a promising venue for the development of\nscientifically interpretable approaches to deep learning.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "physics.bio-ph",
                "q-bio.QM",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/2001.03560v2",
            "date": "2019-12-30 14:45:58+00:00"
        },
        {
            "title": "Reconstruction of Gene Regulatory Networks usingMultiple Datasets",
            "authors": [
                "Mehrzad Saremi",
                "Maryam Amirmazlaghani"
            ],
            "abstract": "Motivation: Laboratory gene regulatory data for a species are sporadic.\nDespite the abundance of gene regulatory network algorithms that employ single\ndata sets, few algorithms can combine the vast but disperse sources of data and\nextract the potential information. With a motivation to compensate for this\nshortage, we developed an algorithm called GENEREF that can accumulate\ninformation from multiple types of data sets in an iterative manner, with each\niteration boosting the performance of the prediction results.\n  Results: The algorithm is examined extensively on data extracted from the\nquintuple DREAM4 networks and DREAM5's Escherichia coli and Saccharomyces\ncerevisiae networks and sub-networks. Many single-dataset and multi-dataset\nalgorithms were compared to test the performance of the algorithm. Results show\nthat GENEREF surpasses non-ensemble state-of-the-art multi-perturbation\nalgorithms on the selected networks and is competitive to present\nmultiple-dataset algorithms. Specifically, it outperforms dynGENIE3 and is on\npar with iRafNet. Also, we argued that a scoring method solely based on the\nAUPR criterion would be more trustworthy than the traditional score.\n  Availability: The Python implementation along with the data sets and results\ncan be downloaded from github.com/msaremi/GENEREF",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "q-bio.MN",
                "E.m"
            ],
            "link": "http://arxiv.org/pdf/1912.10810v2",
            "date": "2019-12-19 22:54:59+00:00"
        },
        {
            "title": "Deep Bayesian Recurrent Neural Networks for Somatic Variant Calling in Cancer",
            "authors": [
                "Geoffroy Dubourg-Felonneau",
                "Omar Darwish",
                "Christopher Parsons",
                "Dami Rebergen",
                "John W Cassidy",
                "Nirmesh Patel",
                "Harry W Clifford"
            ],
            "abstract": "The emerging field of precision oncology relies on the accurate pinpointing\nof alterations in the molecular profile of a tumor to provide personalized\ntargeted treatments. Current methodologies in the field commonly include the\napplication of next generation sequencing technologies to a tumor sample,\nfollowed by the identification of mutations in the DNA known as somatic\nvariants. The differentiation of these variants from sequencing error poses a\nclassic classification problem, which has traditionally been approached with\nBayesian statistics, and more recently with supervised machine learning methods\nsuch as neural networks. Although these methods provide greater accuracy,\nclassic neural networks lack the ability to indicate the confidence of a\nvariant call. In this paper, we explore the performance of deep Bayesian neural\nnetworks on next generation sequencing data, and their ability to give\nprobability estimates for somatic variant calls. In addition to demonstrating\nsimilar performance in comparison to standard neural networks, we show that the\nresultant output probabilities make these better suited to the disparate and\nhighly-variable sequencing data-sets these models are likely to encounter in\nthe real world. We aim to deliver algorithms to oncologists for which model\ncertainty better reflects accuracy, for improved clinical application. By\nmoving away from point estimates to reliable confidence intervals, we expect\nthe resultant clinical and treatment decisions to be more robust and more\ninformed by the underlying reality of the tumor molecular profile.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1912.04174v1",
            "date": "2019-12-06 16:01:15+00:00"
        },
        {
            "title": "Safety and Robustness in Decision Making: Deep Bayesian Recurrent Neural Networks for Somatic Variant Calling in Cancer",
            "authors": [
                "Geoffroy Dubourg-Felonneau",
                "Omar Darwish",
                "Christopher Parsons",
                "Dami Rebergen",
                "John W Cassidy",
                "Nirmesh Patel",
                "Harry W Clifford"
            ],
            "abstract": "The genomic profile underlying an individual tumor can be highly informative\nin the creation of a personalized cancer treatment strategy for a given\npatient; a practice known as precision oncology. This involves next generation\nsequencing of a tumor sample and the subsequent identification of genomic\naberrations, such as somatic mutations, to provide potential candidates of\ntargeted therapy. The identification of these aberrations from sequencing noise\nand germline variant background poses a classic classification-style problem.\nThis has been previously broached with many different supervised machine\nlearning methods, including deep-learning neural networks. However, these\nneural networks have thus far not been tailored to give any indication of\nconfidence in the mutation call, meaning an oncologist could be targeting a\nmutation with a low probability of being true. To address this, we present here\na deep bayesian recurrent neural network for cancer variant calling, which\nshows no degradation in performance compared to standard neural networks. This\napproach enables greater flexibility through different priors to avoid\noverfitting to a single dataset. We will be incorporating this approach into\nsoftware for oncologists to obtain safe, robust, and statistically confident\nsomatic mutation calls for precision oncology treatment choices.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1912.02065v1",
            "date": "2019-12-04 15:47:56+00:00"
        },
        {
            "title": "Learning to Relate from Captions and Bounding Boxes",
            "authors": [
                "Sarthak Garg",
                "Joel Ruben Antony Moniz",
                "Anshu Aviral",
                "Priyatham Bollimpalli"
            ],
            "abstract": "In this work, we propose a novel approach that predicts the relationships\nbetween various entities in an image in a weakly supervised manner by relying\non image captions and object bounding box annotations as the sole source of\nsupervision. Our proposed approach uses a top-down attention mechanism to align\nentities in captions to objects in the image, and then leverage the syntactic\nstructure of the captions to align the relations. We use these alignments to\ntrain a relation classification network, thereby obtaining both grounded\ncaptions and dense relationships. We demonstrate the effectiveness of our model\non the Visual Genome dataset by achieving a recall@50 of 15% and recall@100 of\n25% on the relationships present in the image. We also show that the model\nsuccessfully predicts relations that are not present in the corresponding\ncaptions.",
            "categories": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1912.00311v1",
            "date": "2019-12-01 03:30:00+00:00"
        },
        {
            "title": "Sparsely Grouped Input Variables for Neural Networks",
            "authors": [
                "Beibin Li",
                "Nicholas Nuechterlein",
                "Erin Barney",
                "Caitlin Hudac",
                "Pamela Ventola",
                "Linda Shapiro",
                "Frederick Shic"
            ],
            "abstract": "In genomic analysis, biomarker discovery, image recognition, and other\nsystems involving machine learning, input variables can often be organized into\ndifferent groups by their source or semantic category. Eliminating some groups\nof variables can expedite the process of data acquisition and avoid\nover-fitting. Researchers have used the group lasso to ensure group sparsity in\nlinear models and have extended it to create compact neural networks in\nmeta-learning. Different from previous studies, we use multi-layer non-linear\nneural networks to find sparse groups for input variables. We propose a new\nloss function to regularize parameters for grouped input variables, design a\nnew optimization algorithm for this loss function, and test these methods in\nthree real-world settings. We achieve group sparsity for three datasets,\nmaintaining satisfying results while excluding one nucleotide position from an\nRNA splicing experiment, excluding 89.9% of stimuli from an eye-tracking\nexperiment, and excluding 60% of image rows from an experiment on the MNIST\ndataset.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1911.13068v1",
            "date": "2019-11-29 11:45:20+00:00"
        },
        {
            "title": "Flatsomatic: A Method for Compression of Somatic Mutation Profiles in Cancer",
            "authors": [
                "Geoffroy Dubourg-Felonneau",
                "Yasmeen Kussad",
                "Dominic Kirkham",
                "John W Cassidy",
                "Nirmesh Patel",
                "Harry W Clifford"
            ],
            "abstract": "In this study, we present Flatsomatic - a Variational Auto Encoder (VAE)\noptimized to compress somatic mutations that allow for unbiased data\ncompression whilst maintaining the signal. We compared two different neural\nnetwork architectures for the VAE: Multilayer Perceptron (MLP) and\nbidirectional LSTM. The somatic profiles we used to train our models consisted\nof 8,062 Pan-Cancer patients from The Cancer Genome Atlas and 989 cell lines\nfrom the COSMIC cell line project. The profiles for each patient were\nrepresented by the genomic loci where somatic mutations occurred and, to reduce\nsparsity, the locations with a frequency <5 were removed. We enhanced the VAE\nperformance by changing its evidence lower bound, and devised an F1-score based\nloss showing that it helps the VAE learn better than with binary cross-entropy.\nWe also employed beta-VAE to weight the variational regularisation term in the\nloss function and showed the best performance through a preliminary function to\nincrease the weight of the regularisation term with each epoch. We assessed the\nreconstruction ability of the VAE using the micro F1-score metric and showed\nthat our best performing model was a 2-layer deep MLP VAE. Our analysis also\nshowed that the size of the latent space did not have a significant effect on\nthe VAE learning ability. We compared the Flatsomatic embeddings created to a\nlower dimension version of the data from principal component analysis, showing\nsuperior performance of Flatsomatic, and performed K-means clustering on both\ndatasets to draw comparisons to known cancer types of each profile. Finally, we\npresent results that confirm that the Flatsomatic representations of 64\ndimensions maintain the same predictive power as the original 8,298 dimensions\nvector, through prediction of drug response.",
            "categories": [
                "eess.IV",
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1911.13259v1",
            "date": "2019-11-27 18:29:34+00:00"
        },
        {
            "title": "ComHapDet: A Spatial Community Detection Algorithm for Haplotype Assembly",
            "authors": [
                "Abishek Sankararaman",
                "Haris Vikalo",
                "Fran\u00e7ois Baccelli"
            ],
            "abstract": "Background: Haplotypes, the ordered lists of single nucleotide variations\nthat distinguish chromosomal sequences from their homologous pairs, may reveal\nan individual's susceptibility to hereditary and complex diseases and affect\nhow our bodies respond to therapeutic drugs. Reconstructing haplotypes of an\nindividual from short sequencing reads is an NP-hard problem that becomes even\nmore challenging in the case of polyploids. While increasing lengths of\nsequencing reads and insert sizes {\\color{black} helps improve accuracy of\nreconstruction}, it also exacerbates computational complexity of the haplotype\nassembly task. This has motivated the pursuit of algorithmic frameworks capable\nof accurate yet efficient assembly of haplotypes from high-throughput\nsequencing data.\n  Results: We propose a novel graphical representation of sequencing reads and\npose the haplotype assembly problem as an instance of community detection on a\nspatial random graph. To this end, we construct a graph where each read is a\nnode with an unknown community label associating the read with the haplotype it\nsamples. Haplotype reconstruction can then be thought of as a two-step\nprocedure: first, one recovers the community labels on the nodes (i.e., the\nreads), and then uses the estimated labels to assemble the haplotypes. Based on\nthis observation, we propose ComHapDet - a novel assembly algorithm for diploid\nand ployploid haplotypes which allows both bialleleic and multi-allelic\nvariants.\n  Conclusions: Performance of the proposed algorithm is benchmarked on\nsimulated as well as experimental data obtained by sequencing Chromosome $5$ of\ntetraploid biallelic \\emph{Solanum-Tuberosum} (Potato). The results demonstrate\nthe efficacy of the proposed method and that it compares favorably with the\nexisting techniques.",
            "categories": [
                "cs.SI",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1911.12285v1",
            "date": "2019-11-27 17:01:07+00:00"
        },
        {
            "title": "Pre-Training of Deep Bidirectional Protein Sequence Representations with Structural Information",
            "authors": [
                "Seonwoo Min",
                "Seunghyun Park",
                "Siwon Kim",
                "Hyun-Soo Choi",
                "Byunghan Lee",
                "Sungroh Yoon"
            ],
            "abstract": "Bridging the exponentially growing gap between the numbers of unlabeled and\nlabeled protein sequences, several studies adopted semi-supervised learning for\nprotein sequence modeling. In these studies, models were pre-trained with a\nsubstantial amount of unlabeled data, and the representations were transferred\nto various downstream tasks. Most pre-training methods solely rely on language\nmodeling and often exhibit limited performance. In this paper, we introduce a\nnovel pre-training scheme called PLUS, which stands for Protein sequence\nrepresentations Learned Using Structural information. PLUS consists of masked\nlanguage modeling and a complementary protein-specific pre-training task,\nnamely same-family prediction. PLUS can be used to pre-train various model\narchitectures. In this work, we use PLUS to pre-train a bidirectional recurrent\nneural network and refer to the resulting model as PLUS-RNN. Our experiment\nresults demonstrate that PLUS-RNN outperforms other models of similar size\nsolely pre-trained with the language modeling in six out of seven widely used\nprotein biology tasks. Furthermore, we present the results from our qualitative\ninterpretation analyses to illustrate the strengths of PLUS-RNN. PLUS provides\na novel way to exploit evolutionary relationships among unlabeled proteins and\nis broadly applicable across a variety of protein biology tasks. We expect that\nthe gap between the numbers of unlabeled and labeled proteins will continue to\ngrow exponentially, and the proposed pre-training method will play a larger\nrole.",
            "categories": [
                "q-bio.BM",
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1912.05625v4",
            "date": "2019-11-25 10:12:10+00:00"
        },
        {
            "title": "Consistent recovery threshold of hidden nearest neighbor graphs",
            "authors": [
                "Jian Ding",
                "Yihong Wu",
                "Jiaming Xu",
                "Dana Yang"
            ],
            "abstract": "Motivated by applications such as discovering strong ties in social networks\nand assembling genome subsequences in biology, we study the problem of\nrecovering a hidden $2k$-nearest neighbor (NN) graph in an $n$-vertex complete\ngraph, whose edge weights are independent and distributed according to $P_n$\nfor edges in the hidden $2k$-NN graph and $Q_n$ otherwise. The special case of\nBernoulli distributions corresponds to a variant of the Watts-Strogatz\nsmall-world graph. We focus on two types of asymptotic recovery guarantees as\n$n\\to \\infty$: (1) exact recovery: all edges are classified correctly with\nprobability tending to one; (2) almost exact recovery: the expected number of\nmisclassified edges is $o(nk)$. We show that the maximum likelihood estimator\nachieves (1) exact recovery for $2 \\le k \\le n^{o(1)}$ if $ \\liminf\n\\frac{2\\alpha_n}{\\log n}>1$; (2) almost exact recovery for $ 1 \\le k \\le\no\\left( \\frac{\\log n}{\\log \\log n} \\right)$ if $\\liminf\n\\frac{kD(P_n||Q_n)}{\\log n}>1$, where $\\alpha_n \\triangleq -2 \\log \\int \\sqrt{d\nP_n d Q_n}$ is the R\\'enyi divergence of order $\\frac{1}{2}$ and $D(P_n||Q_n)$\nis the Kullback-Leibler divergence. Under mild distributional assumptions,\nthese conditions are shown to be information-theoretically necessary for any\nalgorithm to succeed. A key challenge in the analysis is the enumeration of\n$2k$-NN graphs that differ from the hidden one by a given number of edges.",
            "categories": [
                "cs.DS",
                "cs.LG",
                "cs.SI",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ],
            "link": "http://arxiv.org/pdf/1911.08004v1",
            "date": "2019-11-18 23:44:54+00:00"
        },
        {
            "title": "Learning Permutation Invariant Representations using Memory Networks",
            "authors": [
                "Shivam Kalra",
                "Mohammed Adnan",
                "Graham Taylor",
                "Hamid Tizhoosh"
            ],
            "abstract": "Many real-world tasks such as classification of digital histopathology images\nand 3D object detection involve learning from a set of instances. In these\ncases, only a group of instances or a set, collectively, contains meaningful\ninformation and therefore only the sets have labels, and not individual data\ninstances. In this work, we present a permutation invariant neural network\ncalled Memory-based Exchangeable Model (MEM) for learning set functions. The\nMEM model consists of memory units that embed an input sequence to high-level\nfeatures enabling the model to learn inter-dependencies among instances through\na self-attention mechanism. We evaluated the learning ability of MEM on various\ntoy datasets, point cloud classification, and classification of lung whole\nslide images (WSIs) into two subtypes of lung cancer---Lung Adenocarcinoma, and\nLung Squamous Cell Carcinoma. We systematically extracted patches from lung\nWSIs downloaded from The Cancer Genome Atlas~(TCGA) dataset, the largest public\nrepository of WSIs, achieving a competitive accuracy of 84.84\\% for\nclassification of two sub-types of lung cancer. The results on other datasets\nare promising as well, and demonstrate the efficacy of our model.",
            "categories": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1911.07984v2",
            "date": "2019-11-18 22:28:30+00:00"
        },
        {
            "title": "Opportunities for artificial intelligence in advancing precision medicine",
            "authors": [
                "Fabian V. Filipp"
            ],
            "abstract": "Machine learning (ML), deep learning (DL), and artificial intelligence (AI)\nare of increasing importance in biomedicine. The goal of this work is to show\nprogress in ML in digital health, to exemplify future needs and trends, and to\nidentify any essential prerequisites of AI and ML for precision health.\nHigh-throughput technologies are delivering growing volumes of biomedical data,\nsuch as large-scale genome-wide sequencing assays, libraries of medical images,\nor drug perturbation screens of healthy, developing, and diseased tissue.\nMulti-omics data in biomedicine is deep and complex, offering an opportunity\nfor data-driven insights and automated disease classification. Learning from\nthese data will open our understanding and definition of healthy baselines and\ndisease signatures. State-of-the-art applications of deep neural networks\ninclude digital image recognition, single cell clustering, and virtual drug\nscreens, demonstrating breadths and power of ML in biomedicine. Significantly,\nAI and systems biology have embraced big data challenges and may enable novel\nbiotechnology-derived therapies to facilitate the implementation of precision\nmedicine approaches.",
            "categories": [
                "cs.AI",
                "cs.LG",
                "q-bio.BM",
                "q-bio.GN",
                "q-bio.MN"
            ],
            "link": "http://arxiv.org/pdf/1911.07125v1",
            "date": "2019-11-17 01:29:54+00:00"
        },
        {
            "title": "A Graph Auto-Encoder for Haplotype Assembly and Viral Quasispecies Reconstruction",
            "authors": [
                "Ziqi Ke",
                "Haris Vikalo"
            ],
            "abstract": "Reconstructing components of a genomic mixture from data obtained by means of\nDNA sequencing is a challenging problem encountered in a variety of\napplications including single individual haplotyping and studies of viral\ncommunities. High-throughput DNA sequencing platforms oversample mixture\ncomponents to provide massive amounts of reads whose relative positions can be\ndetermined by mapping the reads to a known reference genome; assembly of the\ncomponents, however, requires discovery of the reads' origin -- an NP-hard\nproblem that the existing methods struggle to solve with the required level of\naccuracy. In this paper, we present a learning framework based on a graph\nauto-encoder designed to exploit structural properties of sequencing data. The\nalgorithm is a neural network which essentially trains to ignore sequencing\nerrors and infers the posteriori probabilities of the origin of sequencing\nreads. Mixture components are then reconstructed by finding consensus of the\nreads determined to originate from the same genomic component. Results on\nrealistic synthetic as well as experimental data demonstrate that the proposed\nframework reliably assembles haplotypes and reconstructs viral communities,\noften significantly outperforming state-of-the-art techniques.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1911.05316v1",
            "date": "2019-11-13 06:32:48+00:00"
        },
        {
            "title": "Hyper-SAGNN: a self-attention based graph neural network for hypergraphs",
            "authors": [
                "Ruochi Zhang",
                "Yuesong Zou",
                "Jian Ma"
            ],
            "abstract": "Graph representation learning for hypergraphs can be used to extract patterns\namong higher-order interactions that are critically important in many real\nworld problems. Current approaches designed for hypergraphs, however, are\nunable to handle different types of hypergraphs and are typically not generic\nfor various learning tasks. Indeed, models that can predict variable-sized\nheterogeneous hyperedges have not been available. Here we develop a new\nself-attention based graph neural network called Hyper-SAGNN applicable to\nhomogeneous and heterogeneous hypergraphs with variable hyperedge sizes. We\nperform extensive evaluations on multiple datasets, including four benchmark\nnetwork datasets and two single-cell Hi-C datasets in genomics. We demonstrate\nthat Hyper-SAGNN significantly outperforms the state-of-the-art methods on\ntraditional tasks while also achieving great performance on a new task called\noutsider identification. Hyper-SAGNN will be useful for graph representation\nlearning to uncover complex higher-order interactions in different\napplications.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1911.02613v1",
            "date": "2019-11-06 20:10:24+00:00"
        },
        {
            "title": "Scaling structural learning with NO-BEARS to infer causal transcriptome networks",
            "authors": [
                "Hao-Chih Lee",
                "Matteo Danieletto",
                "Riccardo Miotto",
                "Sarah T. Cherng",
                "Joel T. Dudley"
            ],
            "abstract": "Constructing gene regulatory networks is a critical step in revealing disease\nmechanisms from transcriptomic data. In this work, we present NO-BEARS, a novel\nalgorithm for estimating gene regulatory networks. The NO-BEARS algorithm is\nbuilt on the basis of the NOTEARS algorithm with two improvements. First, we\npropose a new constraint and its fast approximation to reduce the computational\ncost of the NO-TEARS algorithm. Next, we introduce a polynomial regression loss\nto handle non-linearity in gene expressions. Our implementation utilizes modern\nGPU computation that can decrease the time of hours-long CPU computation to\nseconds. Using synthetic data, we demonstrate improved performance, both in\nprocessing time and accuracy, on inferring gene regulatory networks from gene\nexpression data.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1911.00081v1",
            "date": "2019-10-31 19:52:18+00:00"
        },
        {
            "title": "The TCGA Meta-Dataset Clinical Benchmark",
            "authors": [
                "Mandana Samiei",
                "Tobias W\u00fcrfl",
                "Tristan Deleu",
                "Martin Weiss",
                "Francis Dutil",
                "Thomas Fevens",
                "Genevi\u00e8ve Boucher",
                "Sebastien Lemieux",
                "Joseph Paul Cohen"
            ],
            "abstract": "Machine learning is bringing a paradigm shift to healthcare by changing the\nprocess of disease diagnosis and prognosis in clinics and hospitals. This\ndevelopment equips doctors and medical staff with tools to evaluate their\nhypotheses and hence make more precise decisions. Although most current\nresearch in the literature seeks to develop techniques and methods for\npredicting one particular clinical outcome, this approach is far from the\nreality of clinical decision making in which you have to consider several\nfactors simultaneously. In addition, it is difficult to follow the recent\nprogress concretely as there is a lack of consistency in benchmark datasets and\ntask definitions in the field of Genomics. To address the aforementioned\nissues, we provide a clinical Meta-Dataset derived from the publicly available\ndata hub called The Cancer Genome Atlas Program (TCGA) that contains 174 tasks.\nWe believe those tasks could be good proxy tasks to develop methods which can\nwork on a few samples of gene expression data. Also, learning to predict\nmultiple clinical variables using gene-expression data is an important task due\nto the variety of phenotypes in clinical problems and lack of samples for some\nof the rare variables. The defined tasks cover a wide range of clinical\nproblems including predicting tumor tissue site, white cell count, histological\ntype, family history of cancer, gender, and many others which we explain later\nin the paper. Each task represents an independent dataset. We use regression\nand neural network baselines for all the tasks using only 150 samples and\ncompare their performance.",
            "categories": [
                "cs.LG",
                "q-bio.QM",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1910.08636v1",
            "date": "2019-10-18 21:44:12+00:00"
        },
        {
            "title": "Deep Hyperedges: a Framework for Transductive and Inductive Learning on Hypergraphs",
            "authors": [
                "Josh Payne"
            ],
            "abstract": "From social networks to protein complexes to disease genomes to visual data,\nhypergraphs are everywhere. However, the scope of research studying deep\nlearning on hypergraphs is still quite sparse and nascent, as there has not yet\nexisted an effective, unified framework for using hyperedge and vertex\nembeddings jointly in the hypergraph context, despite a large body of prior\nwork that has shown the utility of deep learning over graphs and sets. Building\nupon these recent advances, we propose \\textit{Deep Hyperedges} (DHE), a\nmodular framework that jointly uses contextual and permutation-invariant vertex\nmembership properties of hyperedges in hypergraphs to perform classification\nand regression in transductive and inductive learning settings. In our\nexperiments, we use a novel random walk procedure and show that our model\nachieves and, in most cases, surpasses state-of-the-art performance on\nbenchmark datasets. Additionally, we study our framework's performance on a\nvariety of diverse, non-standard hypergraph datasets and propose several\navenues of future work to further enhance DHE.",
            "categories": [
                "cs.LG",
                "cs.SI",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1910.02633v1",
            "date": "2019-10-07 06:56:02+00:00"
        },
        {
            "title": "Scaling Object Detection by Transferring Classification Weights",
            "authors": [
                "Jason Kuen",
                "Federico Perazzi",
                "Zhe Lin",
                "Jianming Zhang",
                "Yap-Peng Tan"
            ],
            "abstract": "Large scale object detection datasets are constantly increasing their size in\nterms of the number of classes and annotations count. Yet, the number of\nobject-level categories annotated in detection datasets is an order of\nmagnitude smaller than image-level classification labels. State-of-the art\nobject detection models are trained in a supervised fashion and this limits the\nnumber of object classes they can detect. In this paper, we propose a novel\nweight transfer network (WTN) to effectively and efficiently transfer knowledge\nfrom classification network's weights to detection network's weights to allow\ndetection of novel classes without box supervision. We first introduce input\nand feature normalization schemes to curb the under-fitting during training of\na vanilla WTN. We then propose autoencoder-WTN (AE-WTN) which uses\nreconstruction loss to preserve classification network's information over all\nclasses in the target latent space to ensure generalization to novel classes.\nCompared to vanilla WTN, AE-WTN obtains absolute performance gains of 6% on two\nOpen Images evaluation sets with 500 seen and 57 novel classes respectively,\nand 25% on a Visual Genome evaluation set with 200 novel classes. The code is\navailable at https://github.com/xternalz/AE-WTN.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1909.06804v1",
            "date": "2019-09-15 13:59:29+00:00"
        },
        {
            "title": "Temporal FiLM: Capturing Long-Range Sequence Dependencies with Feature-Wise Modulations",
            "authors": [
                "Sawyer Birnbaum",
                "Volodymyr Kuleshov",
                "Zayd Enam",
                "Pang Wei Koh",
                "Stefano Ermon"
            ],
            "abstract": "Learning representations that accurately capture long-range dependencies in\nsequential inputs -- including text, audio, and genomic data -- is a key\nproblem in deep learning. Feed-forward convolutional models capture only\nfeature interactions within finite receptive fields while recurrent\narchitectures can be slow and difficult to train due to vanishing gradients.\nHere, we propose Temporal Feature-Wise Linear Modulation (TFiLM) -- a novel\narchitectural component inspired by adaptive batch normalization and its\nextensions -- that uses a recurrent neural network to alter the activations of\na convolutional model. This approach expands the receptive field of\nconvolutional sequence models with minimal computational overhead. Empirically,\nwe find that TFiLM significantly improves the learning speed and accuracy of\nfeed-forward neural networks on a range of generative and discriminative\nlearning tasks, including text classification and audio super-resolution",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1909.06628v3",
            "date": "2019-09-14 16:44:35+00:00"
        },
        {
            "title": "OncoNetExplainer: Explainable Predictions of Cancer Types Based on Gene Expression Data",
            "authors": [
                "Md. Rezaul Karim",
                "Michael Cochez",
                "Oya Beyan",
                "Stefan Decker",
                "Christoph Lange"
            ],
            "abstract": "The discovery of important biomarkers is a significant step towards\nunderstanding the molecular mechanisms of carcinogenesis; enabling accurate\ndiagnosis for, and prognosis of, a certain cancer type. Before recommending any\ndiagnosis, genomics data such as gene expressions(GE) and clinical outcomes\nneed to be analyzed. However, complex nature, high dimensionality, and\nheterogeneity in genomics data make the overall analysis challenging.\nConvolutional neural networks(CNN) have shown tremendous success in solving\nsuch problems. However, neural network models are perceived mostly as `black\nbox' methods because of their not well-understood internal functioning.\nHowever, interpretability is important to provide insights on why a given\ncancer case has a certain type. Besides, finding the most important biomarkers\ncan help in recommending more accurate treatments and drug repositioning. In\nthis paper, we propose a new approach called OncoNetExplainer to make\nexplainable predictions of cancer types based on GE data. We used genomics data\nabout 9,074 cancer patients covering 33 different cancer types from the\nPan-Cancer Atlas on which we trained CNN and VGG16 networks using\nguided-gradient class activation maps++(GradCAM++). Further, we generate\nclass-specific heat maps to identify significant biomarkers and computed\nfeature importance in terms of mean absolute impact to rank top genes across\nall the cancer types. Quantitative and qualitative analyses show that both\nmodels exhibit high confidence at predicting the cancer types correctly giving\nan average precision of 96.25%. To provide comparisons with the baselines, we\nidentified top genes, and cancer-specific driver genes using gradient boosted\ntrees and SHapley Additive exPlanations(SHAP). Finally, our findings were\nvalidated with the annotations provided by the TumorPortal.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1909.04169v1",
            "date": "2019-09-09 21:43:59+00:00"
        },
        {
            "title": "Large-Scale Local Causal Inference of Gene Regulatory Relationships",
            "authors": [
                "Ioan Gabriel Bucur",
                "Tom Claassen",
                "Tom Heskes"
            ],
            "abstract": "Gene regulatory networks play a crucial role in controlling an organism's\nbiological processes, which is why there is significant interest in developing\ncomputational methods that are able to extract their structure from\nhigh-throughput genetic data. Many of these computational methods are designed\nto infer individual regulatory relationships among genes from data on gene\nexpression. We propose a novel efficient Bayesian method for discovering local\ncausal relationships among triplets of (normally distributed) variables. In our\napproach, we score covariance structures for each triplet in one go and\nincorporate available background knowledge in the form of priors to derive\nposterior probabilities over local causal structures. Our method is flexible in\nthe sense that it allows for different types of causal structures and\nassumptions. We apply our approach to the task of learning causal regulatory\nrelationships among genes. We show that the proposed algorithm produces stable\nand conservative posterior probability estimates over local causal structures\nthat can be used to derive an honest ranking of the most meaningful regulatory\nrelationships. We demonstrate the stability and efficacy of our method both on\nsimulated data and on real-world data from an experiment on yeast.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN",
                "q-bio.MN",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1909.03818v2",
            "date": "2019-09-03 17:54:33+00:00"
        },
        {
            "title": "SAERMA: Stacked Autoencoder Rule Mining Algorithm for the Interpretation of Epistatic Interactions in GWAS for Extreme Obesity",
            "authors": [
                "Casimiro Aday Curbelo Monta\u00f1ez",
                "Paul Fergus",
                "Carl Chalmers",
                "Nurul Ahamed Hassain Malim",
                "Basma Abdulaimma",
                "Denis Reilly",
                "Francesco Falciani"
            ],
            "abstract": "One of the most important challenges in the analysis of high-throughput\ngenetic data is the development of efficient computational methods to identify\nstatistically significant Single Nucleotide Polymorphisms (SNPs). Genome-wide\nassociation studies (GWAS) use single-locus analysis where each SNP is\nindependently tested for association with phenotypes. The limitation with this\napproach, however, is its inability to explain genetic variation in complex\ndiseases. Alternative approaches are required to model the intricate\nrelationships between SNPs. Our proposed approach extends GWAS by combining\ndeep learning stacked autoencoders (SAEs) and association rule mining (ARM) to\nidentify epistatic interactions between SNPs. Following traditional GWAS\nquality control and association analysis, the most significant SNPs are\nselected and used in the subsequent analysis to investigate epistasis. SAERMA\ncontrols the classification results produced in the final fully connected\nmulti-layer feedforward artificial neural network (MLP) by manipulating the\ninterestingness measures, support and confidence, in the rule generation\nprocess. The best classification results were achieved with 204 SNPs compressed\nto 100 units (77% AUC, 77% SE, 68% SP, 53% Gini, logloss=0.58, and MSE=0.20),\nalthough it was possible to achieve 73% AUC (77% SE, 63% SP, 45% Gini,\nlogloss=0.62, and MSE=0.21) with 50 hidden units - both supported by close\nmodel interpretation.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1908.10166v1",
            "date": "2019-08-27 12:49:05+00:00"
        },
        {
            "title": "Integrated Multi-omics Analysis Using Variational Autoencoders: Application to Pan-cancer Classification",
            "authors": [
                "Xiaoyu Zhang",
                "Jingqing Zhang",
                "Kai Sun",
                "Xian Yang",
                "Chengliang Dai",
                "Yike Guo"
            ],
            "abstract": "Different aspects of a clinical sample can be revealed by multiple types of\nomics data. Integrated analysis of multi-omics data provides a comprehensive\nview of patients, which has the potential to facilitate more accurate clinical\ndecision making. However, omics data are normally high dimensional with large\nnumber of molecular features and relatively small number of available samples\nwith clinical labels. The \"dimensionality curse\" makes it challenging to train\na machine learning model using high dimensional omics data like DNA methylation\nand gene expression profiles. Here we propose an end-to-end deep learning model\ncalled OmiVAE to extract low dimensional features and classify samples from\nmulti-omics data. OmiVAE combines the basic structure of variational\nautoencoders with a classification network to achieve task-oriented feature\nextraction and multi-class classification. The training procedure of OmiVAE is\ncomprised of an unsupervised phase without the classifier and a supervised\nphase with the classifier. During the unsupervised phase, a hierarchical\ncluster structure of samples can be automatically formed without the need for\nlabels. And in the supervised phase, OmiVAE achieved an average classification\naccuracy of 97.49% after 10-fold cross-validation among 33 tumour types and\nnormal samples, which shows better performance than other existing methods. The\nOmiVAE model learned from multi-omics data outperformed that using only one\ntype of omics data, which indicates that the complementary information from\ndifferent omics datatypes provides useful insights for biomedical tasks like\ncancer classification.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1908.06278v1",
            "date": "2019-08-17 09:48:06+00:00"
        },
        {
            "title": "On Defending Against Label Flipping Attacks on Malware Detection Systems",
            "authors": [
                "Rahim Taheri",
                "Reza Javidan",
                "Mohammad Shojafar",
                "Zahra Pooranian",
                "Ali Miri",
                "Mauro Conti"
            ],
            "abstract": "Label manipulation attacks are a subclass of data poisoning attacks in\nadversarial machine learning used against different applications, such as\nmalware detection. These types of attacks represent a serious threat to\ndetection systems in environments having high noise rate or uncertainty, such\nas complex networks and Internet of Thing (IoT). Recent work in the literature\nhas suggested using the $K$-Nearest Neighboring (KNN) algorithm to defend\nagainst such attacks. However, such an approach can suffer from low to wrong\ndetection accuracy. In this paper, we design an architecture to tackle the\nAndroid malware detection problem in IoT systems. We develop an attack\nmechanism based on Silhouette clustering method, modified for mobile Android\nplatforms. We proposed two Convolutional Neural Network (CNN)-type deep\nlearning algorithms against this \\emph{Silhouette Clustering-based Label\nFlipping Attack (SCLFA)}. We show the effectiveness of these two defense\nalgorithms - \\emph{Label-based Semi-supervised Defense (LSD)} and\n\\emph{clustering-based Semi-supervised Defense (CSD)} - in correcting labels\nbeing attacked. We evaluate the performance of the proposed algorithms by\nvarying the various machine learning parameters on three Android datasets:\nDrebin, Contagio, and Genome and three types of features: API, intent, and\npermission. Our evaluation shows that using random forest feature selection and\nvarying ratios of features can result in an improvement of up to 19\\% accuracy\nwhen compared with the state-of-the-art method in the literature.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1908.04473v3",
            "date": "2019-08-13 03:31:33+00:00"
        },
        {
            "title": "Transcriptional Response of SK-N-AS Cells to Methamidophos",
            "authors": [
                "Akos Vertes",
                "Albert-Baskar Arul",
                "Peter Avar",
                "Andrew R. Korte",
                "Lida Parvin",
                "Ziad J. Sahab",
                "Deborah I. Bunin",
                "Merrill Knapp",
                "Denise Nishita",
                "Andrew Poggio",
                "Mark-Oliver Stehr",
                "Carolyn L. Talcott",
                "Brian M. Davis",
                "Christine A. Morton",
                "Christopher J. Sevinsky",
                "Maria I. Zavodszky"
            ],
            "abstract": "Transcriptomics response of SK-N-AS cells to methamidophos (an acetylcholine\nesterase inhibitor) exposure was measured at 10 time points between 0.5 and 48\nh. The data was analyzed using a combination of traditional statistical methods\nand novel machine learning algorithms for detecting anomalous behavior and\ninfer causal relations between time profiles. We identified several processes\nthat appeared to be upregulated in cells treated with methamidophos including:\nunfolded protein response, response to cAMP, calcium ion response, and\ncell-cell signaling. The data confirmed the expected consequence of\nacetylcholine buildup. In addition, transcripts with potentially key roles were\nidentified and causal networks relating these transcripts were inferred using\ntwo different computational methods: Siamese convolutional networks and time\nwarp causal inference. Two types of anomaly detection algorithms, one based on\nAutoencoders and the other one based on Generative Adversarial Networks (GANs),\nwere applied to narrow down the set of relevant transcripts.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "q-bio.CB",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1908.03841v1",
            "date": "2019-08-11 02:53:56+00:00"
        },
        {
            "title": "Machine Learning based Prediction of Hierarchical Classification of Transposable Elements",
            "authors": [
                "Manisha Panta",
                "Avdesh Mishra",
                "Md Tamjidul Hoque",
                "Joel Atallah"
            ],
            "abstract": "Transposable Elements (TEs) or jumping genes are the DNA sequences that have\nan intrinsic capability to move within a host genome from one genomic location\nto another. Studies show that the presence of a TE within or adjacent to a\nfunctional gene may alter its expression. TEs can also cause an increase in the\nrate of mutation and can even mediate duplications and large insertions and\ndeletions in the genome, promoting gross genetic rearrangements. Thus, the\nproper classification of the identified jumping genes is essential to\nunderstand their genetic and evolutionary effects in the genome. While\ncomputational methods have been developed that perform either binary\nclassification or multi-label classification of TEs, few studies have focused\non their hierarchical classification. The state-of-the-art machine learning\nclassification method utilizes a Multi-Layer Perceptron (MLP), a class of\nneural network, for hierarchical classification of TEs. However, the existing\nmethods have limited accuracy in classifying TEs. A more effective classifier,\nwhich can explain the role of TEs in germline and somatic evolution, is needed.\nIn this study, we examine the performance of a variety of machine learning (ML)\nmethods. And eventually, propose a robust approach for the hierarchical\nclassification of TEs, with higher accuracy, using Support Vector Machines\n(SVM).",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1907.01674v3",
            "date": "2019-07-02 23:09:57+00:00"
        },
        {
            "title": "Prediction of Small Molecule Kinase Inhibitors for Chemotherapy Using Deep Learning",
            "authors": [
                "Niranjan Balachandar",
                "Christine Liu",
                "Winston Wang"
            ],
            "abstract": "The current state of cancer therapeutics has been moving away from\none-size-fits-all cytotoxic chemotherapy, and towards a more individualized and\nspecific approach involving the targeting of each tumor's genetic\nvulnerabilities. Different tumors, even of the same type, may be more reliant\non certain cellular pathways more than others. With modern advancements in our\nunderstanding of cancer genome sequencing, these pathways can be discovered.\nInvestigating each of the millions of possible small molecule inhibitors for\neach kinase in vitro, however, would be extremely expensive and time consuming.\nThis project focuses on predicting the inhibition activity of small molecules\ntargeting 8 different kinases using multiple deep learning models. We trained\nfingerprint-based MLPs and simplified molecular-input line-entry specification\n(SMILES)-based recurrent neural networks (RNNs) and molecular graph\nconvolutional networks (GCNs) to accurately predict inhibitory activity\ntargeting these 8 kinases.",
            "categories": [
                "q-bio.BM",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1907.00329v1",
            "date": "2019-06-30 06:36:46+00:00"
        },
        {
            "title": "Simplex2Vec embeddings for community detection in simplicial complexes",
            "authors": [
                "Jacob Charles Wright Billings",
                "Mirko Hu",
                "Giulia Lerda",
                "Alexey N. Medvedev",
                "Francesco Mottes",
                "Adrian Onicas",
                "Andrea Santoro",
                "Giovanni Petri"
            ],
            "abstract": "Topological representations are rapidly becoming a popular way to capture and\nencode higher-order interactions in complex systems. They have found\napplications in disciplines as different as cancer genomics, brain function,\nand computational social science, in representing both descriptive features of\ndata and inference models. While intense research has focused on the\nconnectivity and homological features of topological representations,\nsurprisingly scarce attention has been given to the investigation of the\ncommunity structures of simplicial complexes. To this end, we adopt recent\nadvances in symbolic embeddings to compute and visualize the community\nstructures of simplicial complexes. We first investigate the stability\nproperties of embedding obtained for synthetic simplicial complexes to the\npresence of higher order interactions. We then focus on complexes arising from\nsocial and brain functional data and show how higher order interactions can be\nleveraged to improve clustering detection and assess the effect of higher order\ninteraction on individual nodes. We conclude delineating limitations and\ndirections for extension of this work.",
            "categories": [
                "physics.soc-ph",
                "cs.LG",
                "cs.SI",
                "math.AT"
            ],
            "link": "http://arxiv.org/pdf/1906.09068v1",
            "date": "2019-06-21 11:13:56+00:00"
        },
        {
            "title": "Convolutional neural network models for cancer type prediction based on gene expression",
            "authors": [
                "Milad Mostavi",
                "Yu-Chiao Chiu",
                "Yufei Huang",
                "Yidong Chen"
            ],
            "abstract": "Background Precise prediction of cancer types is vital for cancer diagnosis\nand therapy. Important cancer marker genes can be inferred through predictive\nmodel. Several studies have attempted to build machine learning models for this\ntask however none has taken into consideration the effects of tissue of origin\nthat can potentially bias the identification of cancer markers. Results In this\npaper, we introduced several Convolutional Neural Network (CNN) models that\ntake unstructured gene expression inputs to classify tumor and non-tumor\nsamples into their designated cancer types or as normal. Based on different\ndesigns of gene embeddings and convolution schemes, we implemented three CNN\nmodels: 1D-CNN, 2D-Vanilla-CNN, and 2D-Hybrid-CNN. The models were trained and\ntested on combined 10,340 samples of 33 cancer types and 731 matched normal\ntissues of The Cancer Genome Atlas (TCGA). Our models achieved excellent\nprediction accuracies (93.9-95.0%) among 34 classes (33 cancers and normal).\nFurthermore, we interpreted one of the models, known as 1D-CNN model, with a\nguided saliency technique and identified a total of 2,090 cancer markers (108\nper class). The concordance of differential expression of these markers between\nthe cancer type they represent and others is confirmed. In breast cancer, for\ninstance, our model identified well-known markers, such as GATA3 and ESR1.\nFinally, we extended the 1D-CNN model for prediction of breast cancer subtypes\nand achieved an average accuracy of 88.42% among 5 subtypes. The codes can be\nfound at https://github.com/chenlabgccri/CancerTypePrediction.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1906.07794v1",
            "date": "2019-06-18 20:27:35+00:00"
        },
        {
            "title": "A Variational Autoencoder for Probabilistic Non-Negative Matrix Factorisation",
            "authors": [
                "Steven Squires",
                "Adam Pr\u00fcgel Bennett",
                "Mahesan Niranjan"
            ],
            "abstract": "We introduce and demonstrate the variational autoencoder (VAE) for\nprobabilistic non-negative matrix factorisation (PAE-NMF). We design a network\nwhich can perform non-negative matrix factorisation (NMF) and add in aspects of\na VAE to make the coefficients of the latent space probabilistic. By\nrestricting the weights in the final layer of the network to be non-negative\nand using the non-negative Weibull distribution we produce a probabilistic form\nof NMF which allows us to generate new data and find a probability distribution\nthat effectively links the latent and input variables. We demonstrate the\neffectiveness of PAE-NMF on three heterogeneous datasets: images, financial\ntime series and genomic.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1906.05912v1",
            "date": "2019-06-13 20:05:15+00:00"
        },
        {
            "title": "Multiway clustering via tensor block models",
            "authors": [
                "Miaoyan Wang",
                "Yuchen Zeng"
            ],
            "abstract": "We consider the problem of identifying multiway block structure from a large\nnoisy tensor. Such problems arise frequently in applications such as genomics,\nrecommendation system, topic modeling, and sensor network localization. We\npropose a tensor block model, develop a unified least-square estimation, and\nobtain the theoretical accuracy guarantees for multiway clustering. The\nstatistical convergence of the estimator is established, and we show that the\nassociated clustering procedure achieves partition consistency. A sparse\nregularization is further developed for identifying important blocks with\nelevated means. The proposal handles a broad range of data types, including\nbinary, continuous, and hybrid observations. Through simulation and application\nto two real datasets, we demonstrate the outperformance of our approach over\nprevious methods.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.ME",
                "stat.TH",
                "62H25, 62H12"
            ],
            "link": "http://arxiv.org/pdf/1906.03807v4",
            "date": "2019-06-10 06:07:41+00:00"
        },
        {
            "title": "Likelihood Ratios for Out-of-Distribution Detection",
            "authors": [
                "Jie Ren",
                "Peter J. Liu",
                "Emily Fertig",
                "Jasper Snoek",
                "Ryan Poplin",
                "Mark A. DePristo",
                "Joshua V. Dillon",
                "Balaji Lakshminarayanan"
            ],
            "abstract": "Discriminative neural networks offer little or no performance guarantees when\ndeployed on data not generated by the same process as the training\ndistribution. On such out-of-distribution (OOD) inputs, the prediction may not\nonly be erroneous, but confidently so, limiting the safe deployment of\nclassifiers in real-world applications. One such challenging application is\nbacteria identification based on genomic sequences, which holds the promise of\nearly detection of diseases, but requires a model that can output low\nconfidence predictions on OOD genomic sequences from new bacteria that were not\npresent in the training data. We introduce a genomics dataset for OOD detection\nthat allows other researchers to benchmark progress on this important problem.\nWe investigate deep generative model based approaches for OOD detection and\nobserve that the likelihood score is heavily affected by population level\nbackground statistics. We propose a likelihood ratio method for deep generative\nmodels which effectively corrects for these confounding background statistics.\nWe benchmark the OOD detection performance of the proposed method against\nexisting approaches on the genomics dataset and show that our method achieves\nstate-of-the-art performance. We demonstrate the generality of the proposed\nmethod by showing that it significantly improves OOD detection when applied to\ndeep generative models of images.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1906.02845v2",
            "date": "2019-06-07 00:01:42+00:00"
        },
        {
            "title": "Incorporating Biological Knowledge with Factor Graph Neural Network for Interpretable Deep Learning",
            "authors": [
                "Tianle Ma",
                "Aidong Zhang"
            ],
            "abstract": "While deep learning has achieved great success in many fields, one common\ncriticism about deep learning is its lack of interpretability. In most cases,\nthe hidden units in a deep neural network do not have a clear semantic meaning\nor correspond to any physical entities. However, model interpretability and\nexplainability are crucial in many biomedical applications. To address this\nchallenge, we developed the Factor Graph Neural Network model that is\ninterpretable and predictable by combining probabilistic graphical models with\ndeep learning. We directly encode biological knowledge such as Gene Ontology as\na factor graph into the model architecture, making the model transparent and\ninterpretable. Furthermore, we devised an attention mechanism that can capture\nmulti-scale hierarchical interactions among biological entities such as genes\nand Gene Ontology terms. With parameter sharing mechanism, the unrolled Factor\nGraph Neural Network model can be trained with stochastic depth and generalize\nwell. We applied our model to two cancer genomic datasets to predict target\nclinical variables and achieved better results than other traditional machine\nlearning and deep learning models. Our model can also be used for gene set\nenrichment analysis and selecting Gene Ontology terms that are important to\ntarget clinical variables.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1906.00537v1",
            "date": "2019-06-03 02:51:40+00:00"
        },
        {
            "title": "ncRNA Classification with Graph Convolutional Networks",
            "authors": [
                "Emanuele Rossi",
                "Federico Monti",
                "Michael Bronstein",
                "Pietro Li\u00f2"
            ],
            "abstract": "Non-coding RNA (ncRNA) are RNA sequences which don't code for a gene but\ninstead carry important biological functions. The task of ncRNA classification\nconsists in classifying a given ncRNA sequence into its family. While it has\nbeen shown that the graph structure of an ncRNA sequence folding is of great\nimportance for the prediction of its family, current methods make use of\nmachine learning classifiers on hand-crafted graph features. We improve on the\nstate-of-the-art for this task with a graph convolutional network model which\nachieves an accuracy of 85.73% and an F1-score of 85.61% over 13 classes.\nMoreover, our model learns in an end-to-end fashion from the raw RNA graphs and\nremoves the need for expensive feature extraction. To the best of our\nknowledge, this also represents the first successful application of graph\nconvolutional networks to RNA folding data.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1905.06515v1",
            "date": "2019-05-16 03:54:16+00:00"
        },
        {
            "title": "On Exploring Undetermined Relationships for Visual Relationship Detection",
            "authors": [
                "Yibing Zhan",
                "Jun Yu",
                "Ting Yu",
                "Dacheng Tao"
            ],
            "abstract": "In visual relationship detection, human-notated relationships can be regarded\nas determinate relationships. However, there are still large amount of\nunlabeled data, such as object pairs with less significant relationships or\neven with no relationships. We refer to these unlabeled but potentially useful\ndata as undetermined relationships. Although a vast body of literature exists,\nfew methods exploit these undetermined relationships for visual relationship\ndetection.\n  In this paper, we explore the beneficial effect of undetermined relationships\non visual relationship detection. We propose a novel multi-modal feature based\nundetermined relationship learning network (MF-URLN) and achieve great\nimprovements in relationship detection. In detail, our MF-URLN automatically\ngenerates undetermined relationships by comparing object pairs with\nhuman-notated data according to a designed criterion. Then, the MF-URLN\nextracts and fuses features of object pairs from three complementary modals:\nvisual, spatial, and linguistic modals. Further, the MF-URLN proposes two\ncorrelated subnetworks: one subnetwork decides the determinate confidence, and\nthe other predicts the relationships. We evaluate the MF-URLN on two datasets:\nthe Visual Relationship Detection (VRD) and the Visual Genome (VG) datasets.\nThe experimental results compared with state-of-the-art methods verify the\nsignificant improvements made by the undetermined relationships, e.g., the\ntop-50 relation detection recall improves from 19.5% to 23.9% on the VRD\ndataset.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1905.01595v1",
            "date": "2019-05-05 03:57:12+00:00"
        },
        {
            "title": "Generating protein sequences from antibiotic resistance genes data using Generative Adversarial Networks",
            "authors": [
                "Prabal Chhibbar",
                "Arpit Joshi"
            ],
            "abstract": "We introduce a method to generate synthetic protein sequences which are\npredicted to be resistant to certain antibiotics. We did this using 6,023 genes\nthat were predicted to be resistant to antibiotics in the intestinal region of\nthe human gut and were fed as input to a Wasserstein generative adversarial\nnetwork (W-GAN) model a variant to the original generative adversarial model\nwhich has been known to perform efficiently when it comes to mimicking the\ndistribution of the real data in order to generate new data which is similar in\nstyle to the original data which was fed as the training data",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1904.13240v1",
            "date": "2019-04-28 11:34:03+00:00"
        },
        {
            "title": "MinCall - MinION end2end convolutional deep learning basecaller",
            "authors": [
                "Neven Miculini\u0107",
                "Marko Ratkovi\u0107",
                "Mile \u0160iki\u0107"
            ],
            "abstract": "The Oxford Nanopore Technologies's MinION is the first portable DNA\nsequencing device. It is capable of producing long reads, over 100 kBp were\nreported. However, it has significantly higher error rate than other methods.\nIn this study, we present MinCall, an end2end basecaller model for the MinION.\nThe model is based on deep learning and uses convolutional neural networks\n(CNN) in its implementation. For extra performance, it uses cutting edge deep\nlearning techniques and architectures, batch normalization and Connectionist\nTemporal Classification (CTC) loss. The best performing deep learning model\nachieves 91.4% median match rate on E. Coli dataset using R9 pore chemistry and\n1D reads.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1904.10337v1",
            "date": "2019-04-22 16:37:00+00:00"
        },
        {
            "title": "Performance-Efficiency Trade-off of Low-Precision Numerical Formats in Deep Neural Networks",
            "authors": [
                "Zachariah Carmichael",
                "Hamed F. Langroudi",
                "Char Khazanov",
                "Jeffrey Lillie",
                "John L. Gustafson",
                "Dhireesha Kudithipudi"
            ],
            "abstract": "Deep neural networks (DNNs) have been demonstrated as effective prognostic\nmodels across various domains, e.g. natural language processing, computer\nvision, and genomics. However, modern-day DNNs demand high compute and memory\nstorage for executing any reasonably complex task. To optimize the inference\ntime and alleviate the power consumption of these networks, DNN accelerators\nwith low-precision representations of data and DNN parameters are being\nactively studied. An interesting research question is in how low-precision\nnetworks can be ported to edge-devices with similar performance as\nhigh-precision networks. In this work, we employ the fixed-point, floating\npoint, and posit numerical formats at $\\leq$8-bit precision within a DNN\naccelerator, Deep Positron, with exact multiply-and-accumulate (EMAC) units for\ninference. A unified analysis quantifies the trade-offs between overall network\nefficiency and performance across five classification tasks. Our results\nindicate that posits are a natural fit for DNN inference, outperforming at\n$\\leq$8-bit precision, and can be realized with competitive resource\nrequirements relative to those of floating point.",
            "categories": [
                "cs.DC",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1903.10584v1",
            "date": "2019-03-25 20:21:45+00:00"
        },
        {
            "title": "A Nonparametric Multi-view Model for Estimating Cell Type-Specific Gene Regulatory Networks",
            "authors": [
                "Cassandra Burdziak",
                "Elham Azizi",
                "Sandhya Prabhakaran",
                "Dana Pe'er"
            ],
            "abstract": "We present a Bayesian hierarchical multi-view mixture model termed Symphony\nthat simultaneously learns clusters of cells representing cell types and their\nunderlying gene regulatory networks by integrating data from two views:\nsingle-cell gene expression data and paired epigenetic data, which is\ninformative of gene-gene interactions. This model improves interpretation of\nclusters as cell types with similar expression patterns as well as regulatory\nnetworks driving expression, by explaining gene-gene covariances with the\nbiological machinery regulating gene expression. We show the theoretical\nadvantages of the multi-view learning approach and present a Variational EM\ninference procedure. We demonstrate superior performance on both synthetic data\nand real genomic data with subtypes of peripheral blood cells compared to other\nmethods.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN",
                "q-bio.MN",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1902.08138v1",
            "date": "2019-02-21 16:55:28+00:00"
        },
        {
            "title": "AnomiGAN: Generative adversarial networks for anonymizing private medical data",
            "authors": [
                "Ho Bae",
                "Dahuin Jung",
                "Sungroh Yoon"
            ],
            "abstract": "Typical personal medical data contains sensitive information about\nindividuals. Storing or sharing the personal medical data is thus often risky.\nFor example, a short DNA sequence can provide information that can not only\nidentify an individual, but also his or her relatives. Nonetheless, most\ncountries and researchers agree on the necessity of collecting personal medical\ndata. This stems from the fact that medical data, including genomic data, are\nan indispensable resource for further research and development regarding\ndisease prevention and treatment. To prevent personal medical data from being\nmisused, techniques to reliably preserve sensitive information should be\ndeveloped for real world application. In this paper, we propose a framework\ncalled anonymized generative adversarial networks (AnomiGAN), to improve the\nmaintenance of privacy of personal medical data, while also maintaining high\nprediction performance. We compared our method to state-of-the-art techniques\nand observed that our method preserves the same level of privacy as\ndifferential privacy (DP), but had better prediction results. We also observed\nthat there is a trade-off between privacy and performance results depending on\nthe degree of preservation of the original data. Here, we provide a\nmathematical overview of our proposed model and demonstrate its validation\nusing UCI machine learning repository datasets in order to highlight its\nutility in practice. Experimentally, our approach delivers a better performance\ncompared to that of the DP approach.",
            "categories": [
                "cs.CR",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1901.11313v1",
            "date": "2019-01-31 11:38:58+00:00"
        },
        {
            "title": "Distinguishing between Normal and Cancer Cells Using Autoencoder Node Saliency",
            "authors": [
                "Ya Ju Fan",
                "Jonathan E. Allen",
                "Sam Ade Jacobs",
                "Brian C. Van Essen"
            ],
            "abstract": "Gene expression profiles have been widely used to characterize patterns of\ncellular responses to diseases. As data becomes available, scalable learning\ntoolkits become essential to processing large datasets using deep learning\nmodels to model complex biological processes. We present an autoencoder to\ncapture nonlinear relationships recovered from gene expression profiles. The\nautoencoder is a nonlinear dimension reduction technique using an artificial\nneural network, which learns hidden representations of unlabeled data. We train\nthe autoencoder on a large collection of tumor samples from the National Cancer\nInstitute Genomic Data Commons, and obtain a generalized and unsupervised\nlatent representation. We leverage a HPC-focused deep learning toolkit,\nLivermore Big Artificial Neural Network (LBANN) to efficiently parallelize the\ntraining algorithm, reducing computation times from several hours to a few\nminutes. With the trained autoencoder, we generate latent representations of a\nsmall dataset, containing pairs of normal and cancer cells of various tumor\ntypes. A novel measure called autoencoder node saliency (ANS) is introduced to\nidentify the hidden nodes that best differentiate various pairs of cells. We\ncompare our findings of the best classifying nodes with principal component\nanalysis and the visualization of t-distributed stochastic neighbor embedding.\nWe demonstrate that the autoencoder effectively extracts distinct gene features\nfor multiple learning tasks in the dataset.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1901.11152v1",
            "date": "2019-01-30 23:59:20+00:00"
        },
        {
            "title": "Learning a Generative Model of Cancer Metastasis",
            "authors": [
                "Benjamin Kompa",
                "Beau Coker"
            ],
            "abstract": "We introduce a Unified Disentanglement Network (UFDN) trained on The Cancer\nGenome Atlas (TCGA). We demonstrate that the UFDN learns a biologically\nrelevant latent space of gene expression data by applying our network to two\nclassification tasks of cancer status and cancer type. Our UFDN specific\nalgorithms perform comparably to random forest methods. The UFDN allows for\ncontinuous, partial interpolation between distinct cancer types. Furthermore,\nwe perform an analysis of differentially expressed genes between skin cutaneous\nmelanoma(SKCM) samples and the same samples interpolated into glioblastoma\n(GBM). We demonstrate that our interpolations learn relevant metagenes that\nrecapitulate known glioblastoma mechanisms and suggest possible starting points\nfor investigations into the metastasis of SKCM into GBM.",
            "categories": [
                "q-bio.QM",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1901.06023v1",
            "date": "2019-01-17 22:39:41+00:00"
        },
        {
            "title": "Machine-learning a virus assembly fitness landscape",
            "authors": [
                "Pierre-Philippe Dechant",
                "Yang-Hui He"
            ],
            "abstract": "Realistic evolutionary fitness landscapes are notoriously difficult to\nconstruct. A recent cutting-edge model of virus assembly consists of a\ndodecahedral capsid with $12$ corresponding packaging signals in three affinity\nbands. This whole genome/phenotype space consisting of $3^{12}$ genomes has\nbeen explored via computationally expensive stochastic assembly models, giving\na fitness landscape in terms of the assembly efficiency. Using latest\nmachine-learning techniques by establishing a neural network, we show that the\nintensive computation can be short-circuited in a matter of minutes to\nastounding accuracy.",
            "categories": [
                "q-bio.BM",
                "cs.LG",
                "q-bio.QM",
                "stat.ML",
                "68Txx, 97R40, 92B20, 92Bxx, 82Dxx, 82D80"
            ],
            "link": "http://arxiv.org/pdf/1901.05051v1",
            "date": "2019-01-13 12:17:02+00:00"
        },
        {
            "title": "Drug cell line interaction prediction",
            "authors": [
                "Pengfei Liu"
            ],
            "abstract": "Understanding the phenotypic drug response on cancer cell lines plays a vital\nrule in anti-cancer drug discovery and re-purposing. The Genomics of Drug\nSensitivity in Cancer (GDSC) database provides open data for researchers in\nphenotypic screening to test their models and methods. Previously, most\nresearch in these areas starts from the fingerprints or features of drugs,\ninstead of their structures. In this paper, we introduce a model for phenotypic\nscreening, which is called twin Convolutional Neural Network for drugs in\nSMILES format (tCNNS). tCNNS is comprised of CNN input channels for drugs in\nSMILES format and cancer cell lines respectively. Our model achieves $0.84$ for\nthe coefficient of determinant($R^2$) and $0.92$ for Pearson\ncorrelation($R_p$), which are significantly better than previous\nworks\\cite{ammad2014integrative,haider2015copula,menden2013machine}. Besides\nthese statistical metrics, tCNNS also provides some insights into phenotypic\nscreening.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1812.11178v1",
            "date": "2018-12-28 09:14:16+00:00"
        },
        {
            "title": "A Method to Facilitate Cancer Detection and Type Classification from Gene Expression Data using a Deep Autoencoder and Neural Network",
            "authors": [
                "Xi Chen",
                "Jin Xie",
                "Qingcong Yuan"
            ],
            "abstract": "With the increased affordability and availability of whole-genome sequencing,\nlarge-scale and high-throughput gene expression is widely used to characterize\ndiseases, including cancers. However, establishing specificity in cancer\ndiagnosis using gene expression data continues to pose challenges due to the\nhigh dimensionality and complexity of the data. Here we present models of deep\nlearning (DL) and apply them to gene expression data for the diagnosis and\ncategorization of cancer. In this study, we have developed two DL models using\nmessenger ribonucleic acid (mRNA) datasets available from the Genomic Data\nCommons repository. Our models achieved 98% accuracy in cancer detection, with\nfalse negative and false positive rates below 1.7%. In our results, we\ndemonstrated that 18 out of 32 cancer-typing classifications achieved more than\n90% accuracy. Due to the limitation of a small sample size (less than 50\nobservations), certain cancers could not achieve a higher accuracy in typing\nclassification, but still achieved high accuracy for the cancer detection task.\nTo validate our models, we compared them with traditional statistical models.\nThe main advantage of our models over traditional cancer detection is the\nability to use data from various cancer types to automatically form features to\nenhance the detection and diagnosis of a specific cancer type.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1812.08674v1",
            "date": "2018-12-20 16:22:51+00:00"
        },
        {
            "title": "METCC: METric learning for Confounder Control Making distance matter in high dimensional biological analysis",
            "authors": [
                "Kabir Manghnani",
                "Adam Drake",
                "Nathan Wan",
                "Imran Haque"
            ],
            "abstract": "High-dimensional data acquired from biological experiments such as next\ngeneration sequencing are subject to a number of confounding effects. These\neffects include both technical effects, such as variation across batches from\ninstrument noise or sample processing, or institution-specific differences in\nsample acquisition and physical handling, as well as biological effects arising\nfrom true but irrelevant differences in the biology of each sample, such as age\nbiases in diseases. Prior work has used linear methods to adjust for such batch\neffects. Here, we apply contrastive metric learning by a non-linear triplet\nnetwork to optimize the ability to distinguish biologically distinct sample\nclasses in the presence of irrelevant technical and biological variation. Using\nwhole-genome cell-free DNA data from 817 patients, we demonstrate that our\napproach, METric learning for Confounder Control (METCC), is able to match or\nexceed the classification performance achieved using a best-in-class linear\nmethod (HCP) or no normalization. Critically, results from METCC appear less\nconfounded by irrelevant technical variables like institution and batch than\nthose from other methods even without access to high quality metadata\ninformation required by many existing techniques; offering hope for improved\ngeneralization.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1812.03188v1",
            "date": "2018-12-07 19:20:43+00:00"
        },
        {
            "title": "Privacy-Preserving Distributed Deep Learning for Clinical Data",
            "authors": [
                "Brett K. Beaulieu-Jones",
                "William Yuan",
                "Samuel G. Finlayson",
                "Zhiwei Steven Wu"
            ],
            "abstract": "Deep learning with medical data often requires larger samples sizes than are\navailable at single providers. While data sharing among institutions is\ndesirable to train more accurate and sophisticated models, it can lead to\nsevere privacy concerns due the sensitive nature of the data. This problem has\nmotivated a number of studies on distributed training of neural networks that\ndo not require direct sharing of the training data. However, simple distributed\ntraining does not offer provable privacy guarantees to satisfy technical safe\nstandards and may reveal information about the underlying patients. We present\na method to train neural networks for clinical data in a distributed fashion\nunder differential privacy. We demonstrate these methods on two datasets that\ninclude information from multiple independent sites, the eICU collaborative\nResearch Database and The Cancer Genome Atlas.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1812.01484v1",
            "date": "2018-12-04 15:25:29+00:00"
        },
        {
            "title": "Integrating omics and MRI data with kernel-based tests and CNNs to identify rare genetic markers for Alzheimer's disease",
            "authors": [
                "Stefan Konigorski",
                "Shahryar Khorasani",
                "Christoph Lippert"
            ],
            "abstract": "For precision medicine and personalized treatment, we need to identify\npredictive markers of disease. We focus on Alzheimer's disease (AD), where\nmagnetic resonance imaging scans provide information about the disease status.\nBy combining imaging with genome sequencing, we aim at identifying rare genetic\nmarkers associated with quantitative traits predicted from convolutional neural\nnetworks (CNNs), which traditionally have been derived manually by experts.\nKernel-based tests are a powerful tool for associating sets of genetic\nvariants, but how to optimally model rare genetic variants is still an open\nresearch question. We propose a generalized set of kernels that incorporate\nprior information from various annotations and multi-omics data. In the\nanalysis of data from the Alzheimer's Disease Neuroimaging Initiative (ADNI),\nwe evaluate whether (i) CNNs yield precise and reliable brain traits, and (ii)\nthe novel kernel-based tests can help to identify loci associated with AD. The\nresults indicate that CNNs provide a fast, scalable and precise tool to derive\nquantitative AD traits and that new kernels integrating domain knowledge can\nyield higher power in association tests of very rare variants.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1812.00448v2",
            "date": "2018-12-02 19:10:22+00:00"
        },
        {
            "title": "Rank Projection Trees for Multilevel Neural Network Interpretation",
            "authors": [
                "Jonathan Warrell",
                "Hussein Mohsen",
                "Mark Gerstein"
            ],
            "abstract": "A variety of methods have been proposed for interpreting nodes in deep neural\nnetworks, which typically involve scoring nodes at lower layers with respect to\ntheir effects on the output of higher-layer nodes (where lower and higher\nlayers are closer to the input and output layers, respectively). However, we\nmay be interested in picking out a prioritized collection of subsets of the\ninputs across a range of scales according to their importance for an output\nnode, and not simply a prioritized ranking across the inputs as singletons.\nSuch a situation may arise in biological applications, for instance, where we\nare interested in epistatic effects between groups of genes in determining a\ntrait of interest. Here, we outline a flexible framework which may be used to\ngenerate multiscale network interpretations, using any previously defined\nscoring function. We demonstrate the ability of our method to pick out\nbiologically important genes and gene sets in the domains of cancer and\npsychiatric genomics.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1812.00172v1",
            "date": "2018-12-01 08:07:57+00:00"
        },
        {
            "title": "Interlacing Personal and Reference Genomes for Machine Learning Disease-Variant Detection",
            "authors": [
                "Luke R Harries",
                "Suyi Zhang",
                "Geoffroy Dubourg-Felonneau",
                "James H R Farmery",
                "Jonathan Sinai",
                "Belle Taylor",
                "Nirmesh Patel",
                "John W Cassidy",
                "John Shawe-Taylor",
                "Harry W Clifford"
            ],
            "abstract": "DNA sequencing to identify genetic variants is becoming increasingly valuable\nin clinical settings. Assessment of variants in such sequencing data is\ncommonly implemented through Bayesian heuristic algorithms. Machine learning\nhas shown great promise in improving on these variant calls, but the input for\nthese is still a standardized \"pile-up\" image, which is not always best suited.\nIn this paper, we present a novel method for generating images from DNA\nsequencing data, which interlaces the human reference genome with personalized\nsequencing output, to maximize usage of sequencing reads and improve machine\nlearning algorithm performance. We demonstrate the success of this in improving\nstandard germline variant calling. We also furthered this approach to include\nsomatic variant calling across tumor/normal data with Siamese networks. These\napproaches can be used in machine learning applications on sequencing data with\nthe hope of improving clinical outcomes, and are freely available for\nnoncommercial use at www.ccg.ai.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1811.11674v1",
            "date": "2018-11-26 15:38:29+00:00"
        },
        {
            "title": "Group induced graphical lasso allows for discovery of molecular pathways-pathways interactions",
            "authors": [
                "Veronica Tozzo",
                "Federico Tomasi",
                "Margherita Squillario",
                "Annalisa Barla"
            ],
            "abstract": "Complex systems may contain heterogeneous types of variables that interact in\na multi-level and multi-scale manner. In this context, high-level layers may\nconsidered as groups of variables interacting in lower-level layers. This is\nparticularly true in biology, where, for example, genes are grouped in pathways\nand two types of interactions are present: pathway-pathway interactions and\ngene-gene interactions. However, from data it is only possible to measure the\nexpression of genes while it is impossible to directly measure the activity of\npathways. Nevertheless, the knowledge on the inter-dependence between the\ngroups and the variables allows for a multi-layer network inference, on both\nobserved variables and groups, even if no direct information on the latter is\npresent in the data (hence groups are considered as latent). In this paper, we\npropose an extension of the latent graphical lasso method that leverages on the\nknowledge of the inter-links between the hidden (groups) and observed layers.\nThe method exploits the knowledge of group structure that influence the\nbehaviour of observed variables to retrieve a two layers network. Its efficacy\nwas tested on synthetic data to check its ability in retrieving the network\nstructure compared to the ground truth. We present a case study on\nNeuroblastoma, which shows how our multi-level inference is relevant in real\ncontexts to infer biologically meaningful connections.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1811.09673v1",
            "date": "2018-11-21 10:39:59+00:00"
        },
        {
            "title": "Synergistic Drug Combination Prediction by Integrating Multi-omics Data in Deep Learning Models",
            "authors": [
                "Tianyu Zhang",
                "Liwei Zhang",
                "Philip R. O. Payne",
                "Fuhai Li"
            ],
            "abstract": "Drug resistance is still a major challenge in cancer therapy. Drug\ncombination is expected to overcome drug resistance. However, the number of\npossible drug combinations is enormous, and thus it is infeasible to\nexperimentally screen all effective drug combinations considering the limited\nresources. Therefore, computational models to predict and prioritize effective\ndrug combinations is important for combinatory therapy discovery in cancer. In\nthis study, we proposed a novel deep learning model, AuDNNsynergy, to\nprediction drug combinations by integrating multi-omics data and chemical\nstructure data. In specific, three autoencoders were trained using the gene\nexpression, copy number and genetic mutation data of all tumor samples from The\nCancer Genome Atlas. Then the physicochemical properties of drugs combined with\nthe output of the three autoencoders, characterizing the individual cancer\ncell-lines, were used as the input of a deep neural network that predicts the\nsynergy value of given pair-wise drug combinations against the specific cancer\ncell-lines. The comparison results showed the proposed AuDNNsynergy model\noutperforms four state-of-art approaches, namely DeepSynergy, Gradient Boosting\nMachines, Random Forests, and Elastic Nets. Moreover, we conducted the\ninterpretation analysis of the deep learning model to investigate potential\nvital genetic predictors and the underlying mechanism of synergistic drug\ncombinations on specific cancer cell-lines.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1811.07054v1",
            "date": "2018-11-16 22:40:06+00:00"
        },
        {
            "title": "Learning Latent Fractional dynamics with Unknown Unknowns",
            "authors": [
                "Gaurav Gupta",
                "Sergio Pequito",
                "Paul Bogdan"
            ],
            "abstract": "Despite significant effort in understanding complex systems (CS), we lack a\ntheory for modeling, inference, analysis and efficient control of time-varying\ncomplex networks (TVCNs) in uncertain environments. From brain activity\ndynamics to microbiome, and even chromatin interactions within the genome\narchitecture, many such TVCNs exhibits a pronounced spatio-temporal fractality.\nMoreover, for many TVCNs only limited information (e.g., few variables) is\naccessible for modeling, which hampers the capabilities of analytical tools to\nuncover the true degrees of freedom and infer the CS model, the hidden states\nand their parameters. Another fundamental limitation is that of understanding\nand unveiling of unknown drivers of the dynamics that could sporadically excite\nthe network in ways that straightforward modeling does not work due to our\ninability to model non-stationary processes. Towards addressing these\nchallenges, in this paper, we consider the problem of learning the fractional\ndynamical complex networks under unknown unknowns (i.e., hidden drivers) and\npartial observability (i.e., only partial data is available). More precisely,\nwe consider a generalized modeling approach of TVCNs consisting of\ndiscrete-time fractional dynamical equations and propose an iterative framework\nto determine the network parameterization and predict the state of the system.\nWe showcase the performance of the proposed framework in the context of task\nclassification using real electroencephalogram data.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1811.00703v2",
            "date": "2018-11-02 02:01:11+00:00"
        },
        {
            "title": "Application of Deep Learning on Predicting Prognosis of Acute Myeloid Leukemia with Cytogenetics, Age, and Mutations",
            "authors": [
                "Mei Lin",
                "Vanya Jaitly",
                "Iris Wang",
                "Zhihong Hu",
                "Lei Chen",
                "Md. Amer Wahed",
                "Zeyad Kanaan",
                "Adan Rios",
                "Andy N. D. Nguyen"
            ],
            "abstract": "We explore how Deep Learning (DL) can be utilized to predict prognosis of\nacute myeloid leukemia (AML). Out of TCGA (The Cancer Genome Atlas) database,\n94 AML cases are used in this study. Input data include age, 10 common\ncytogenetic and 23 most common mutation results; output is the prognosis\n(diagnosis to death, DTD). In our DL network, autoencoders are stacked to form\na hierarchical DL model from which raw data are compressed and organized and\nhigh-level features are extracted. The network is written in R language and is\ndesigned to predict prognosis of AML for a given case (DTD of more than or less\nthan 730 days). The DL network achieves an excellent accuracy of 83% in\npredicting prognosis. As a proof-of-concept study, our preliminary results\ndemonstrate a practical application of DL in future practice of prognostic\nprediction using next-gen sequencing (NGS) data.",
            "categories": [
                "cs.LG",
                "q-bio.QM",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1810.13247v1",
            "date": "2018-10-30 15:03:35+00:00"
        },
        {
            "title": "What made you do this? Understanding black-box decisions with sufficient input subsets",
            "authors": [
                "Brandon Carter",
                "Jonas Mueller",
                "Siddhartha Jain",
                "David Gifford"
            ],
            "abstract": "Local explanation frameworks aim to rationalize particular decisions made by\na black-box prediction model. Existing techniques are often restricted to a\nspecific type of predictor or based on input saliency, which may be undesirably\nsensitive to factors unrelated to the model's decision making process. We\ninstead propose sufficient input subsets that identify minimal subsets of\nfeatures whose observed values alone suffice for the same decision to be\nreached, even if all other input feature values are missing. General principles\nthat globally govern a model's decision-making can also be revealed by\nsearching for clusters of such input patterns across many data points. Our\napproach is conceptually straightforward, entirely model-agnostic, simply\nimplemented using instance-wise backward selection, and able to produce more\nconcise rationales than existing techniques. We demonstrate the utility of our\ninterpretation method on various neural network models trained on text, image,\nand genomic data.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1810.03805v2",
            "date": "2018-10-09 04:22:44+00:00"
        },
        {
            "title": "Gene Shaving using influence function of a kernel method",
            "authors": [
                "Md. Ashad Alam",
                "Mohammad Shahjama",
                "Md. Ferdush Rahman"
            ],
            "abstract": "Identifying significant subsets of the genes, gene shaving is an essential\nand challenging issue for biomedical research for a huge number of genes and\nthe complex nature of biological networks,. Since positive definite kernel\nbased methods on genomic information can improve the prediction of diseases, in\nthis paper we proposed a new method, \"kernel gene shaving (kernel canonical\ncorrelation analysis (kernel CCA) based gene shaving). This problem is\naddressed using the influence function of the kernel CCA. To investigate the\nperformance of the proposed method in a comparison of three popular gene\nselection methods (T-test, SAM and LIMMA), we were used extensive simulated and\nreal microarray gene expression datasets. The performance measures AUC was\ncomputed for each of the methods. The achievement of the proposed method has\nimproved than the three well-known gene selection methods. In real data\nanalysis, the proposed method identified a subsets of $210$ genes out of $2000$\ngenes. The network of these genes has significantly more interactions than\nexpected, which indicates that they may function in a concerted effort on colon\ncancer.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1809.01625v1",
            "date": "2018-09-05 17:09:00+00:00"
        },
        {
            "title": "Network-based Biased Tree Ensembles (NetBiTE) for Drug Sensitivity Prediction and Drug Sensitivity Biomarker Identification in Cancer",
            "authors": [
                "Ali Oskooei",
                "Matteo Manica",
                "Roland Mathis",
                "Maria Rodriguez Martinez"
            ],
            "abstract": "We present the Network-based Biased Tree Ensembles (NetBiTE) method for drug\nsensitivity prediction and drug sensitivity biomarker identification in cancer\nusing a combination of prior knowledge and gene expression data. Our devised\nmethod consists of a biased tree ensemble that is built according to a\nprobabilistic bias weight distribution. The bias weight distribution is\nobtained from the assignment of high weights to the drug targets and\npropagating the assigned weights over a protein-protein interaction network\nsuch as STRING. The propagation of weights, defines neighborhoods of influence\naround the drug targets and as such simulates the spread of perturbations\nwithin the cell, following drug administration. Using a synthetic dataset, we\nshowcase how application of biased tree ensembles (BiTE) results in significant\naccuracy gains at a much lower computational cost compared to the unbiased\nrandom forests (RF) algorithm. We then apply NetBiTE to the Genomics of Drug\nSensitivity in Cancer (GDSC) dataset and demonstrate that NetBiTE outperforms\nRF in predicting IC50 drug sensitivity, only for drugs that target membrane\nreceptor pathways (MRPs): RTK, EGFR and IGFR signaling pathways. We propose\nbased on the NetBiTE results, that for drugs that inhibit MRPs, the expression\nof target genes prior to drug administration is a biomarker for IC50 drug\nsensitivity following drug administration. We further verify and reinforce this\nproposition through control studies on, PI3K/MTOR signaling pathway inhibitors,\na drug category that does not target MRPs, and through assignment of dummy\ntargets to MRP inhibiting drugs and investigating the variation in NetBiTE\naccuracy.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1808.06603v2",
            "date": "2018-08-18 14:43:20+00:00"
        },
        {
            "title": "Convolutional Neural Networks In Classifying Cancer Through DNA Methylation",
            "authors": [
                "Soham Chatterjee",
                "Archana Iyer",
                "Satya Avva",
                "Abhai Kollara",
                "Malaikannan Sankarasubbu"
            ],
            "abstract": "DNA Methylation has been the most extensively studied epigenetic mark.\nUsually a change in the genotype, DNA sequence, leads to a change in the\nphenotype, observable characteristics of the individual. But DNA methylation,\nwhich happens in the context of CpG (cytosine and guanine bases linked by\nphosphate backbone) dinucleotides, does not lead to a change in the original\nDNA sequence but has the potential to change the phenotype. DNA methylation is\nimplicated in various biological processes and diseases including cancer. Hence\nthere is a strong interest in understanding the DNA methylation patterns across\nvarious epigenetic related ailments in order to distinguish and diagnose the\ntype of disease in its early stages. In this work, the relationship between\nmethylated versus unmethylated CpG regions and cancer types is explored using\nConvolutional Neural Networks (CNNs). A CNN based Deep Learning model that can\nclassify the cancer of a new DNA methylation profile based on the learning from\npublicly available DNA methylation datasets is then proposed.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1807.09617v1",
            "date": "2018-07-24 17:11:58+00:00"
        },
        {
            "title": "Estimating Cellular Goals from High-Dimensional Biological Data",
            "authors": [
                "Laurence Yang",
                "Michael A. Saunders",
                "Jean-Christophe Lachance",
                "Bernhard O. Palsson",
                "Jos\u00e9 Bento"
            ],
            "abstract": "Optimization-based models have been used to predict cellular behavior for\nover 25 years. The constraints in these models are derived from genome\nannotations, measured macro-molecular composition of cells, and by measuring\nthe cell's growth rate and metabolism in different conditions. The cellular\ngoal (the optimization problem that the cell is trying to solve) can be\nchallenging to derive experimentally for many organisms, including human or\nmammalian cells, which have complex metabolic capabilities and are not well\nunderstood. Existing approaches to learning goals from data include (a)\nestimating a linear objective function, or (b) estimating linear constraints\nthat model complex biochemical reactions and constrain the cell's operation.\nThe latter approach is important because often the known/observed biochemical\nreactions are not enough to explain observations, and hence there is a need to\nextend automatically the model complexity by learning new chemical reactions.\nHowever, this leads to nonconvex optimization problems, and existing tools\ncannot scale to realistically large metabolic models. Hence, constraint\nestimation is still used sparingly despite its benefits for modeling cell\nmetabolism, which is important for developing novel antimicrobials against\npathogens, discovering cancer drug targets, and producing value-added\nchemicals. Here, we develop the first approach to estimating constraint\nreactions from data that can scale to realistically large metabolic models.\nPrevious tools have been used on problems having less than 75 biochemical\nreactions and 60 metabolites, which limits real-life-size applications. We\nperform extensive experiments using 75 large-scale metabolic network models for\ndifferent organisms (including bacteria, yeasts, and mammals) and show that our\nalgorithm can recover cellular constraint reactions, even when some\nmeasurements are missing.",
            "categories": [
                "q-bio.QM",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1807.04245v4",
            "date": "2018-07-11 16:57:57+00:00"
        },
        {
            "title": "Deep SNP: An End-to-end Deep Neural Network with Attention-based Localization for Break-point Detection in SNP Array Genomic data",
            "authors": [
                "Hamid Eghbal-zadeh",
                "Lukas Fischer",
                "Niko Popitsch",
                "Florian Kromp",
                "Sabine Taschner-Mandl",
                "Khaled Koutini",
                "Teresa Gerber",
                "Eva Bozsaky",
                "Peter F. Ambros",
                "Inge M. Ambros",
                "Gerhard Widmer",
                "Bernhard A. Moser"
            ],
            "abstract": "Diagnosis and risk stratification of cancer and many other diseases require\nthe detection of genomic breakpoints as a prerequisite of calling copy number\nalterations (CNA). This, however, is still challenging and requires\ntime-consuming manual curation. As deep-learning methods outperformed classical\nstate-of-the-art algorithms in various domains and have also been successfully\napplied to life science problems including medicine and biology, we here\npropose Deep SNP, a novel Deep Neural Network to learn from genomic data.\nSpecifically, we used a manually curated dataset from 12 genomic single\nnucleotide polymorphism array (SNPa) profiles as truth-set and aimed at\npredicting the presence or absence of genomic breakpoints, an indicator of\nstructural chromosomal variations, in windows of 40,000 probes. We compare our\nresults with well-known neural network models as well as Rawcopy though this\ntool is designed to predict breakpoints and in addition genomic segments with\nhigh sensitivity. We show, that Deep SNP is capable of successfully predicting\nthe presence or absence of a breakpoint in large genomic windows and\noutperforms state-of-the-art neural network models. Qualitative examples\nsuggest that integration of a localization unit may enable breakpoint detection\nand prediction of genomic segments, even if the breakpoint coordinates were not\nprovided for network training. These results warrant further evaluation of\nDeepSNP for breakpoint localization and subsequent calling of genomic segments.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1806.08840v1",
            "date": "2018-06-22 20:15:13+00:00"
        },
        {
            "title": "Towards Gene Expression Convolutions using Gene Interaction Graphs",
            "authors": [
                "Francis Dutil",
                "Joseph Paul Cohen",
                "Martin Weiss",
                "Georgy Derevyanko",
                "Yoshua Bengio"
            ],
            "abstract": "We study the challenges of applying deep learning to gene expression data. We\nfind experimentally that there exists non-linear signal in the data, however is\nit not discovered automatically given the noise and low numbers of samples used\nin most research. We discuss how gene interaction graphs (same pathway,\nprotein-protein, co-expression, or research paper text association) can be used\nto impose a bias on a deep model similar to the spatial bias imposed by\nconvolutions on an image. We explore the usage of Graph Convolutional Neural\nNetworks coupled with dropout and gene embeddings to utilize the graph\ninformation. We find this approach provides an advantage for particular tasks\nin a low data regime but is very dependent on the quality of the graph used. We\nconclude that more work should be done in this direction. We design experiments\nthat show why existing methods fail to capture signal that is present in the\ndata when features are added which clearly isolates the problem that needs to\nbe addressed.",
            "categories": [
                "q-bio.GN",
                "cs.CE",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1806.06975v1",
            "date": "2018-06-18 22:40:37+00:00"
        },
        {
            "title": "Latent heterogeneous multilayer community detection",
            "authors": [
                "Hafiz Tiomoko Ali",
                "Sijia Liu",
                "Yasin Yilmaz",
                "Romain Couillet",
                "Indika Rajapakse",
                "Alfred Hero"
            ],
            "abstract": "We propose a method for simultaneously detecting shared and unshared\ncommunities in heterogeneous multilayer weighted and undirected networks. The\nmultilayer network is assumed to follow a generative probabilistic model that\ntakes into account the similarities and dissimilarities between the\ncommunities. We make use of a variational Bayes approach for jointly inferring\nthe shared and unshared hidden communities from multilayer network\nobservations. We show that our approach outperforms state-of-the-art algorithms\nin detecting disparate (shared and private) communities on synthetic data as\nwell as on real genome-wide fibroblast proliferation dataset.",
            "categories": [
                "cs.SI",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1806.07963v2",
            "date": "2018-06-16 18:02:11+00:00"
        },
        {
            "title": "The Reduced PC-Algorithm: Improved Causal Structure Learning in Large Random Networks",
            "authors": [
                "Arjun Sondhi",
                "Ali Shojaie"
            ],
            "abstract": "We consider the task of estimating a high-dimensional directed acyclic graph,\ngiven observations from a linear structural equation model with arbitrary noise\ndistribution. By exploiting properties of common random graphs, we develop a\nnew algorithm that requires conditioning only on small sets of variables. The\nproposed algorithm, which is essentially a modified version of the\nPC-Algorithm, offers significant gains in both computational complexity and\nestimation accuracy. In particular, it results in more efficient and accurate\nestimation in large networks containing hub nodes, which are common in\nbiological systems. We prove the consistency of the proposed algorithm, and\nshow that it also requires a less stringent faithfulness assumption than the\nPC-Algorithm. Simulations in low and high-dimensional settings are used to\nillustrate these findings. An application to gene expression data suggests that\nthe proposed algorithm can identify a greater number of clinically relevant\ngenes than current methods.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN",
                "stat.ME"
            ],
            "link": "http://arxiv.org/pdf/1806.06209v2",
            "date": "2018-06-16 08:40:14+00:00"
        },
        {
            "title": "Cell Identity Codes: Understanding Cell Identity from Gene Expression Profiles using Deep Neural Networks",
            "authors": [
                "Farzad Abdolhosseini",
                "Behrooz Azarkhalili",
                "Abbas Maazallahi",
                "Aryan Kamal",
                "Seyed Abolfazl Motahari",
                "Ali Sharifi-Zarchi",
                "Hamidreza Chitsaz"
            ],
            "abstract": "Understanding cell identity is an important task in many biomedical areas.\nExpression patterns of specific marker genes have been used to characterize\nsome limited cell types, but exclusive markers are not available for many cell\ntypes. A second approach is to use machine learning to discriminate cell types\nbased on the whole gene expression profiles (GEPs). The accuracies of simple\nclassification algorithms such as linear discriminators or support vector\nmachines are limited due to the complexity of biological systems. We used deep\nneural networks to analyze 1040 GEPs from 16 different human tissues and cell\ntypes. After comparing different architectures, we identified a specific\nstructure of deep autoencoders that can encode a GEP into a vector of 30\nnumeric values, which we call the cell identity code (CIC). The original GEP\ncan be reproduced from the CIC with an accuracy comparable to technical\nreplicates of the same experiment. Although we use an unsupervised approach to\ntrain the autoencoder, we show different values of the CIC are connected to\ndifferent biological aspects of the cell, such as different pathways or\nbiological processes. This network can use CIC to reproduce the GEP of the cell\ntypes it has never seen during the training. It also can resist some noise in\nthe measurement of the GEP. Furthermore, we introduce classifier autoencoder,\nan architecture that can accurately identify cell type based on the GEP or the\nCIC.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1806.04863v1",
            "date": "2018-06-13 06:42:44+00:00"
        },
        {
            "title": "Black Box FDR",
            "authors": [
                "Wesley Tansey",
                "Yixin Wang",
                "David M. Blei",
                "Raul Rabadan"
            ],
            "abstract": "Analyzing large-scale, multi-experiment studies requires scientists to test\neach experimental outcome for statistical significance and then assess the\nresults as a whole. We present Black Box FDR (BB-FDR), an empirical-Bayes\nmethod for analyzing multi-experiment studies when many covariates are gathered\nper experiment. BB-FDR learns a series of black box predictive models to boost\npower and control the false discovery rate (FDR) at two stages of study\nanalysis. In Stage 1, it uses a deep neural network prior to report which\nexperiments yielded significant outcomes. In Stage 2, a separate black box\nmodel of each covariate is used to select features that have significant\npredictive power across all experiments. In benchmarks, BB-FDR outperforms\ncompeting state-of-the-art methods in both stages of analysis. We apply BB-FDR\nto two real studies on cancer drug efficacy. For both studies, BB-FDR increases\nthe proportion of significant outcomes discovered and selects variables that\nreveal key genomic drivers of drug sensitivity and resistance in cancer.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1806.03143v1",
            "date": "2018-06-08 13:29:08+00:00"
        },
        {
            "title": "Holographic Neural Architectures",
            "authors": [
                "Tariq Daouda",
                "Jeremie Zumer",
                "Claude Perreault",
                "S\u00e9bastien Lemieux"
            ],
            "abstract": "Representation learning is at the heart of what makes deep learning\neffective. In this work, we introduce a new framework for representation\nlearning that we call \"Holographic Neural Architectures\" (HNAs). In the same\nway that an observer can experience the 3D structure of a holographed object by\nlooking at its hologram from several angles, HNAs derive Holographic\nRepresentations from the training set. These representations can then be\nexplored by moving along a continuous bounded single dimension. We show that\nHNAs can be used to make generative networks, state-of-the-art regression\nmodels and that they are inherently highly resistant to noise. Finally, we\nargue that because of their denoising abilities and their capacity to\ngeneralize well from very few examples, models based upon HNAs are particularly\nwell suited for biological applications where training examples are rare or\nnoisy.",
            "categories": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "q-bio.GN",
                "q-bio.TO",
                "68T30, 68T05, 62-07l",
                "I.2.0; I.2.4; I.2.6; G.3"
            ],
            "link": "http://arxiv.org/pdf/1806.00931v1",
            "date": "2018-06-04 02:41:20+00:00"
        },
        {
            "title": "Convolutional Embedded Networks for Population Scale Clustering and Bio-ancestry Inferencing",
            "authors": [
                "Md. Rezaul Karim",
                "Michael Cochez",
                "Achille Zappa",
                "Ratnesh Sahay",
                "Oya Beyan",
                "Dietrich-Rebholz Schuhmann",
                "Stefan Decker"
            ],
            "abstract": "The study of genetic variants can help find correlating population groups to\nidentify cohorts that are predisposed to common diseases and explain\ndifferences in disease susceptibility and how patients react to drugs. Machine\nlearning algorithms are increasingly being applied to identify interacting GVs\nto understand their complex phenotypic traits. Since the performance of a\nlearning algorithm not only depends on the size and nature of the data but also\non the quality of underlying representation, deep neural networks can learn\nnon-linear mappings that allow transforming GVs data into more clustering and\nclassification friendly representations than manual feature selection. In this\npaper, we proposed convolutional embedded networks in which we combine two DNN\narchitectures called convolutional embedded clustering and convolutional\nautoencoder classifier for clustering individuals and predicting geographic\nethnicity based on GVs, respectively. We employed CAE-based representation\nlearning on 95 million GVs from the 1000 genomes and Simons genome diversity\nprojects. Quantitative and qualitative analyses with a focus on accuracy and\nscalability show that our approach outperforms state-of-the-art approaches such\nas VariantSpark and ADMIXTURE. In particular, CEC can cluster targeted\npopulation groups in 22 hours with an adjusted rand index of 0.915, the\nnormalized mutual information of 0.92, and the clustering accuracy of 89%.\nContrarily, the CAE classifier can predict the geographic ethnicity of unknown\nsamples with an F1 and Mathews correlation coefficient(MCC) score of 0.9004 and\n0.8245, respectively. To provide interpretations of the predictions, we\nidentify significant biomarkers using gradient boosted trees(GBT) and SHAP.\nOverall, our approach is transparent and faster than the baseline methods, and\nscalable for 5% to 100% of the full human genome.",
            "categories": [
                "cs.LG",
                "q-bio.QM",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1805.12218v2",
            "date": "2018-05-30 20:30:13+00:00"
        },
        {
            "title": "AffinityNet: semi-supervised few-shot learning for disease type prediction",
            "authors": [
                "Tianle Ma",
                "Aidong Zhang"
            ],
            "abstract": "While deep learning has achieved great success in computer vision and many\nother fields, currently it does not work very well on patient genomic data with\nthe \"big p, small N\" problem (i.e., a relatively small number of samples with\nhigh-dimensional features). In order to make deep learning work with a small\namount of training data, we have to design new models that facilitate few-shot\nlearning. Here we present the Affinity Network Model (AffinityNet), a data\nefficient deep learning model that can learn from a limited number of training\nexamples and generalize well. The backbone of the AffinityNet model consists of\nstacked k-Nearest-Neighbor (kNN) attention pooling layers. The kNN attention\npooling layer is a generalization of the Graph Attention Model (GAM), and can\nbe applied to not only graphs but also any set of objects regardless of whether\na graph is given or not. As a new deep learning module, kNN attention pooling\nlayers can be plugged into any neural network model just like convolutional\nlayers. As a simple special case of kNN attention pooling layer, feature\nattention layer can directly select important features that are useful for\nclassification tasks. Experiments on both synthetic data and cancer genomic\ndata from TCGA projects show that our AffinityNet model has better\ngeneralization power than conventional neural network models with little\ntraining data. The code is freely available at\nhttps://github.com/BeautyOfWeb/AffinityNet .",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1805.08905v2",
            "date": "2018-05-22 23:22:18+00:00"
        },
        {
            "title": "Information Constraints on Auto-Encoding Variational Bayes",
            "authors": [
                "Romain Lopez",
                "Jeffrey Regier",
                "Michael I. Jordan",
                "Nir Yosef"
            ],
            "abstract": "Parameterizing the approximate posterior of a generative model with neural\nnetworks has become a common theme in recent machine learning research. While\nproviding appealing flexibility, this approach makes it difficult to impose or\nassess structural constraints such as conditional independence. We propose a\nframework for learning representations that relies on Auto-Encoding Variational\nBayes and whose search space is constrained via kernel-based measures of\nindependence. In particular, our method employs the $d$-variable\nHilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between\nthe latent representations and arbitrary nuisance factors. We show how to apply\nthis method to a range of problems, including the problems of learning\ninvariant representations and the learning of interpretable representations. We\nalso present a full-fledged application to single-cell RNA sequencing\n(scRNA-seq). In this setting the biological signal is mixed in complex ways\nwith sequencing errors and sampling effects. We show that our method\nout-performs the state-of-the-art in this domain.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1805.08672v4",
            "date": "2018-05-22 15:45:14+00:00"
        },
        {
            "title": "Predicting drug response of tumors from integrated genomic profiles by deep neural networks",
            "authors": [
                "Yu-Chiao Chiu",
                "Hung-I Harry Chen",
                "Tinghe Zhang",
                "Songyao Zhang",
                "Aparna Gorthi",
                "Li-Ju Wang",
                "Yufei Huang",
                "Yidong Chen"
            ],
            "abstract": "The study of high-throughput genomic profiles from a pharmacogenomics\nviewpoint has provided unprecedented insights into the oncogenic features\nmodulating drug response. A recent screening of ~1,000 cancer cell lines to a\ncollection of anti-cancer drugs illuminated the link between genotypes and\nvulnerability. However, due to essential differences between cell lines and\ntumors, the translation into predicting drug response in tumors remains\nchallenging. Here we proposed a DNN model to predict drug response based on\nmutation and expression profiles of a cancer cell or a tumor. The model\ncontains a mutation and an expression encoders pre-trained using a large\npan-cancer dataset to abstract core representations of high-dimension data,\nfollowed by a drug response predictor network. Given a pair of mutation and\nexpression profiles, the model predicts IC50 values of 265 drugs. We trained\nand tested the model on a dataset of 622 cancer cell lines and achieved an\noverall prediction performance of mean squared error at 1.96 (log-scale IC50\nvalues). The performance was superior in prediction error or stability than two\nclassical methods and four analog DNNs of our model. We then applied the model\nto predict drug response of 9,059 tumors of 33 cancer types. The model\npredicted both known, including EGFR inhibitors in non-small cell lung cancer\nand tamoxifen in ER+ breast cancer, and novel drug targets. The comprehensive\nanalysis further revealed the molecular mechanisms underlying the resistance to\na chemotherapeutic drug docetaxel in a pan-cancer setting and the anti-cancer\npotential of a novel agent, CX-5461, in treating gliomas and hematopoietic\nmalignancies. Overall, our model and findings improve the prediction of drug\nresponse and the identification of novel therapeutic options.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1805.07702v1",
            "date": "2018-05-20 04:27:09+00:00"
        },
        {
            "title": "TensOrMachine: Probabilistic Boolean Tensor Decomposition",
            "authors": [
                "Tammo Rukat",
                "Chris C. Holmes",
                "Christopher Yau"
            ],
            "abstract": "Boolean tensor decomposition approximates data of multi-way binary\nrelationships as product of interpretable low-rank binary factors, following\nthe rules of Boolean algebra. Here, we present its first probabilistic\ntreatment. We facilitate scalable sampling-based posterior inference by\nexploitation of the combinatorial structure of the factor conditionals. Maximum\na posteriori decompositions feature higher accuracies than existing techniques\nthroughout a wide range of simulated conditions. Moreover, the probabilistic\napproach facilitates the treatment of missing data and enables model selection\nwith much greater accuracy. We investigate three real-world data-sets. First,\ntemporal interaction networks in a hospital ward and behavioural data of\nuniversity students demonstrate the inference of instructive latent patterns.\nNext, we decompose a tensor with more than 10 billion data points, indicating\nrelations of gene expression in cancer patients. Not only does this demonstrate\nscalability, it also provides an entirely novel perspective on relational\nproperties of continuous data and, in the present example, on the molecular\nheterogeneity of cancer. Our implementation is available on GitHub:\nhttps://github.com/TammoR/LogicalFactorisationMachines.",
            "categories": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "q-bio.GN",
                "stat.AP"
            ],
            "link": "http://arxiv.org/pdf/1805.04582v1",
            "date": "2018-05-11 20:23:35+00:00"
        },
        {
            "title": "Network Enhancement: a general method to denoise weighted biological networks",
            "authors": [
                "Bo Wang",
                "Armin Pourshafeie",
                "Marinka Zitnik",
                "Junjie Zhu",
                "Carlos D. Bustamante",
                "Serafim Batzoglou",
                "Jure Leskovec"
            ],
            "abstract": "Networks are ubiquitous in biology where they encode connectivity patterns at\nall scales of organization, from molecular to the biome. However, biological\nnetworks are noisy due to the limitations of measurement technology and\ninherent natural variation, which can hamper discovery of network patterns and\ndynamics. We propose Network Enhancement (NE), a method for improving the\nsignal-to-noise ratio of undirected, weighted networks. NE uses a doubly\nstochastic matrix operator that induces sparsity and provides a closed-form\nsolution that increases spectral eigengap of the input network. As a result, NE\nremoves weak edges, enhances real connections, and leads to better downstream\nperformance. Experiments show that NE improves gene function prediction by\ndenoising tissue-specific interaction networks, alleviates interpretation of\nnoisy Hi-C contact maps from the human genome, and boosts fine-grained\nidentification accuracy of species. Our results indicate that NE is widely\napplicable for denoising biological networks.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "cs.SI"
            ],
            "link": "http://arxiv.org/pdf/1805.03327v2",
            "date": "2018-05-09 00:22:03+00:00"
        },
        {
            "title": "Bayesian Metabolic Flux Analysis reveals intracellular flux couplings",
            "authors": [
                "Markus Heinonen",
                "Maria Osmala",
                "Henrik Mannerstr\u00f6m",
                "Janne Wallenius",
                "Samuel Kaski",
                "Juho Rousu",
                "Harri L\u00e4hdesm\u00e4ki"
            ],
            "abstract": "Metabolic flux balance analyses are a standard tool in analysing metabolic\nreaction rates compatible with measurements, steady-state and the metabolic\nreaction network stoichiometry. Flux analysis methods commonly place\nunrealistic assumptions on fluxes due to the convenience of formulating the\nproblem as a linear programming model, and most methods ignore the notable\nuncertainty in flux estimates. We introduce a novel paradigm of Bayesian\nmetabolic flux analysis that models the reactions of the whole genome-scale\ncellular system in probabilistic terms, and can infer the full flux vector\ndistribution of genome-scale metabolic systems based on exchange and\nintracellular (e.g. 13C) flux measurements, steady-state assumptions, and\ntarget function assumptions. The Bayesian model couples all fluxes jointly\ntogether in a simple truncated multivariate posterior distribution, which\nreveals informative flux couplings. Our model is a plug-in replacement to\nconventional metabolic balance methods, such as flux balance analysis (FBA).\nOur experiments indicate that we can characterise the genome-scale flux\ncovariances, reveal flux couplings, and determine more intracellular unobserved\nfluxes in C. acetobutylicum from 13C data than flux variability analysis. The\nCOBRA compatible software is available at github.com/markusheinonen/bamfa",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1804.06673v1",
            "date": "2018-04-18 12:19:34+00:00"
        },
        {
            "title": "Analysis of Extremely Obese Individuals Using Deep Learning Stacked Autoencoders and Genome-Wide Genetic Data",
            "authors": [
                "Casimiro A. Curbelo Monta\u00f1ez",
                "Paul Fergus",
                "Carl Chalmers",
                "Jade Hind"
            ],
            "abstract": "The aetiology of polygenic obesity is multifactorial, which indicates that\nlife-style and environmental factors may influence multiples genes to aggravate\nthis disorder. Several low-risk single nucleotide polymorphisms (SNPs) have\nbeen associated with BMI. However, identified loci only explain a small\nproportion of the variation ob-served for this phenotype. The linear nature of\ngenome wide association studies (GWAS) used to identify associations between\ngenetic variants and the phenotype have had limited success in explaining the\nheritability variation of BMI and shown low predictive capacity in\nclassification studies. GWAS ignores the epistatic interactions that less\nsignificant variants have on the phenotypic outcome. In this paper we utilise a\nnovel deep learning-based methodology to reduce the high dimensional space in\nGWAS and find epistatic interactions between SNPs for classification purposes.\nSNPs were filtered based on the effects associations have with BMI. Since\nBonferroni adjustment for multiple testing is highly conservative, an important\nproportion of SNPs involved in SNP-SNP interactions are ignored. Therefore,\nonly SNPs with p-values < 1x10-2 were considered for subsequent epistasis\nanalysis using stacked auto encoders (SAE). This allows the nonlinearity\npresent in SNP-SNP interactions to be discovered through progressively smaller\nhidden layer units and to initialise a multi-layer feedforward artificial\nneural network (ANN) classifier. The classifier is fine-tuned to classify\nextremely obese and non-obese individuals. The best results were obtained with\n2000 compressed units (SE=0.949153, SP=0.933014, Gini=0.949936,\nLo-gloss=0.1956, AUC=0.97497 and MSE=0.054057). Using 50 compressed units it\nwas possible to achieve (SE=0.785311, SP=0.799043, Gini=0.703566,\nLogloss=0.476864, AUC=0.85178 and MSE=0.156315).",
            "categories": [
                "q-bio.GN",
                "cs.CE",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1804.06262v2",
            "date": "2018-04-16 15:25:14+00:00"
        },
        {
            "title": "Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions",
            "authors": [
                "Anvita Gupta",
                "James Zou"
            ],
            "abstract": "Generative Adversarial Networks (GANs) represent an attractive and novel\napproach to generate realistic data, such as genes, proteins, or drugs, in\nsynthetic biology. Here, we apply GANs to generate synthetic DNA sequences\nencoding for proteins of variable length. We propose a novel feedback-loop\narchitecture, called Feedback GAN (FBGAN), to optimize the synthetic gene\nsequences for desired properties using an external function analyzer. The\nproposed architecture also has the advantage that the analyzer need not be\ndifferentiable. We apply the feedback-loop mechanism to two examples: 1)\ngenerating synthetic genes coding for antimicrobial peptides, and 2) optimizing\nsynthetic genes for the secondary structure of their resulting peptides. A\nsuite of metrics demonstrate that the GAN generated proteins have desirable\nbiophysical properties. The FBGAN architecture can also be used to optimize\nGAN-generated datapoints for useful properties in domains beyond genomics.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/1804.01694v1",
            "date": "2018-04-05 07:17:42+00:00"
        },
        {
            "title": "Image Generation from Scene Graphs",
            "authors": [
                "Justin Johnson",
                "Agrim Gupta",
                "Li Fei-Fei"
            ],
            "abstract": "To truly understand the visual world our models should be able not only to\nrecognize images but also generate them. To this end, there has been exciting\nrecent progress on generating images from natural language descriptions. These\nmethods give stunning results on limited domains such as descriptions of birds\nor flowers, but struggle to faithfully reproduce complex sentences with many\nobjects and relationships. To overcome this limitation we propose a method for\ngenerating images from scene graphs, enabling explicitly reasoning about\nobjects and their relationships. Our model uses graph convolution to process\ninput graphs, computes a scene layout by predicting bounding boxes and\nsegmentation masks for objects, and converts the layout to an image with a\ncascaded refinement network. The network is trained adversarially against a\npair of discriminators to ensure realistic outputs. We validate our approach on\nVisual Genome and COCO-Stuff, where qualitative results, ablations, and user\nstudies demonstrate our method's ability to generate complex images with\nmultiple objects.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1804.01622v1",
            "date": "2018-04-04 22:59:08+00:00"
        },
        {
            "title": "A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks",
            "authors": [
                "Jeffrey Chan",
                "Valerio Perrone",
                "Jeffrey P. Spence",
                "Paul A. Jenkins",
                "Sara Mathieson",
                "Yun S. Song"
            ],
            "abstract": "An explosion of high-throughput DNA sequencing in the past decade has led to\na surge of interest in population-scale inference with whole-genome data.\nRecent work in population genetics has centered on designing inference methods\nfor relatively simple model classes, and few scalable general-purpose inference\ntechniques exist for more realistic, complex models. To achieve this, two\ninferential challenges need to be addressed: (1) population data are\nexchangeable, calling for methods that efficiently exploit the symmetries of\nthe data, and (2) computing likelihoods is intractable as it requires\nintegrating over a set of correlated, extremely high-dimensional latent\nvariables. These challenges are traditionally tackled by likelihood-free\nmethods that use scientific simulators to generate datasets and reduce them to\nhand-designed, permutation-invariant summary statistics, often leading to\ninaccurate inference. In this work, we develop an exchangeable neural network\nthat performs summary statistic-free, likelihood-free inference. Our framework\ncan be applied in a black-box fashion across a variety of simulation-based\ntasks, both within and outside biology. We demonstrate the power of our\napproach on the recombination hotspot testing problem, outperforming the\nstate-of-the-art.",
            "categories": [
                "cs.LG",
                "q-bio.PE",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1802.06153v2",
            "date": "2018-02-16 22:36:16+00:00"
        },
        {
            "title": "VISER: Visual Self-Regularization",
            "authors": [
                "Hamid Izadinia",
                "Pierre Garrigues"
            ],
            "abstract": "In this work, we propose the use of large set of unlabeled images as a source\nof regularization data for learning robust visual representation. Given a\nvisual model trained by a labeled dataset in a supervised fashion, we augment\nour training samples by incorporating large number of unlabeled data and train\na semi-supervised model. We demonstrate that our proposed learning approach\nleverages an abundance of unlabeled images and boosts the visual recognition\nperformance which alleviates the need to rely on large labeled datasets for\nlearning robust representation. To increment the number of image instances\nneeded to learn robust visual models in our approach, each labeled image\npropagates its label to its nearest unlabeled image instances. These retrieved\nunlabeled images serve as local perturbations of each labeled image to perform\nVisual Self-Regularization (VISER). To retrieve such visual self regularizers,\nwe compute the cosine similarity in a semantic space defined by the penultimate\nlayer in a fully convolutional neural network. We use the publicly available\nYahoo Flickr Creative Commons 100M dataset as the source of our unlabeled image\nset and propose a distributed approximate nearest neighbor algorithm to make\nretrieval practical at that scale. Using the labeled instances and their\nregularizer samples we show that we significantly improve object categorization\nand localization performance on the MS COCO and Visual Genome datasets where\nobjects appear in context.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1802.02568v1",
            "date": "2018-02-07 18:55:01+00:00"
        },
        {
            "title": "Proteomics Analysis of FLT3-ITD Mutation in Acute Myeloid Leukemia Using Deep Learning Neural Network",
            "authors": [
                "Christine A. Liang",
                "Lei Chen",
                "Amer Wahed",
                "Andy N. D. Nguyen"
            ],
            "abstract": "Deep Learning can significantly benefit cancer proteomics and genomics. In\nthis study, we attempt to determine a set of critical proteins that are\nassociated with the FLT3-ITD mutation in newly-diagnosed acute myeloid leukemia\npatients. A Deep Learning network consisting of autoencoders forming a\nhierarchical model from which high-level features are extracted without labeled\ntraining data. Dimensional reduction reduced the number of critical proteins\nfrom 231 to 20. Deep Learning found an excellent correlation between FLT3-ITD\nmutation with the levels of these 20 critical proteins (accuracy 97%,\nsensitivity 90%, specificity 100%). Our Deep Learning network could hone in on\n20 proteins with the strongest association with FLT3-ITD. The results of this\nstudy allow a novel approach to determine critical protein pathways in the\nFLT3-ITD mutation, and provide proof-of-concept for an accurate approach to\nmodel big data in cancer proteomics and genomics.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1801.01019v1",
            "date": "2017-12-29 13:05:30+00:00"
        },
        {
            "title": "Generating and designing DNA with deep generative models",
            "authors": [
                "Nathan Killoran",
                "Leo J. Lee",
                "Andrew Delong",
                "David Duvenaud",
                "Brendan J. Frey"
            ],
            "abstract": "We propose generative neural network methods to generate DNA sequences and\ntune them to have desired properties. We present three approaches: creating\nsynthetic DNA sequences using a generative adversarial network; a DNA-based\nvariant of the activation maximization (\"deep dream\") design method; and a\njoint procedure which combines these two approaches together. We show that\nthese tools capture important structures of the data and, when applied to\ndesigning probes for protein binding microarrays, allow us to generate new\nsequences whose properties are estimated to be superior to those found in the\ntraining data. We believe that these results open the door for applying deep\ngenerative models to advance genomics research.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1712.06148v1",
            "date": "2017-12-17 17:23:10+00:00"
        },
        {
            "title": "Attention based convolutional neural network for predicting RNA-protein binding sites",
            "authors": [
                "Xiaoyong Pan",
                "Junchi Yan"
            ],
            "abstract": "RNA-binding proteins (RBPs) play crucial roles in many biological processes,\ne.g. gene regulation. Computational identification of RBP binding sites on RNAs\nare urgently needed. In particular, RBPs bind to RNAs by recognizing sequence\nmotifs. Thus, fast locating those motifs on RNA sequences is crucial and\ntime-efficient for determining whether the RNAs interact with the RBPs or not.\nIn this study, we present an attention based convolutional neural network,\niDeepA, to predict RNA-protein binding sites from raw RNA sequences. We first\nencode RNA sequences into one-hot encoding. Next, we design a deep learning\nmodel with a convolutional neural network (CNN) and an attention mechanism,\nwhich automatically search for important positions, e.g. binding motifs, to\nlearn discriminant high-level features for predicting RBP binding sites. We\nevaluate iDeepA on publicly gold-standard RBP binding sites derived from\nCLIP-seq data. The results demonstrate iDeepA achieves comparable performance\nwith other state-of-the-art methods.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1712.02270v1",
            "date": "2017-12-06 16:33:29+00:00"
        },
        {
            "title": "Interpretable Convolutional Neural Networks for Effective Translation Initiation Site Prediction",
            "authors": [
                "Jasper Zuallaert",
                "Mijung Kim",
                "Yvan Saeys",
                "Wesley De Neve"
            ],
            "abstract": "Thanks to rapidly evolving sequencing techniques, the amount of genomic data\nat our disposal is growing increasingly large. Determining the gene structure\nis a fundamental requirement to effectively interpret gene function and\nregulation. An important part in that determination process is the\nidentification of translation initiation sites. In this paper, we propose a\nnovel approach for automatic prediction of translation initiation sites,\nleveraging convolutional neural networks that allow for automatic feature\nextraction. Our experimental results demonstrate that we are able to improve\nthe state-of-the-art approaches with a decrease of 75.2% in false positive rate\nand with a decrease of 24.5% in error rate on chosen datasets. Furthermore, an\nin-depth analysis of the decision-making process used by our predictive model\nshows that our neural network implicitly learns biologically relevant features\nfrom scratch, without any prior knowledge about the problem at hand, such as\nthe Kozak consensus sequence, the influence of stop and start codons in the\nsequence and the presence of donor splice site patterns. In summary, our\nfindings yield a better understanding of the internal reasoning of a\nconvolutional neural network when applying such a neural network to genomic\ndata.",
            "categories": [
                "q-bio.GN",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1711.09558v1",
            "date": "2017-11-27 06:37:37+00:00"
        },
        {
            "title": "SNeCT: Scalable network constrained Tucker decomposition for integrative multi-platform data analysis",
            "authors": [
                "Dongjin Choi",
                "Lee Sael"
            ],
            "abstract": "Motivation: How do we integratively analyze large-scale multi-platform\ngenomic data that are high dimensional and sparse? Furthermore, how can we\nincorporate prior knowledge, such as the association between genes, in the\nanalysis systematically? Method: To solve this problem, we propose a Scalable\nNetwork Constrained Tucker decomposition method we call SNeCT. SNeCT adopts\nparallel stochastic gradient descent approach on the proposed parallelizable\nnetwork constrained optimization function. SNeCT decomposition is applied to\ntensor constructed from large scale multi-platform multi-cohort cancer data,\nPanCan12, constrained on a network built from PathwayCommons database. Results:\nThe decomposed factor matrices are applied to stratify cancers, to search for\ntop-k similar patients, and to illustrate how the matrices can be used for\npersonalized interpretation. In the stratification test, combined twelve-cohort\ndata is clustered to form thirteen subclasses. The thirteen subclasses have a\nhigh correlation to tissue of origin in addition to other interesting\nobservations, such as clear separation of OV cancers to two groups, and high\nclinical correlation within subclusters formed in cohorts BRCA and UCEC. In the\ntop-k search, a new patient's genomic profile is generated and searched against\nexisting patients based on the factor matrices. The similarity of the top-k\npatient to the query is high for 23 clinical features, including\nestrogen/progesterone receptor statuses of BRCA patients with average precision\nvalue ranges from 0.72 to 0.86 and from 0.68 to 0.86, respectively. We also\nprovide an illustration of how the factor matrices can be used for\ninterpretable personalized analysis of each patient.",
            "categories": [
                "cs.LG",
                "q-bio.QM",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1711.08095v2",
            "date": "2017-11-22 01:03:49+00:00"
        },
        {
            "title": "Prototype Matching Networks for Large-Scale Multi-label Genomic Sequence Classification",
            "authors": [
                "Jack Lanchantin",
                "Arshdeep Sekhon",
                "Ritambhara Singh",
                "Yanjun Qi"
            ],
            "abstract": "One of the fundamental tasks in understanding genomics is the problem of\npredicting Transcription Factor Binding Sites (TFBSs). With more than hundreds\nof Transcription Factors (TFs) as labels, genomic-sequence based TFBS\nprediction is a challenging multi-label classification task. There are two\nmajor biological mechanisms for TF binding: (1) sequence-specific binding\npatterns on genomes known as \"motifs\" and (2) interactions among TFs known as\nco-binding effects. In this paper, we propose a novel deep architecture, the\nPrototype Matching Network (PMN) to mimic the TF binding mechanisms. Our PMN\nmodel automatically extracts prototypes (\"motif\"-like features) for each TF\nthrough a novel prototype-matching loss. Borrowing ideas from few-shot matching\nmodels, we use the notion of support set of prototypes and an LSTM to learn how\nTFs interact and bind to genomic sequences. On a reference TFBS dataset with\n$2.1$ $million$ genomic sequences, PMN significantly outperforms baselines and\nvalidates our design choices empirically. To our knowledge, this is the first\ndeep learning architecture that introduces prototype learning and considers\nTF-TF interactions for large-scale TFBS prediction. Not only is the proposed\narchitecture accurate, but it also models the underlying biology.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1710.11238v2",
            "date": "2017-10-30 21:04:49+00:00"
        },
        {
            "title": "Contextual Regression: An Accurate and Conveniently Interpretable Nonlinear Model for Mining Discovery from Scientific Data",
            "authors": [
                "Chengyu Liu",
                "Wei Wang"
            ],
            "abstract": "Machine learning algorithms such as linear regression, SVM and neural network\nhave played an increasingly important role in the process of scientific\ndiscovery. However, none of them is both interpretable and accurate on\nnonlinear datasets. Here we present contextual regression, a method that joins\nthese two desirable properties together using a hybrid architecture of neural\nnetwork embedding and dot product layer. We demonstrate its high prediction\naccuracy and sensitivity through the task of predictive feature selection on a\nsimulated dataset and the application of predicting open chromatin sites in the\nhuman genome. On the simulated data, our method achieved high fidelity recovery\nof feature contributions under random noise levels up to 200%. On the open\nchromatin dataset, the application of our method not only outperformed the\nstate of the art method in terms of accuracy, but also unveiled two previously\nunfound open chromatin related histone marks. Our method can fill the blank of\naccurate and interpretable nonlinear modeling in scientific data mining tasks.",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "stat.AP",
                "stat.CO",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1710.10728v1",
            "date": "2017-10-30 00:39:47+00:00"
        },
        {
            "title": "Feature versus Raw Sequence: Deep Learning Comparative Study on Predicting Pre-miRNA",
            "authors": [
                "Jaya Thomas",
                "Sonia Thomas",
                "Lee Sael"
            ],
            "abstract": "Should we input known genome sequence features or input sequence itself in\ndeep learning framework? As deep learning more popular in various applications,\nresearchers often come to question whether to generate features or use raw\nsequences for deep learning. To answer this question, we study the prediction\naccuracy of precursor miRNA prediction of feature-based deep belief network and\nsequence-based convolution neural network. Tested on a variant of six-layer\nconvolution neural net and three-layer deep belief network, we find the raw\nsequence input based convolution neural network model performs similar or\nslightly better than feature based deep belief networks with best accuracy\nvalues of 0.995 and 0.990, respectively. Both the models outperform existing\nbenchmarks models. The results shows us that if provided large enough data,\nwell devised raw sequence based deep learning models can replace feature based\ndeep learning models. However, construction of well behaved deep learning model\ncan be very challenging. In cased features can be easily extracted,\nfeature-based deep learning models may be a better alternative.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1710.06798v1",
            "date": "2017-10-17 14:09:00+00:00"
        },
        {
            "title": "A deep generative model for single-cell RNA sequencing with application to detecting differentially expressed genes",
            "authors": [
                "Romain Lopez",
                "Jeffrey Regier",
                "Michael Cole",
                "Michael Jordan",
                "Nir Yosef"
            ],
            "abstract": "We propose a probabilistic model for interpreting gene expression levels that\nare observed through single-cell RNA sequencing. In the model, each cell has a\nlow-dimensional latent representation. Additional latent variables account for\ntechnical effects that may erroneously set some observations of gene expression\nlevels to zero. Conditional distributions are specified by neural networks,\ngiving the proposed model enough flexibility to fit the data well. We use\nvariational inference and stochastic optimization to approximate the posterior\ndistribution. The inference procedure scales to over one million cells, whereas\ncompeting algorithms do not. Even for smaller datasets, for several tasks, the\nproposed procedure outperforms state-of-the-art methods like ZIFA and\nZINB-WaVE. We also extend our framework to take into account batch effects and\nother confounding factors and propose a natural Bayesian hypothesis framework\nfor differential expression that outperforms tradition DESeq2.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1710.05086v2",
            "date": "2017-10-13 21:47:48+00:00"
        },
        {
            "title": "Identifying Genetic Risk Factors via Sparse Group Lasso with Group Graph Structure",
            "authors": [
                "Tao Yang",
                "Paul Thompson",
                "Sihai Zhao",
                "Jieping Ye"
            ],
            "abstract": "Genome-wide association studies (GWA studies or GWAS) investigate the\nrelationships between genetic variants such as single-nucleotide polymorphisms\n(SNPs) and individual traits. Recently, incorporating biological priors\ntogether with machine learning methods in GWA studies has attracted increasing\nattention. However, in real-world, nucleotide-level bio-priors have not been\nwell-studied to date. Alternatively, studies at gene-level, for example,\nprotein--protein interactions and pathways, are more rigorous and legitimate,\nand it is potentially beneficial to utilize such gene-level priors in GWAS. In\nthis paper, we proposed a novel two-level structured sparse model, called\nSparse Group Lasso with Group-level Graph structure (SGLGG), for GWAS. It can\nbe considered as a sparse group Lasso along with a group-level graph Lasso.\nEssentially, SGLGG penalizes the nucleotide-level sparsity as well as takes\nadvantages of gene-level priors (both gene groups and networks), to identifying\nphenotype-associated risk SNPs. We employ the alternating direction method of\nmultipliers algorithm to optimize the proposed model. Our experiments on the\nAlzheimer's Disease Neuroimaging Initiative whole genome sequence data and\nneuroimage data demonstrate the effectiveness of SGLGG. As a regression model,\nit is competitive to the state-of-the-arts sparse models; as a variable\nselection method, SGLGG is promising for identifying Alzheimer's\ndisease-related risk SNPs.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1709.03645v1",
            "date": "2017-09-12 01:34:50+00:00"
        },
        {
            "title": "A deep generative model for gene expression profiles from single-cell RNA sequencing",
            "authors": [
                "Romain Lopez",
                "Jeffrey Regier",
                "Michael Cole",
                "Michael Jordan",
                "Nir Yosef"
            ],
            "abstract": "We propose a probabilistic model for interpreting gene expression levels that\nare observed through single-cell RNA sequencing. In the model, each cell has a\nlow-dimensional latent representation. Additional latent variables account for\ntechnical effects that may erroneously set some observations of gene expression\nlevels to zero. Conditional distributions are specified by neural networks,\ngiving the proposed model enough flexibility to fit the data well. We use\nvariational inference and stochastic optimization to approximate the posterior\ndistribution. The inference procedure scales to over one million cells, whereas\ncompeting algorithms do not. Even for smaller datasets, for several tasks, the\nproposed procedure outperforms state-of-the-art methods like ZIFA and\nZINB-WaVE. We also extend our framework to account for batch effects and other\nconfounding factors, and propose a Bayesian hypothesis test for differential\nexpression that outperforms DESeq2.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1709.02082v4",
            "date": "2017-09-07 05:59:49+00:00"
        },
        {
            "title": "Phylogenetic Convolutional Neural Networks in Metagenomics",
            "authors": [
                "Diego Fioravanti",
                "Ylenia Giarratano",
                "Valerio Maggio",
                "Claudio Agostinelli",
                "Marco Chierici",
                "Giuseppe Jurman",
                "Cesare Furlanello"
            ],
            "abstract": "Background: Convolutional Neural Networks can be effectively used only when\ndata are endowed with an intrinsic concept of neighbourhood in the input space,\nas is the case of pixels in images. We introduce here Ph-CNN, a novel deep\nlearning architecture for the classification of metagenomics data based on the\nConvolutional Neural Networks, with the patristic distance defined on the\nphylogenetic tree being used as the proximity measure. The patristic distance\nbetween variables is used together with a sparsified version of\nMultiDimensional Scaling to embed the phylogenetic tree in a Euclidean space.\nResults: Ph-CNN is tested with a domain adaptation approach on synthetic data\nand on a metagenomics collection of gut microbiota of 38 healthy subjects and\n222 Inflammatory Bowel Disease patients, divided in 6 subclasses.\nClassification performance is promising when compared to classical algorithms\nlike Support Vector Machines and Random Forest and a baseline fully connected\nneural network, e.g. the Multi-Layer Perceptron. Conclusion: Ph-CNN represents\na novel deep learning approach for the classification of metagenomics data.\nOperatively, the algorithm has been implemented as a custom Keras layer taking\ncare of passing to the following convolutional layer not only the data but also\nthe ranked list of neighbourhood of each sample, thus mimicking the case of\nimage data, transparently to the user. Keywords: Metagenomics; Deep learning;\nConvolutional Neural Networks; Phylogenetic trees",
            "categories": [
                "q-bio.QM",
                "cs.LG",
                "cs.NE",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1709.02268v1",
            "date": "2017-09-06 12:59:14+00:00"
        },
        {
            "title": "Pixels to Graphs by Associative Embedding",
            "authors": [
                "Alejandro Newell",
                "Jia Deng"
            ],
            "abstract": "Graphs are a useful abstraction of image content. Not only can graphs\nrepresent details about individual objects in a scene but they can capture the\ninteractions between pairs of objects. We present a method for training a\nconvolutional neural network such that it takes in an input image and produces\na full graph definition. This is done end-to-end in a single stage with the use\nof associative embeddings. The network learns to simultaneously identify all of\nthe elements that make up a graph and piece them together. We benchmark on the\nVisual Genome dataset, and demonstrate state-of-the-art performance on the\nchallenging task of scene graph generation.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1706.07365v2",
            "date": "2017-06-22 15:20:25+00:00"
        },
        {
            "title": "Learning the structure of Bayesian Networks via the bootstrap",
            "authors": [
                "Giulio Caravagna",
                "Daniele Ramazzotti"
            ],
            "abstract": "Learning the structure of dependencies among multiple random variables is a\nproblem of considerable theoretical and practical interest. Within the context\nof Bayesian Networks, a practical and surprisingly successful solution to this\nlearning problem is achieved by adopting score-functions optimisation schema,\naugmented with multiple restarts to avoid local optima. Yet, the conditions\nunder which such strategies work well are poorly understood, and there are also\nsome intrinsic limitations to learning the directionality of the interaction\namong the variables. Following an early intuition of Friedman and Koller, we\npropose to decouple the learning problem into two steps: first, we identify a\npartial ordering among input variables which constrains the structural learning\nproblem, and then propose an effective bootstrap-based algorithm to simulate\naugmented data sets, and select the most important dependencies among the\nvariables. By using several synthetic data sets, we show that our algorithm\nyields better recovery performance than the state of the art, increasing the\nchances of identifying a globally-optimal solution to the learning problem, and\nsolving also well-known identifiability issues that affect the standard\napproach. We use our new algorithm to infer statistical dependencies between\ncancer driver somatic mutations detected by high-throughput genome sequencing\ndata of multiple colorectal cancer patients. In this way, we also show how the\nproposed methods can shade new insights about cancer initiation, and\nprogression. Code: https://github.com/caravagn/Bootstrap-based-Learning",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1706.02386v2",
            "date": "2017-06-07 21:30:47+00:00"
        },
        {
            "title": "A generalized method toward drug-target interaction prediction via low-rank matrix projection",
            "authors": [
                "Ratha Pech",
                "Dong Hao",
                "Yan-Li Lee",
                "Maryna Po",
                "Tao Zhou"
            ],
            "abstract": "Drug-target interaction (DTI) prediction plays a very important role in drug\ndevelopment and drug discovery. Biochemical experiments or \\textit{in vitro}\nmethods are very expensive, laborious and time-consuming. Therefore, \\textit{in\nsilico} approaches including docking simulation and machine learning have been\nproposed to solve this problem. In particular, machine learning approaches have\nattracted increasing attentions recently. However, in addition to the known\ndrug-target interactions, most of the machine learning methods require extra\ncharacteristic information such as chemical structures, genome sequences,\nbinding types and so on. Whenever such information is not available, they may\nperform poor. Very recently, the similarity-based link prediction methods were\nextended to bipartite networks, which can be applied to solve the DTI\nprediction problem by using topological information only. In this work, we\npropose a method based on low-rank matrix projection to solve the DTI\nprediction problem. On one hand, when there is no extra characteristic\ninformation of drugs or targets, the proposed method utilizes only the known\ninteractions. On the other hand, the proposed method can also utilize the extra\ncharacteristic information when it is available and the performances will be\nremarkably improved. Moreover, the proposed method can predict the interactions\nassociated with new drugs or targets of which we know nothing about their\nassociated interactions, but only some characteristic information. We compare\nthe proposed method with ten baseline methods, e.g., six similarity-based\nmethods that utilize only the known interactions and four methods that utilize\nthe extra characteristic information. The datasets and codes implementing the\nsimulations are available at https://github.com/rathapech/DTI_LMP.",
            "categories": [
                "cs.LG",
                "cs.CE",
                "physics.bio-ph"
            ],
            "link": "http://arxiv.org/pdf/1706.01876v2",
            "date": "2017-06-06 08:39:28+00:00"
        },
        {
            "title": "DeepGO: Predicting protein functions from sequence and interactions using a deep ontology-aware classifier",
            "authors": [
                "Maxat Kulmanov",
                "Mohammed Asif Khan",
                "Robert Hoehndorf"
            ],
            "abstract": "A large number of protein sequences are becoming available through the\napplication of novel high-throughput sequencing technologies. Experimental\nfunctional characterization of these proteins is time-consuming and expensive,\nand is often only done rigorously for few selected model organisms.\nComputational function prediction approaches have been suggested to fill this\ngap. The functions of proteins are classified using the Gene Ontology (GO),\nwhich contains over 40,000 classes. Additionally, proteins have multiple\nfunctions, making function prediction a large-scale, multi-class, multi-label\nproblem.\n  We have developed a novel method to predict protein function from sequence.\nWe use deep learning to learn features from protein sequences as well as a\ncross-species protein-protein interaction network. Our approach specifically\noutputs information in the structure of the GO and utilizes the dependencies\nbetween GO classes as background information to construct a deep learning\nmodel. We evaluate our method using the standards established by the\nComputational Assessment of Function Annotation (CAFA) and demonstrate a\nsignificant improvement over baseline methods such as BLAST, with significant\nimprovement for predicting cellular locations.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1705.05919v1",
            "date": "2017-05-15 06:04:08+00:00"
        },
        {
            "title": "3D Deep Learning for Biological Function Prediction from Physical Fields",
            "authors": [
                "Vladimir Golkov",
                "Marcin J. Skwark",
                "Atanas Mirchev",
                "Georgi Dikov",
                "Alexander R. Geanes",
                "Jeffrey Mendenhall",
                "Jens Meiler",
                "Daniel Cremers"
            ],
            "abstract": "Predicting the biological function of molecules, be it proteins or drug-like\ncompounds, from their atomic structure is an important and long-standing\nproblem. Function is dictated by structure, since it is by spatial interactions\nthat molecules interact with each other, both in terms of steric\ncomplementarity, as well as intermolecular forces. Thus, the electron density\nfield and electrostatic potential field of a molecule contain the \"raw\nfingerprint\" of how this molecule can fit to binding partners. In this paper,\nwe show that deep learning can predict biological function of molecules\ndirectly from their raw 3D approximated electron density and electrostatic\npotential fields. Protein function based on EC numbers is predicted from the\napproximated electron density field. In another experiment, the activity of\nsmall molecules is predicted with quality comparable to state-of-the-art\ndescriptor-based methods. We propose several alternative computational models\nfor the GPU with different memory and runtime requirements for different sizes\nof molecules and of databases. We also propose application-specific\nmulti-channel data representations. With future improvements of training\ndatasets and neural network settings in combination with complementary\ninformation sources (sequence, genomic context, expression level), deep\nlearning can be expected to show its generalization power and revolutionize the\nfield of molecular function prediction.",
            "categories": [
                "q-bio.BM",
                "cs.LG",
                "q-bio.QM",
                "stat.ML",
                "I.2.6; J.3"
            ],
            "link": "http://arxiv.org/pdf/1704.04039v1",
            "date": "2017-04-13 09:11:23+00:00"
        },
        {
            "title": "Learning Important Features Through Propagating Activation Differences",
            "authors": [
                "Avanti Shrikumar",
                "Peyton Greenside",
                "Anshul Kundaje"
            ],
            "abstract": "The purported \"black box\" nature of neural networks is a barrier to adoption\nin applications where interpretability is essential. Here we present DeepLIFT\n(Deep Learning Important FeaTures), a method for decomposing the output\nprediction of a neural network on a specific input by backpropagating the\ncontributions of all neurons in the network to every feature of the input.\nDeepLIFT compares the activation of each neuron to its 'reference activation'\nand assigns contribution scores according to the difference. By optionally\ngiving separate consideration to positive and negative contributions, DeepLIFT\ncan also reveal dependencies which are missed by other approaches. Scores can\nbe computed efficiently in a single backward pass. We apply DeepLIFT to models\ntrained on MNIST and simulated genomic data, and show significant advantages\nover gradient-based methods. Video tutorial: http://goo.gl/qKb7pL, ICML slides:\nbit.ly/deeplifticmlslides, ICML talk: https://vimeo.com/238275076, code:\nhttp://goo.gl/RM8jvH.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/1704.02685v2",
            "date": "2017-04-10 02:23:57+00:00"
        },
        {
            "title": "Learning Large-Scale Bayesian Networks with the sparsebn Package",
            "authors": [
                "Bryon Aragam",
                "Jiaying Gu",
                "Qing Zhou"
            ],
            "abstract": "Learning graphical models from data is an important problem with wide\napplications, ranging from genomics to the social sciences. Nowadays datasets\noften have upwards of thousands---sometimes tens or hundreds of thousands---of\nvariables and far fewer samples. To meet this challenge, we have developed a\nnew R package called sparsebn for learning the structure of large, sparse\ngraphical models with a focus on Bayesian networks. While there are many\nexisting software packages for this task, this package focuses on the unique\nsetting of learning large networks from high-dimensional data, possibly with\ninterventions. As such, the methods provided place a premium on scalability and\nconsistency in a high-dimensional setting. Furthermore, in the presence of\ninterventions, the methods implemented here achieve the goal of learning a\ncausal network from data. Additionally, the sparsebn package is fully\ncompatible with existing software packages for network analysis.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.CO",
                "stat.ME"
            ],
            "link": "http://arxiv.org/pdf/1703.04025v2",
            "date": "2017-03-11 20:07:06+00:00"
        },
        {
            "title": "Parallel Implementation of Efficient Search Schemes for the Inference of Cancer Progression Models",
            "authors": [
                "Daniele Ramazzotti",
                "Marco S. Nobile",
                "Paolo Cazzaniga",
                "Giancarlo Mauri",
                "Marco Antoniotti"
            ],
            "abstract": "The emergence and development of cancer is a consequence of the accumulation\nover time of genomic mutations involving a specific set of genes, which\nprovides the cancer clones with a functional selective advantage. In this work,\nwe model the order of accumulation of such mutations during the progression,\nwhich eventually leads to the disease, by means of probabilistic graphic\nmodels, i.e., Bayesian Networks (BNs). We investigate how to perform the task\nof learning the structure of such BNs, according to experimental evidence,\nadopting a global optimization meta-heuristics. In particular, in this work we\nrely on Genetic Algorithms, and to strongly reduce the execution time of the\ninference -- which can also involve multiple repetitions to collect\nstatistically significant assessments of the data -- we distribute the\ncalculations using both multi-threading and a multi-node architecture. The\nresults show that our approach is characterized by good accuracy and\nspecificity; we also demonstrate its feasibility, thanks to a 84x reduction of\nthe overall execution time with respect to a traditional sequential\nimplementation.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1703.03038v1",
            "date": "2017-03-08 21:29:52+00:00"
        },
        {
            "title": "Auto-clustering Output Layer: Automatic Learning of Latent Annotations in Neural Networks",
            "authors": [
                "Ozsel Kilinc",
                "Ismail Uysal"
            ],
            "abstract": "In this paper, we discuss a different type of semi-supervised setting: a\ncoarse level of labeling is available for all observations but the model has to\nlearn a fine level of latent annotation for each one of them. Problems in this\nsetting are likely to be encountered in many domains such as text\ncategorization, protein function prediction, image classification as well as in\nexploratory scientific studies such as medical and genomics research. We\nconsider this setting as simultaneously performed supervised classification\n(per the available coarse labels) and unsupervised clustering (within each one\nof the coarse labels) and propose a novel output layer modification called\nauto-clustering output layer (ACOL) that allows concurrent classification and\nclustering based on Graph-based Activity Regularization (GAR) technique. As the\nproposed output layer modification duplicates the softmax nodes at the output\nlayer for each class, GAR allows for competitive learning between these\nduplicates on a traditional error-correction learning framework to ultimately\nenable a neural network to learn the latent annotations in this partially\nsupervised setup. We demonstrate how the coarse label supervision impacts\nperformance and helps propagate useful clustering information between\nsub-classes. Comparative tests on three of the most popular image datasets\nMNIST, SVHN and CIFAR-100 rigorously demonstrate the effectiveness and\ncompetitiveness of the proposed approach.",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1702.08648v2",
            "date": "2017-02-28 05:21:31+00:00"
        },
        {
            "title": "Semi-parametric Network Structure Discovery Models",
            "authors": [
                "Amir Dezfouli",
                "Edwin V. Bonilla",
                "Richard Nock"
            ],
            "abstract": "We propose a network structure discovery model for continuous observations\nthat generalizes linear causal models by incorporating a Gaussian process (GP)\nprior on a network-independent component, and random sparsity and weight\nmatrices as the network-dependent parameters. This approach provides flexible\nmodeling of network-independent trends in the observations as well as\nuncertainty quantification around the discovered network structure. We\nestablish a connection between our model and multi-task GPs and develop an\nefficient stochastic variational inference algorithm for it. Furthermore, we\nformally show that our approach is numerically stable and in fact numerically\neasy to carry out almost everywhere on the support of the random variables\ninvolved. Finally, we evaluate our model on three applications, showing that it\noutperforms previous approaches. We provide a qualitative and quantitative\nanalysis of the structures discovered for domains such as the study of the full\ngenome regulation of the yeast Saccharomyces cerevisiae.",
            "categories": [
                "cs.LG",
                "stat.ML",
                "I.2.6; I.5.1"
            ],
            "link": "http://arxiv.org/pdf/1702.08530v1",
            "date": "2017-02-27 21:04:05+00:00"
        },
        {
            "title": "Memory Matching Networks for Genomic Sequence Classification",
            "authors": [
                "Jack Lanchantin",
                "Ritambhara Singh",
                "Yanjun Qi"
            ],
            "abstract": "When analyzing the genome, researchers have discovered that proteins bind to\nDNA based on certain patterns of the DNA sequence known as \"motifs\". However,\nit is difficult to manually construct motifs due to their complexity. Recently,\nexternally learned memory models have proven to be effective methods for\nreasoning over inputs and supporting sets. In this work, we present memory\nmatching networks (MMN) for classifying DNA sequences as protein binding sites.\nOur model learns a memory bank of encoded motifs, which are dynamic memory\nmodules, and then matches a new test sequence to each of the motifs to classify\nthe sequence as a binding or nonbinding site.",
            "categories": [
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1702.06760v1",
            "date": "2017-02-22 11:37:49+00:00"
        },
        {
            "title": "HLA class I binding prediction via convolutional neural networks",
            "authors": [
                "Yeeleng Scott Vang",
                "Xiaohui Xie"
            ],
            "abstract": "Many biological processes are governed by protein-ligand interactions. One\nsuch example is the recognition of self and nonself cells by the immune system.\nThis immune response process is regulated by the major histocompatibility\ncomplex (MHC) protein which is encoded by the human leukocyte antigen (HLA)\ncomplex. Understanding the binding potential between MHC and peptides can lead\nto the design of more potent, peptide-based vaccines and immunotherapies for\ninfectious autoimmune diseases.\n  We apply machine learning techniques from the natural language processing\n(NLP) domain to address the task of MHC-peptide binding prediction. More\nspecifically, we introduce a new distributed representation of amino acids,\nname HLA-Vec, that can be used for a variety of downstream proteomic machine\nlearning tasks. We then propose a deep convolutional neural network\narchitecture, name HLA-CNN, for the task of HLA class I-peptide binding\nprediction. Experimental results show combining the new distributed\nrepresentation with our HLA-CNN architecture achieves state-of-the-art results\nin the majority of the latest two Immune Epitope Database (IEDB) weekly\nautomated benchmark datasets. We further apply our model to predict binding on\nthe human genome and identify 15 genes with potential for self binding.",
            "categories": [
                "q-bio.QM",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1701.00593v2",
            "date": "2017-01-03 06:08:52+00:00"
        },
        {
            "title": "Diet Networks: Thin Parameters for Fat Genomics",
            "authors": [
                "Adriana Romero",
                "Pierre Luc Carrier",
                "Akram Erraqabi",
                "Tristan Sylvain",
                "Alex Auvolat",
                "Etienne Dejoie",
                "Marc-Andr\u00e9 Legault",
                "Marie-Pierre Dub\u00e9",
                "Julie G. Hussin",
                "Yoshua Bengio"
            ],
            "abstract": "Learning tasks such as those involving genomic data often poses a serious\nchallenge: the number of input features can be orders of magnitude larger than\nthe number of training examples, making it difficult to avoid overfitting, even\nwhen using the known regularization techniques. We focus here on tasks in which\nthe input is a description of the genetic variation specific to a patient, the\nsingle nucleotide polymorphisms (SNPs), yielding millions of ternary inputs.\nImproving the ability of deep learning to handle such datasets could have an\nimportant impact in precision medicine, where high-dimensional data regarding a\nparticular patient is used to make predictions of interest. Even though the\namount of data for such tasks is increasing, this mismatch between the number\nof examples and the number of inputs remains a concern. Naive implementations\nof classifier neural networks involve a huge number of free parameters in their\nfirst layer: each input feature is associated with as many parameters as there\nare hidden units. We propose a novel neural network parametrization which\nconsiderably reduces the number of free parameters. It is based on the idea\nthat we can first learn or provide a distributed representation for each input\nfeature (e.g. for each position in the genome where variations are observed),\nand then learn (with another neural network called the parameter prediction\nnetwork) how to map a feature's distributed representation to the vector of\nparameters specific to that feature in the classifier neural network (the\nweights which link the value of the feature to each of the hidden units). We\nshow experimentally on a population stratification task of interest to medical\nstudies that the proposed approach can significantly reduce both the number of\nparameters and the error rate of the classifier.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1611.09340v3",
            "date": "2016-11-28 20:50:32+00:00"
        },
        {
            "title": "A Neural Network Model to Classify Liver Cancer Patients Using Data Expansion and Compression",
            "authors": [
                "Ashkan Zeinalzadeh",
                "Tom Wenska",
                "Gordon Okimoto"
            ],
            "abstract": "We develop a neural network model to classify liver cancer patients into\nhigh-risk and low-risk groups using genomic data. Our approach provides a novel\ntechnique to classify big data sets using neural network models. We preprocess\nthe data before training the neural network models. We first expand the data\nusing wavelet analysis. We then compress the wavelet coefficients by mapping\nthem onto a new scaled orthonormal coordinate system. Then the data is used to\ntrain a neural network model that enables us to classify cancer patients into\ntwo different classes of high-risk and low-risk patients. We use the\nleave-one-out approach to build a neural network model. This neural network\nmodel enables us to classify a patient using genomic data as a high-risk or\nlow-risk patient without any information about the survival time of the\npatient. The results from genomic data analysis are compared with survival time\nanalysis. It is shown that the expansion and compression of data using wavelet\nanalysis and singular value decomposition (SVD) is essential to train the\nneural network model.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1611.07588v2",
            "date": "2016-11-23 00:11:41+00:00"
        },
        {
            "title": "Learning Genomic Representations to Predict Clinical Outcomes in Cancer",
            "authors": [
                "Safoora Yousefi",
                "Congzheng Song",
                "Nelson Nauata",
                "Lee Cooper"
            ],
            "abstract": "Genomics are rapidly transforming medical practice and basic biomedical\nresearch, providing insights into disease mechanisms and improving therapeutic\nstrategies, particularly in cancer. The ability to predict the future course of\na patient's disease from high-dimensional genomic profiling will be essential\nin realizing the promise of genomic medicine, but presents significant\nchallenges for state-of-the-art survival analysis methods. In this abstract we\npresent an investigation in learning genomic representations with neural\nnetworks to predict patient survival in cancer. We demonstrate the advantages\nof this approach over existing survival analysis methods using brain tumor\ndata.",
            "categories": [
                "cs.NE",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1609.08663v1",
            "date": "2016-09-27 20:53:16+00:00"
        },
        {
            "title": "Network-regularized Sparse Logistic Regression Models for Clinical Risk Prediction and Biomarker Discovery",
            "authors": [
                "Wenwen Min",
                "Juan Liu",
                "Shihua Zhang"
            ],
            "abstract": "Molecular profiling data (e.g., gene expression) has been used for clinical\nrisk prediction and biomarker discovery. However, it is necessary to integrate\nother prior knowledge like biological pathways or gene interaction networks to\nimprove the predictive ability and biological interpretability of biomarkers.\nHere, we first introduce a general regularized Logistic Regression (LR)\nframework with regularized term $\\lambda \\|\\bm{w}\\|_1 +\n\\eta\\bm{w}^T\\bm{M}\\bm{w}$, which can reduce to different penalties, including\nLasso, elastic net, and network-regularized terms with different $\\bm{M}$. This\nframework can be easily solved in a unified manner by a cyclic coordinate\ndescent algorithm which can avoid inverse matrix operation and accelerate the\ncomputing speed. However, if those estimated $\\bm{w}_i$ and $\\bm{w}_j$ have\nopposite signs, then the traditional network-regularized penalty may not\nperform well. To address it, we introduce a novel network-regularized sparse LR\nmodel with a new penalty $\\lambda \\|\\bm{w}\\|_1 + \\eta|\\bm{w}|^T\\bm{M}|\\bm{w}|$\nto consider the difference between the absolute values of the coefficients. And\nwe develop two efficient algorithms to solve it. Finally, we test our methods\nand compare them with the related ones using simulated and real data to show\ntheir efficiency.",
            "categories": [
                "q-bio.GN",
                "cs.LG",
                "stat.ML",
                "J.3; H.2.8; G.1.6; I.5"
            ],
            "link": "http://arxiv.org/pdf/1609.06480v1",
            "date": "2016-09-21 09:47:32+00:00"
        },
        {
            "title": "Deep Motif Dashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks",
            "authors": [
                "Jack Lanchantin",
                "Ritambhara Singh",
                "Beilun Wang",
                "Yanjun Qi"
            ],
            "abstract": "Deep neural network (DNN) models have recently obtained state-of-the-art\nprediction accuracy for the transcription factor binding (TFBS) site\nclassification task. However, it remains unclear how these approaches identify\nmeaningful DNA sequence signals and give insights as to why TFs bind to certain\nlocations. In this paper, we propose a toolkit called the Deep Motif Dashboard\n(DeMo Dashboard) which provides a suite of visualization strategies to extract\nmotifs, or sequence patterns from deep neural network models for TFBS\nclassification. We demonstrate how to visualize and understand three important\nDNN models: convolutional, recurrent, and convolutional-recurrent networks. Our\nfirst visualization method is finding a test sequence's saliency map which uses\nfirst-order derivatives to describe the importance of each nucleotide in making\nthe final prediction. Second, considering recurrent models make predictions in\na temporal manner (from one end of a TFBS sequence to the other), we introduce\ntemporal output scores, indicating the prediction score of a model over time\nfor a sequential input. Lastly, a class-specific visualization strategy finds\nthe optimal input sequence for a given TFBS positive class via stochastic\ngradient optimization. Our experimental results indicate that a\nconvolutional-recurrent architecture performs the best among the three\narchitectures. The visualization techniques indicate that CNN-RNN makes\npredictions by modeling both motifs as well as dependencies among them.",
            "categories": [
                "cs.LG",
                "cs.CV",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/1608.03644v4",
            "date": "2016-08-12 00:43:59+00:00"
        },
        {
            "title": "Network-Guided Biomarker Discovery",
            "authors": [
                "Chlo\u00e9-Agathe Azencott"
            ],
            "abstract": "Identifying measurable genetic indicators (or biomarkers) of a specific\ncondition of a biological system is a key element of precision medicine. Indeed\nit allows to tailor diagnostic, prognostic and treatment choice to individual\ncharacteristics of a patient. In machine learning terms, biomarker discovery\ncan be framed as a feature selection problem on whole-genome data sets.\nHowever, classical feature selection methods are usually underpowered to\nprocess these data sets, which contain orders of magnitude more features than\nsamples. This can be addressed by making the assumption that genetic features\nthat are linked on a biological network are more likely to work jointly towards\nexplaining the phenotype of interest. We review here three families of methods\nfor feature selection that integrate prior knowledge in the form of networks.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1607.08161v2",
            "date": "2016-07-27 15:53:02+00:00"
        },
        {
            "title": "DeepChrome: Deep-learning for predicting gene expression from histone modifications",
            "authors": [
                "Ritambhara Singh",
                "Jack Lanchantin",
                "Gabriel Robins",
                "Yanjun Qi"
            ],
            "abstract": "Motivation: Histone modifications are among the most important factors that\ncontrol gene regulation. Computational methods that predict gene expression\nfrom histone modification signals are highly desirable for understanding their\ncombinatorial effects in gene regulation. This knowledge can help in developing\n'epigenetic drugs' for diseases like cancer. Previous studies for quantifying\nthe relationship between histone modifications and gene expression levels\neither failed to capture combinatorial effects or relied on multiple methods\nthat separate predictions and combinatorial analysis. This paper develops a\nunified discriminative framework using a deep convolutional neural network to\nclassify gene expression using histone modification data as input. Our system,\ncalled DeepChrome, allows automatic extraction of complex interactions among\nimportant features. To simultaneously visualize the combinatorial interactions\namong histone modifications, we propose a novel optimization-based technique\nthat generates feature pattern maps from the learnt deep model. This provides\nan intuitive description of underlying epigenetic mechanisms that regulate\ngenes. Results: We show that DeepChrome outperforms state-of-the-art models\nlike Support Vector Machines and Random Forests for gene expression\nclassification task on 56 different cell-types from REMC database. The output\nof our visualization technique not only validates the previous observations but\nalso allows novel insights about combinatorial interactions among histone\nmodification marks, some of which have recently been observed by experimental\nstudies.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1607.02078v1",
            "date": "2016-07-07 16:50:57+00:00"
        },
        {
            "title": "Not Just a Black Box: Learning Important Features Through Propagating Activation Differences",
            "authors": [
                "Avanti Shrikumar",
                "Peyton Greenside",
                "Anna Shcherbina",
                "Anshul Kundaje"
            ],
            "abstract": "Note: This paper describes an older version of DeepLIFT. See\nhttps://arxiv.org/abs/1704.02685 for the newer version. Original abstract\nfollows: The purported \"black box\" nature of neural networks is a barrier to\nadoption in applications where interpretability is essential. Here we present\nDeepLIFT (Learning Important FeaTures), an efficient and effective method for\ncomputing importance scores in a neural network. DeepLIFT compares the\nactivation of each neuron to its 'reference activation' and assigns\ncontribution scores according to the difference. We apply DeepLIFT to models\ntrained on natural images and genomic data, and show significant advantages\nover gradient-based methods.",
            "categories": [
                "cs.LG",
                "cs.CV",
                "cs.NE"
            ],
            "link": "http://arxiv.org/pdf/1605.01713v3",
            "date": "2016-05-05 19:52:32+00:00"
        },
        {
            "title": "Deep Motif: Visualizing Genomic Sequence Classifications",
            "authors": [
                "Jack Lanchantin",
                "Ritambhara Singh",
                "Zeming Lin",
                "Yanjun Qi"
            ],
            "abstract": "This paper applies a deep convolutional/highway MLP framework to classify\ngenomic sequences on the transcription factor binding site task. To make the\nmodel understandable, we propose an optimization driven strategy to extract\n\"motifs\", or symbolic patterns which visualize the positive class learned by\nthe network. We show that our system, Deep Motif (DeMo), extracts motifs that\nare similar to, and in some cases outperform the current well known motifs. In\naddition, we find that a deeper model consisting of multiple convolutional and\nhighway layers can outperform a single convolutional and fully connected layer\nin the previous state-of-the-art.",
            "categories": [
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1605.01133v2",
            "date": "2016-05-04 03:33:48+00:00"
        },
        {
            "title": "deepTarget: End-to-end Learning Framework for microRNA Target Prediction using Deep Recurrent Neural Networks",
            "authors": [
                "Byunghan Lee",
                "Junghwan Baek",
                "Seunghyun Park",
                "Sungroh Yoon"
            ],
            "abstract": "MicroRNAs (miRNAs) are short sequences of ribonucleic acids that control the\nexpression of target messenger RNAs (mRNAs) by binding them. Robust prediction\nof miRNA-mRNA pairs is of utmost importance in deciphering gene regulations but\nhas been challenging because of high false positive rates, despite a deluge of\ncomputational tools that normally require laborious manual feature extraction.\nThis paper presents an end-to-end machine learning framework for miRNA target\nprediction. Leveraged by deep recurrent neural networks-based auto-encoding and\nsequence-sequence interaction learning, our approach not only delivers an\nunprecedented level of accuracy but also eliminates the need for manual feature\nextraction. The performance gap between the proposed method and existing\nalternatives is substantial (over 25% increase in F-measure), and deepTarget\ndelivers a quantum leap in the long-standing challenge of robust miRNA target\nprediction.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1603.09123v2",
            "date": "2016-03-30 10:59:36+00:00"
        },
        {
            "title": "Localized Lasso for High-Dimensional Regression",
            "authors": [
                "Makoto Yamada",
                "Koh Takeuchi",
                "Tomoharu Iwata",
                "John Shawe-Taylor",
                "Samuel Kaski"
            ],
            "abstract": "We introduce the localized Lasso, which is suited for learning models that\nare both interpretable and have a high predictive power in problems with high\ndimensionality $d$ and small sample size $n$. More specifically, we consider a\nfunction defined by local sparse models, one at each data point. We introduce\nsample-wise network regularization to borrow strength across the models, and\nsample-wise exclusive group sparsity (a.k.a., $\\ell_{1,2}$ norm) to introduce\ndiversity into the choice of feature sets in the local models. The local models\nare interpretable in terms of similarity of their sparsity patterns. The cost\nfunction is convex, and thus has a globally optimal solution. Moreover, we\npropose a simple yet efficient iterative least-squares based optimization\nprocedure for the localized Lasso, which does not need a tuning parameter, and\nis guaranteed to converge to a globally optimal solution. The solution is\nempirically shown to outperform alternatives for both simulated and genomic\npersonalized medicine data.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ],
            "link": "http://arxiv.org/pdf/1603.06743v3",
            "date": "2016-03-22 11:41:28+00:00"
        },
        {
            "title": "Deep Learning in Bioinformatics",
            "authors": [
                "Seonwoo Min",
                "Byunghan Lee",
                "Sungroh Yoon"
            ],
            "abstract": "In the era of big data, transformation of biomedical big data into valuable\nknowledge has been one of the most important challenges in bioinformatics. Deep\nlearning has advanced rapidly since the early 2000s and now demonstrates\nstate-of-the-art performance in various fields. Accordingly, application of\ndeep learning in bioinformatics to gain insight from data has been emphasized\nin both academia and industry. Here, we review deep learning in bioinformatics,\npresenting examples of current research. To provide a useful and comprehensive\nperspective, we categorize research both by the bioinformatics domain (i.e.,\nomics, biomedical imaging, biomedical signal processing) and deep learning\narchitecture (i.e., deep neural networks, convolutional neural networks,\nrecurrent neural networks, emergent architectures) and present brief\ndescriptions of each study. Additionally, we discuss theoretical and practical\nissues of deep learning in bioinformatics and suggest future research\ndirections. We believe that this review will provide valuable insights and\nserve as a starting point for researchers to apply deep learning approaches in\ntheir bioinformatics studies.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1603.06430v5",
            "date": "2016-03-21 13:55:02+00:00"
        },
        {
            "title": "Community Recovery in Graphs with Locality",
            "authors": [
                "Yuxin Chen",
                "Govinda Kamath",
                "Changho Suh",
                "David Tse"
            ],
            "abstract": "Motivated by applications in domains such as social networks and\ncomputational biology, we study the problem of community recovery in graphs\nwith locality. In this problem, pairwise noisy measurements of whether two\nnodes are in the same community or different communities come mainly or\nexclusively from nearby nodes rather than uniformly sampled between all nodes\npairs, as in most existing models. We present an algorithm that runs nearly\nlinearly in the number of measurements and which achieves the information\ntheoretic limit for exact recovery.",
            "categories": [
                "cs.IT",
                "cs.LG",
                "cs.SI",
                "math.IT",
                "math.ST",
                "q-bio.GN",
                "stat.TH"
            ],
            "link": "http://arxiv.org/pdf/1602.03828v3",
            "date": "2016-02-11 19:13:20+00:00"
        },
        {
            "title": "A new correlation clustering method for cancer mutation analysis",
            "authors": [
                "Jack P. Hou",
                "Amin Emad",
                "Gregory J. Puleo",
                "Jian Ma",
                "Olgica Milenkovic"
            ],
            "abstract": "Cancer genomes exhibit a large number of different alterations that affect\nmany genes in a diverse manner. It is widely believed that these alterations\nfollow combinatorial patterns that have a strong connection with the underlying\nmolecular interaction networks and functional pathways. A better understanding\nof the generative mechanisms behind the mutation rules and their influence on\ngene communities is of great importance for the process of driver mutations\ndiscovery and for identification of network modules related to cancer\ndevelopment and progression. We developed a new method for cancer mutation\npattern analysis based on a constrained form of correlation clustering.\nCorrelation clustering is an agnostic learning method that can be used for\ngeneral community detection problems in which the number of communities or\ntheir structure is not known beforehand. The resulting algorithm, named $C^3$,\nleverages mutual exclusivity of mutations, patient coverage, and driver network\nconcentration principles; it accepts as its input a user determined combination\nof heterogeneous patient data, such as that available from TCGA (including\nmutation, copy number, and gene expression information), and creates a large\nnumber of clusters containing mutually exclusive mutated genes in a particular\ntype of cancer. The cluster sizes may be required to obey some useful soft size\nconstraints, without impacting the computational complexity of the algorithm.\nTo test $C^3$, we performed a detailed analysis on TCGA breast cancer and\nglioblastoma data and showed that our algorithm outperforms the\nstate-of-the-art CoMEt method in terms of discovering mutually exclusive gene\nmodules and identifying driver genes. Our $C^3$ method represents a unique tool\nfor efficient and reliable identification of mutation patterns and driver\npathways in large-scale cancer genomics studies.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1601.06476v1",
            "date": "2016-01-25 04:02:52+00:00"
        },
        {
            "title": "DNA-Level Splice Junction Prediction using Deep Recurrent Neural Networks",
            "authors": [
                "Byunghan Lee",
                "Taehoon Lee",
                "Byunggook Na",
                "Sungroh Yoon"
            ],
            "abstract": "A eukaryotic gene consists of multiple exons (protein coding regions) and\nintrons (non-coding regions), and a splice junction refers to the boundary\nbetween a pair of exon and intron. Precise identification of spice junctions on\na gene is important for deciphering its primary structure, function, and\ninteraction. Experimental techniques for determining exon/intron boundaries\ninclude RNA-seq, which is often accompanied by computational approaches.\nCanonical splicing signals are known, but computational junction prediction\nstill remains challenging because of a large number of false positives and\nother complications. In this paper, we exploit deep recurrent neural networks\n(RNNs) to model DNA sequences and to detect splice junctions thereon. We test\nvarious RNN units and architectures including long short-term memory units,\ngated recurrent units, and recently proposed iRNN for in-depth design space\nexploration. According to our experimental results, the proposed approach\nsignificantly outperforms not only conventional machine learning-based methods\nbut also a recent state-of-the-art deep belief network-based technique in terms\nof prediction accuracy.",
            "categories": [
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1512.05135v1",
            "date": "2015-12-16 11:41:00+00:00"
        },
        {
            "title": "DenseCap: Fully Convolutional Localization Networks for Dense Captioning",
            "authors": [
                "Justin Johnson",
                "Andrej Karpathy",
                "Li Fei-Fei"
            ],
            "abstract": "We introduce the dense captioning task, which requires a computer vision\nsystem to both localize and describe salient regions in images in natural\nlanguage. The dense captioning task generalizes object detection when the\ndescriptions consist of a single word, and Image Captioning when one predicted\nregion covers the full image. To address the localization and description task\njointly we propose a Fully Convolutional Localization Network (FCLN)\narchitecture that processes an image with a single, efficient forward pass,\nrequires no external regions proposals, and can be trained end-to-end with a\nsingle round of optimization. The architecture is composed of a Convolutional\nNetwork, a novel dense localization layer, and Recurrent Neural Network\nlanguage model that generates the label sequences. We evaluate our network on\nthe Visual Genome dataset, which comprises 94,000 images and 4,100,000\nregion-grounded captions. We observe both speed and accuracy improvements over\nbaselines based on current state of the art approaches in both generation and\nretrieval settings.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1511.07571v1",
            "date": "2015-11-24 05:13:54+00:00"
        },
        {
            "title": "Deep Recurrent Neural Networks for Sequential Phenotype Prediction in Genomics",
            "authors": [
                "Farhad Pouladi",
                "Hojjat Salehinejad",
                "Amir Mohammad Gilani"
            ],
            "abstract": "In analyzing of modern biological data, we are often dealing with ill-posed\nproblems and missing data, mostly due to high dimensionality and\nmulticollinearity of the dataset. In this paper, we have proposed a system\nbased on matrix factorization (MF) and deep recurrent neural networks (DRNNs)\nfor genotype imputation and phenotype sequences prediction. In order to model\nthe long-term dependencies of phenotype data, the new Recurrent Linear Units\n(ReLU) learning strategy is utilized for the first time. The proposed model is\nimplemented for parallel processing on central processing units (CPUs) and\ngraphic processing units (GPUs). Performance of the proposed model is compared\nwith other training algorithms for learning long-term dependencies as well as\nthe sparse partial least square (SPLS) method on a set of genotype and\nphenotype data with 604 samples, 1980 single-nucleotide polymorphisms (SNPs),\nand two traits. The results demonstrate performance of the ReLU training\nalgorithm in learning long-term dependencies in RNNs.",
            "categories": [
                "cs.NE",
                "cs.CE",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1511.02554v3",
            "date": "2015-11-09 02:11:00+00:00"
        },
        {
            "title": "Supporting Regularized Logistic Regression Privately and Efficiently",
            "authors": [
                "Wenfa Li",
                "Hongzhe Liu",
                "Peng Yang",
                "Wei Xie"
            ],
            "abstract": "As one of the most popular statistical and machine learning models, logistic\nregression with regularization has found wide adoption in biomedicine, social\nsciences, information technology, and so on. These domains often involve data\nof human subjects that are contingent upon strict privacy regulations.\nIncreasing concerns over data privacy make it more and more difficult to\ncoordinate and conduct large-scale collaborative studies, which typically rely\non cross-institution data sharing and joint analysis. Our work here focuses on\nsafeguarding regularized logistic regression, a widely-used machine learning\nmodel in various disciplines while at the same time has not been investigated\nfrom a data security and privacy perspective. We consider a common use scenario\nof multi-institution collaborative studies, such as in the form of research\nconsortia or networks as widely seen in genetics, epidemiology, social\nsciences, etc. To make our privacy-enhancing solution practical, we demonstrate\na non-conventional and computationally efficient method leveraging distributing\ncomputing and strong cryptography to provide comprehensive protection over\nindividual-level and summary data. Extensive empirical evaluation on several\nstudies validated the privacy guarantees, efficiency and scalability of our\nproposal. We also discuss the practical implications of our solution for\nlarge-scale studies and applications from various disciplines, including\ngenetic and biomedical studies, smart grid, network analysis, etc.",
            "categories": [
                "cs.LG",
                "cs.CR",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1510.00095v1",
            "date": "2015-10-01 02:44:09+00:00"
        },
        {
            "title": "Diffusion Component Analysis: Unraveling Functional Topology in Biological Networks",
            "authors": [
                "Hyunghoon Cho",
                "Bonnie Berger",
                "Jian Peng"
            ],
            "abstract": "Complex biological systems have been successfully modeled by biochemical and\ngenetic interaction networks, typically gathered from high-throughput (HTP)\ndata. These networks can be used to infer functional relationships between\ngenes or proteins. Using the intuition that the topological role of a gene in a\nnetwork relates to its biological function, local or diffusion based\n\"guilt-by-association\" and graph-theoretic methods have had success in\ninferring gene functions. Here we seek to improve function prediction by\nintegrating diffusion-based methods with a novel dimensionality reduction\ntechnique to overcome the incomplete and noisy nature of network data. In this\npaper, we introduce diffusion component analysis (DCA), a framework that plugs\nin a diffusion model and learns a low-dimensional vector representation of each\nnode to encode the topological properties of a network. As a proof of concept,\nwe demonstrate DCA's substantial improvement over state-of-the-art\ndiffusion-based approaches in predicting protein function from molecular\ninteraction networks. Moreover, our DCA framework can integrate multiple\nnetworks from heterogeneous sources, consisting of genomic information,\nbiochemical experiments and other resources, to even further improve function\nprediction. Yet another layer of performance gain is achieved by integrating\nthe DCA framework with support vector machines that take our node vector\nrepresentations as features. Overall, our DCA framework provides a novel\nrepresentation of nodes in a network that can be used as a plug-in architecture\nto other machine learning algorithms to decipher topological properties of and\nobtain novel insights into interactomes.",
            "categories": [
                "q-bio.MN",
                "cs.LG",
                "cs.SI",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1504.02719v1",
            "date": "2015-04-10 15:42:11+00:00"
        },
        {
            "title": "ProtVec: A Continuous Distributed Representation of Biological Sequences",
            "authors": [
                "Ehsaneddin Asgari",
                "Mohammad R. K. Mofrad"
            ],
            "abstract": "We introduce a new representation and feature extraction method for\nbiological sequences. Named bio-vectors (BioVec) to refer to biological\nsequences in general with protein-vectors (ProtVec) for proteins (amino-acid\nsequences) and gene-vectors (GeneVec) for gene sequences, this representation\ncan be widely used in applications of deep learning in proteomics and genomics.\nIn the present paper, we focus on protein-vectors that can be utilized in a\nwide array of bioinformatics investigations such as family classification,\nprotein visualization, structure prediction, disordered protein identification,\nand protein-protein interaction prediction. In this method, we adopt artificial\nneural network approaches and represent a protein sequence with a single dense\nn-dimensional vector. To evaluate this method, we apply it in classification of\n324,018 protein sequences obtained from Swiss-Prot belonging to 7,027 protein\nfamilies, where an average family classification accuracy of 93%+-0.06% is\nobtained, outperforming existing family classification methods. In addition, we\nuse ProtVec representation to predict disordered proteins from structured\nproteins. Two databases of disordered sequences are used: the DisProt database\nas well as a database featuring the disordered regions of nucleoporins rich\nwith phenylalanine-glycine repeats (FG-Nups). Using support vector machine\nclassifiers, FG-Nup sequences are distinguished from structured protein\nsequences found in Protein Data Bank (PDB) with a 99.8% accuracy, and\nunstructured DisProt sequences are differentiated from structured DisProt\nsequences with 100.0% accuracy. These results indicate that by only providing\nsequence data for various proteins into this model, accurate information about\nprotein structure can be determined.",
            "categories": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1503.05140v2",
            "date": "2015-03-17 17:55:22+00:00"
        },
        {
            "title": "Microbial community pattern detection in human body habitats via ensemble clustering framework",
            "authors": [
                "Peng Yang",
                "Xiaoquan Su",
                "Le Ou-Yang",
                "Hon-Nian Chua",
                "Xiao-Li Li",
                "Kang Ning"
            ],
            "abstract": "The human habitat is a host where microbial species evolve, function, and\ncontinue to evolve. Elucidating how microbial communities respond to human\nhabitats is a fundamental and critical task, as establishing baselines of human\nmicrobiome is essential in understanding its role in human disease and health.\nHowever, current studies usually overlook a complex and interconnected\nlandscape of human microbiome and limit the ability in particular body habitats\nwith learning models of specific criterion. Therefore, these methods could not\ncapture the real-world underlying microbial patterns effectively. To obtain a\ncomprehensive view, we propose a novel ensemble clustering framework to mine\nthe structure of microbial community pattern on large-scale metagenomic data.\nParticularly, we first build a microbial similarity network via integrating\n1920 metagenomic samples from three body habitats of healthy adults. Then a\nnovel symmetric Nonnegative Matrix Factorization (NMF) based ensemble model is\nproposed and applied onto the network to detect clustering pattern. Extensive\nexperiments are conducted to evaluate the effectiveness of our model on\nderiving microbial community with respect to body habitat and host gender. From\nclustering results, we observed that body habitat exhibits a strong bound but\nnon-unique microbial structural patterns. Meanwhile, human microbiome reveals\ndifferent degree of structural variations over body habitat and host gender. In\nsummary, our ensemble clustering framework could efficiently explore integrated\nclustering results to accurately identify microbial communities, and provide a\ncomprehensive view for a set of microbial communities. Such trends depict an\nintegrated biography of microbial communities, which offer a new insight\ntowards uncovering pathogenic model of human microbiome.",
            "categories": [
                "q-bio.QM",
                "cs.CE",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1412.7384v3",
            "date": "2014-12-21 12:52:45+00:00"
        },
        {
            "title": "Feature extraction from complex networks: A case of study in genomic sequences classification",
            "authors": [
                "Bruno Mendes Moro Conque",
                "Andr\u00e9 Yoshiaki Kashiwabara",
                "Fabr\u00edcio Martins Lopes"
            ],
            "abstract": "This work presents a new approach for classification of genomic sequences\nfrom measurements of complex networks and information theory. For this, it is\nconsidered the nucleotides, dinucleotides and trinucleotides of a genomic\nsequence. For each of them, the entropy, sum entropy and maximum entropy values\nare calculated.For each of them is also generated a network, in which the nodes\nare the nucleotides, dinucleotides or trinucleotides and its edges are\nestimated by observing the respective adjacency among them in the genomic\nsequence. In this way, it is generated three networks, for which measures of\ncomplex networks are extracted.These measures together with measures of\ninformation theory comprise a feature vector representing a genomic sequence.\nThus, the feature vector is used for classification by methods such as SVM,\nMultiLayer Perceptron, J48, IBK, Naive Bayes and Random Forest in order to\nevaluate the proposed approach.It was adopted coding sequences, intergenic\nsequences and TSS (Transcriptional Starter Sites) as datasets, for which the\nbetter results were obtained by the Random Forest with 91.2%, followed by J48\nwith 89.1% and SVM with 84.8% of accuracy. These results indicate that the new\napproach of feature extraction has its value, reaching good levels of\nclassification even considering only the genomic sequences, i.e., no other a\npriori knowledge about them is considered.",
            "categories": [
                "cs.CE",
                "cs.LG",
                "q-bio.QM"
            ],
            "link": "http://arxiv.org/pdf/1412.5627v1",
            "date": "2014-12-17 21:31:51+00:00"
        },
        {
            "title": "Covariate-assisted spectral clustering",
            "authors": [
                "Norbert Binkiewicz",
                "Joshua T. Vogelstein",
                "Karl Rohe"
            ],
            "abstract": "Biological and social systems consist of myriad interacting units. The\ninteractions can be represented in the form of a graph or network. Measurements\nof these graphs can reveal the underlying structure of these interactions,\nwhich provides insight into the systems that generated the graphs. Moreover, in\napplications such as connectomics, social networks, and genomics, graph data\nare accompanied by contextualizing measures on each node. We utilize these node\ncovariates to help uncover latent communities in a graph, using a modification\nof spectral clustering. Statistical guarantees are provided under a joint\nmixture model that we call the node-contextualized stochastic blockmodel,\nincluding a bound on the mis-clustering rate. The bound is used to derive\nconditions for achieving perfect clustering. For most simulated cases,\ncovariate-assisted spectral clustering yields results superior to regularized\nspectral clustering without node covariates and to an adaptation of canonical\ncorrelation analysis. We apply our clustering method to large brain graphs\nderived from diffusion MRI data, using the node locations or neurological\nregion membership as covariates. In both cases, covariate-assisted spectral\nclustering yields clusters that are easier to interpret neurologically.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.ME",
                "stat.TH"
            ],
            "link": "http://arxiv.org/pdf/1411.2158v5",
            "date": "2014-11-08 20:14:59+00:00"
        },
        {
            "title": "Network-based Isoform Quantification with RNA-Seq Data for Cancer Transcriptome Analysis",
            "authors": [
                "Wei Zhang",
                "Jae-Woong Chang",
                "Lilong Lin",
                "Kay Minn",
                "Baolin Wu",
                "Jeremy Chien",
                "Jeongsik Yong",
                "Hui Zheng",
                "Rui Kuang"
            ],
            "abstract": "High-throughput mRNA sequencing (RNA-Seq) is widely used for transcript\nquantification of gene isoforms. Since RNA-Seq data alone is often not\nsufficient to accurately identify the read origins from the isoforms for\nquantification, we propose to explore protein domain-domain interactions as\nprior knowledge for integrative analysis with RNA-seq data. We introduce a\nNetwork-based method for RNA-Seq-based Transcript Quantification (Net-RSTQ) to\nintegrate protein domain-domain interaction network with short read alignments\nfor transcript abundance estimation. Based on our observation that the\nabundances of the neighboring isoforms by domain-domain interactions in the\nnetwork are positively correlated, Net-RSTQ models the expression of the\nneighboring transcripts as Dirichlet priors on the likelihood of the observed\nread alignments against the transcripts in one gene. The transcript abundances\nof all the genes are then jointly estimated with alternating optimization of\nmultiple EM problems. In simulation Net-RSTQ effectively improved isoform\ntranscript quantifications when isoform co-expressions correlate with their\ninteractions. qRT-PCR results on 25 multi-isoform genes in a stem cell line, an\novarian cancer cell line, and a breast cancer cell line also showed that\nNet-RSTQ estimated more consistent isoform proportions with RNA-Seq data. In\nthe experiments on the RNA-Seq data in The Cancer Genome Atlas (TCGA), the\ntranscript abundances estimated by Net-RSTQ are more informative for patient\nsample classification of ovarian cancer, breast cancer and lung cancer. All\nexperimental results collectively support that Net-RSTQ is a promising approach\nfor isoform quantification.",
            "categories": [
                "cs.CE",
                "cs.AI",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1403.5029v3",
            "date": "2014-03-20 02:35:15+00:00"
        },
        {
            "title": "Identification of Protein Coding Regions in Genomic DNA Using Unsupervised FMACA Based Pattern Classifier",
            "authors": [
                "Pokkuluri Kiran Sree",
                "Inampudi Ramesh Babu"
            ],
            "abstract": "Genes carry the instructions for making proteins that are found in a cell as\na specific sequence of nucleotides that are found in DNA molecules. But, the\nregions of these genes that code for proteins may occupy only a small region of\nthe sequence. Identifying the coding regions play a vital role in understanding\nthese genes. In this paper we propose a unsupervised Fuzzy Multiple Attractor\nCellular Automata (FMCA) based pattern classifier to identify the coding region\nof a DNA sequence. We propose a distinct K-Means algorithm for designing FMACA\nclassifier which is simple, efficient and produces more accurate classifier\nthan that has previously been obtained for a range of different sequence\nlengths. Experimental results confirm the scalability of the proposed\nUnsupervised FCA based classifier to handle large volume of datasets\nirrespective of the number of classes, tuples and attributes. Good\nclassification accuracy has been established.",
            "categories": [
                "cs.CE",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1401.6484v1",
            "date": "2014-01-25 01:48:14+00:00"
        },
        {
            "title": "High dimensional Sparse Gaussian Graphical Mixture Model",
            "authors": [
                "Anani Lotsi",
                "Ernst Wit"
            ],
            "abstract": "This paper considers the problem of networks reconstruction from\nheterogeneous data using a Gaussian Graphical Mixture Model (GGMM). It is well\nknown that parameter estimation in this context is challenging due to large\nnumbers of variables coupled with the degeneracy of the likelihood. We propose\nas a solution a penalized maximum likelihood technique by imposing an $l_{1}$\npenalty on the precision matrix. Our approach shrinks the parameters thereby\nresulting in better identifiability and variable selection. We use the\nExpectation Maximization (EM) algorithm which involves the graphical LASSO to\nestimate the mixing coefficients and the precision matrices. We show that under\ncertain regularity conditions the Penalized Maximum Likelihood (PML) estimates\nare consistent. We demonstrate the performance of the PML estimator through\nsimulations and we show the utility of our method for high dimensional data\nanalysis in a genomic application.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/1308.3381v3",
            "date": "2013-08-15 13:17:47+00:00"
        },
        {
            "title": "Protein (Multi-)Location Prediction: Using Location Inter-Dependencies in a Probabilistic Framework",
            "authors": [
                "Ramanuja Simha",
                "Hagit Shatkay"
            ],
            "abstract": "Knowing the location of a protein within the cell is important for\nunderstanding its function, role in biological processes, and potential use as\na drug target. Much progress has been made in developing computational methods\nthat predict single locations for proteins, assuming that proteins localize to\na single location. However, it has been shown that proteins localize to\nmultiple locations. While a few recent systems have attempted to predict\nmultiple locations of proteins, they typically treat locations as independent\nor capture inter-dependencies by treating each locations-combination present in\nthe training set as an individual location-class. We present a new method and a\npreliminary system we have developed that directly incorporates\ninter-dependencies among locations into the multiple-location-prediction\nprocess, using a collection of Bayesian network classifiers. We evaluate our\nsystem on a dataset of single- and multi-localized proteins. Our results,\nobtained by incorporating inter-dependencies are significantly higher than\nthose obtained by classifiers that do not use inter-dependencies. The\nperformance of our system on multi-localized proteins is comparable to a top\nperforming system (YLoc+), without restricting predictions to be based only on\nlocation-combinations present in the training set.",
            "categories": [
                "q-bio.QM",
                "cs.CE",
                "cs.LG",
                "q-bio.GN"
            ],
            "link": "http://arxiv.org/pdf/1307.7795v1",
            "date": "2013-07-30 03:19:05+00:00"
        },
        {
            "title": "A Comprehensive Evaluation of Machine Learning Techniques for Cancer Class Prediction Based on Microarray Data",
            "authors": [
                "Khalid Raza",
                "Atif N Hasan"
            ],
            "abstract": "Prostate cancer is among the most common cancer in males and its\nheterogeneity is well known. Its early detection helps making therapeutic\ndecision. There is no standard technique or procedure yet which is full-proof\nin predicting cancer class. The genomic level changes can be detected in gene\nexpression data and those changes may serve as standard model for any random\ncancer data for class prediction. Various techniques were implied on prostate\ncancer data set in order to accurately predict cancer class including machine\nlearning techniques. Huge number of attributes and few number of sample in\nmicroarray data leads to poor machine learning, therefore the most challenging\npart is attribute reduction or non significant gene reduction. In this work we\nhave compared several machine learning techniques for their accuracy in\npredicting the cancer class. Machine learning is effective when number of\nattributes (genes) are larger than the number of samples which is rarely\npossible with gene expression data. Attribute reduction or gene filtering is\nabsolutely required in order to make the data more meaningful as most of the\ngenes do not participate in tumor development and are irrelevant for cancer\nprediction. Here we have applied combination of statistical techniques such as\ninter-quartile range and t-test, which has been effective in filtering\nsignificant genes and minimizing noise from data. Further we have done a\ncomprehensive evaluation of ten state-of-the-art machine learning techniques\nfor their accuracy in class prediction of prostate cancer. Out of these\ntechniques, Bayes Network out performed with an accuracy of 94.11% followed by\nNavie Bayes with an accuracy of 91.17%. To cross validate our results, we\nmodified our training dataset in six different way and found that average\nsensitivity, specificity, precision and accuracy of Bayes Network is highest\namong all other techniques used.",
            "categories": [
                "cs.LG",
                "cs.CE"
            ],
            "link": "http://arxiv.org/pdf/1307.7050v1",
            "date": "2013-07-26 14:44:16+00:00"
        },
        {
            "title": "Verdict Accuracy of Quick Reduct Algorithm using Clustering and Classification Techniques for Gene Expression Data",
            "authors": [
                "T. Chandrasekhar",
                "K. Thangavel",
                "E. N. Sathishkumar"
            ],
            "abstract": "In most gene expression data, the number of training samples is very small\ncompared to the large number of genes involved in the experiments. However,\namong the large amount of genes, only a small fraction is effective for\nperforming a certain task. Furthermore, a small subset of genes is desirable in\ndeveloping gene expression based diagnostic tools for delivering reliable and\nunderstandable results. With the gene selection results, the cost of biological\nexperiment and decision can be greatly reduced by analyzing only the marker\ngenes. An important application of gene expression data in functional genomics\nis to classify samples according to their gene expression profiles. Feature\nselection (FS) is a process which attempts to select more informative features.\nIt is one of the important steps in knowledge discovery. Conventional\nsupervised FS methods evaluate various feature subsets using an evaluation\nfunction or metric to select only those features which are related to the\ndecision classes of the data under consideration. This paper studies a feature\nselection method based on rough set theory. Further K-Means, Fuzzy C-Means\n(FCM) algorithm have implemented for the reduced feature set without\nconsidering class labels. Then the obtained results are compared with the\noriginal class labels. Back Propagation Network (BPN) has also been used for\nclassification. Then the performance of K-Means, FCM, and BPN are analyzed\nthrough the confusion matrix. It is found that the BPN is performing well\ncomparatively.",
            "categories": [
                "cs.LG",
                "cs.CE",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1306.1323v1",
            "date": "2013-06-06 07:26:06+00:00"
        },
        {
            "title": "Enhancing the functional content of protein interaction networks",
            "authors": [
                "Gaurav Pandey",
                "Sahil Manocha",
                "Gowtham Atluri",
                "Vipin Kumar"
            ],
            "abstract": "Protein interaction networks are a promising type of data for studying\ncomplex biological systems. However, despite the rich information embedded in\nthese networks, they face important data quality challenges of noise and\nincompleteness that adversely affect the results obtained from their analysis.\nHere, we explore the use of the concept of common neighborhood similarity\n(CNS), which is a form of local structure in networks, to address these issues.\nAlthough several CNS measures have been proposed in the literature, an\nunderstanding of their relative efficacies for the analysis of interaction\nnetworks has been lacking. We follow the framework of graph transformation to\nconvert the given interaction network into a transformed network corresponding\nto a variety of CNS measures evaluated. The effectiveness of each measure is\nthen estimated by comparing the quality of protein function predictions\nobtained from its corresponding transformed network with those from the\noriginal network. Using a large set of S. cerevisiae interactions, and a set of\n136 GO terms, we find that several of the transformed networks produce more\naccurate predictions than those obtained from the original network. In\nparticular, the $HC.cont$ measure proposed here performs particularly well for\nthis task. Further investigation reveals that the two major factors\ncontributing to this improvement are the abilities of CNS measures, especially\n$HC.cont$, to prune out noisy edges and introduce new links between\nfunctionally related proteins.",
            "categories": [
                "q-bio.MN",
                "cs.CE",
                "cs.LG",
                "q-bio.GN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1210.6912v1",
            "date": "2012-10-25 17:13:57+00:00"
        },
        {
            "title": "Bayesian Analysis for miRNA and mRNA Interactions Using Expression Data",
            "authors": [
                "Mingjun Zhong",
                "Rong Liu",
                "Bo Liu"
            ],
            "abstract": "MicroRNAs (miRNAs) are small RNA molecules composed of 19-22 nt, which play\nimportant regulatory roles in post-transcriptional gene regulation by\ninhibiting the translation of the mRNA into proteins or otherwise cleaving the\ntarget mRNA. Inferring miRNA targets provides useful information for\nunderstanding the roles of miRNA in biological processes that are potentially\ninvolved in complex diseases. Statistical methodologies for point estimation,\nsuch as the Least Absolute Shrinkage and Selection Operator (LASSO) algorithm,\nhave been proposed to identify the interactions of miRNA and mRNA based on\nsequence and expression data. In this paper, we propose using the Bayesian\nLASSO (BLASSO) and the non-negative Bayesian LASSO (nBLASSO) to analyse the\ninteractions between miRNA and mRNA using expression data. The proposed\nBayesian methods explore the posterior distributions for those parameters\nrequired to model the miRNA-mRNA interactions. These approaches can be used to\nobserve the inferred effects of the miRNAs on the targets by plotting the\nposterior distributions of those parameters. For comparison purposes, the Least\nSquares Regression (LSR), Ridge Regression (RR), LASSO, non-negative LASSO\n(nLASSO), and the proposed Bayesian approaches were applied to four public\ndatasets. We concluded that nLASSO and nBLASSO perform best in terms of\nsensitivity and specificity. Compared to the point estimate algorithms, which\nonly provide single estimates for those parameters, the Bayesian methods are\nmore meaningful and provide credible intervals, which take into account the\nuncertainty of the inferred interactions of the miRNA and mRNA. Furthermore,\nBayesian methods naturally provide statistical significance to select\nconvincing inferred interactions, while point estimate algorithms require a\nmanually chosen threshold, which is less meaningful, to choose the possible\ninteractions.",
            "categories": [
                "stat.AP",
                "cs.LG",
                "q-bio.GN",
                "q-bio.MN",
                "stat.ML"
            ],
            "link": "http://arxiv.org/pdf/1210.3456v2",
            "date": "2012-10-12 09:03:14+00:00"
        },
        {
            "title": "Supervised Feature Selection in Graphs with Path Coding Penalties and Network Flows",
            "authors": [
                "Julien Mairal",
                "Bin Yu"
            ],
            "abstract": "We consider supervised learning problems where the features are embedded in a\ngraph, such as gene expressions in a gene network. In this context, it is of\nmuch interest to automatically select a subgraph with few connected components;\nby exploiting prior knowledge, one can indeed improve the prediction\nperformance or obtain results that are easier to interpret. Regularization or\npenalty functions for selecting features in graphs have recently been proposed,\nbut they raise new algorithmic challenges. For example, they typically require\nsolving a combinatorially hard selection problem among all connected subgraphs.\nIn this paper, we propose computationally feasible strategies to select a\nsparse and well-connected subset of features sitting on a directed acyclic\ngraph (DAG). We introduce structured sparsity penalties over paths on a DAG\ncalled \"path coding\" penalties. Unlike existing regularization functions that\nmodel long-range interactions between features in a graph, path coding\npenalties are tractable. The penalties and their proximal operators involve\npath selection problems, which we efficiently solve by leveraging network flow\noptimization. We experimentally show on synthetic, image, and genomic data that\nour approach is scalable and leads to more connected subgraphs than other\nregularization functions for graphs.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ],
            "link": "http://arxiv.org/pdf/1204.4539v3",
            "date": "2012-04-20 06:24:37+00:00"
        },
        {
            "title": "Inferring Disease and Gene Set Associations with Rank Coherence in Networks",
            "authors": [
                "TaeHyun Hwang",
                "Wei Zhang",
                "Maoqiang Xie",
                "Rui Kuang"
            ],
            "abstract": "A computational challenge to validate the candidate disease genes identified\nin a high-throughput genomic study is to elucidate the associations between the\nset of candidate genes and disease phenotypes. The conventional gene set\nenrichment analysis often fails to reveal associations between disease\nphenotypes and the gene sets with a short list of poorly annotated genes,\nbecause the existing annotations of disease causative genes are incomplete. We\npropose a network-based computational approach called rcNet to discover the\nassociations between gene sets and disease phenotypes. Assuming coherent\nassociations between the genes ranked by their relevance to the query gene set,\nand the disease phenotypes ranked by their relevance to the hidden target\ndisease phenotypes of the query gene set, we formulate a learning framework\nmaximizing the rank coherence with respect to the known disease phenotype-gene\nassociations. An efficient algorithm coupling ridge regression with label\npropagation, and two variants are introduced to find the optimal solution of\nthe framework. We evaluated the rcNet algorithms and existing baseline methods\nwith both leave-one-out cross-validation and a task of predicting recently\ndiscovered disease-gene associations in OMIM. The experiments demonstrated that\nthe rcNet algorithms achieved the best overall rankings compared to the\nbaselines. To further validate the reproducibility of the performance, we\napplied the algorithms to identify the target diseases of novel candidate\ndisease genes obtained from recent studies of GWAS, DNA copy number variation\nanalysis, and gene expression profiling. The algorithms ranked the target\ndisease of the candidate genes at the top of the rank list in many cases across\nall the three case studies. The rcNet algorithms are available as a webtool for\ndisease and gene set association analysis at\nhttp://compbio.cs.umn.edu/dgsa_rcNet.",
            "categories": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG",
                "q-bio.MN"
            ],
            "link": "http://arxiv.org/pdf/1102.3919v1",
            "date": "2011-02-18 21:01:38+00:00"
        },
        {
            "title": "Applications of Machine Learning Methods to Quantifying Phenotypic Traits that Distinguish the Wild Type from the Mutant Arabidopsis Thaliana Seedlings during Root Gravitropism",
            "authors": [
                "Hesam T. Dashti",
                "Jernej Tonejc",
                "Adel Ardalan",
                "Alireza F. Siahpirani",
                "Sabrina Guettes",
                "Zohreh Sharif",
                "Liya Wang",
                "Amir H. Assadi"
            ],
            "abstract": "Post-genomic research deals with challenging problems in screening genomes of\norganisms for particular functions or potential for being the targets of\ngenetic engineering for desirable biological features. 'Phenotyping' of wild\ntype and mutants is a time-consuming and costly effort by many individuals.\nThis article is a preliminary progress report in research on large-scale\nautomation of phenotyping steps (imaging, informatics and data analysis) needed\nto study plant gene-proteins networks that influence growth and development of\nplants. Our results undermine the significance of phenotypic traits that are\nimplicit in patterns of dynamics in plant root response to sudden changes of\nits environmental conditions, such as sudden re-orientation of the root tip\nagainst the gravity vector. Including dynamic features besides the common\nmorphological ones has paid off in design of robust and accurate machine\nlearning methods to automate a typical phenotyping scenario, i.e. to\ndistinguish the wild type from the mutants.",
            "categories": [
                "q-bio.QM",
                "cs.CE",
                "cs.LG",
                "q-bio.GN",
                "J.3; I.5.3; I.2.9"
            ],
            "link": "http://arxiv.org/pdf/1008.5390v1",
            "date": "2010-08-31 18:54:33+00:00"
        },
        {
            "title": "Uncovering protein interaction in abstracts and text using a novel linear model and word proximity networks",
            "authors": [
                "Alaa Abi-Haidar",
                "Jasleen Kaur",
                "Ana G. Maguitman",
                "Predrag Radivojac",
                "Andreas Retchsteiner",
                "Karin Verspoor",
                "Zhiping Wang",
                "Luis M. Rocha"
            ],
            "abstract": "We participated in three of the protein-protein interaction subtasks of the\nSecond BioCreative Challenge: classification of abstracts relevant for\nprotein-protein interaction (IAS), discovery of protein pairs (IPS) and text\npassages characterizing protein interaction (ISS) in full text documents. We\napproached the abstract classification task with a novel, lightweight linear\nmodel inspired by spam-detection techniques, as well as an uncertainty-based\nintegration scheme. We also used a Support Vector Machine and the Singular\nValue Decomposition on the same features for comparison purposes. Our approach\nto the full text subtasks (protein pair and passage identification) includes a\nfeature expansion method based on word-proximity networks. Our approach to the\nabstract classification task (IAS) was among the top submissions for this task\nin terms of the measures of performance used in the challenge evaluation\n(accuracy, F-score and AUC). We also report on a web-tool we produced using our\napproach: the Protein Interaction Abstract Relevance Evaluator (PIARE). Our\napproach to the full text tasks resulted in one of the highest recall rates as\nwell as mean reciprocal rank of correct passages. Our approach to abstract\nclassification shows that a simple linear model, using relatively few features,\nis capable of generalizing and uncovering the conceptual nature of\nprotein-protein interaction from the bibliome. Since the novel approach is\nbased on a very lightweight linear model, it can be easily ported and applied\nto similar problems. In full text problems, the expansion of word features with\nword-proximity networks is shown to be useful, though the need for some\nimprovements is discussed.",
            "categories": [
                "cs.IR",
                "cs.LG"
            ],
            "link": "http://arxiv.org/pdf/0812.1029v1",
            "date": "2008-12-04 21:37:35+00:00"
        },
        {
            "title": "Structure induction by lossless graph compression",
            "authors": [
                "Leonid Peshkin"
            ],
            "abstract": "This work is motivated by the necessity to automate the discovery of\nstructure in vast and evergrowing collection of relational data commonly\nrepresented as graphs, for example genomic networks. A novel algorithm, dubbed\nGraphitour, for structure induction by lossless graph compression is presented\nand illustrated by a clear and broadly known case of nested structure in a DNA\nmolecule. This work extends to graphs some well established approaches to\ngrammatical inference previously applied only to strings. The bottom-up graph\ncompression problem is related to the maximum cardinality (non-bipartite)\nmaximum cardinality matching problem. The algorithm accepts a variety of graph\ntypes including directed graphs and graphs with labeled nodes and arcs. The\nresulting structure could be used for representation and classification of\ngraphs.",
            "categories": [
                "cs.DS",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "I.2.6; G.2.2; E.1; E.4; F.4.2; G.2.3; I.3.5; I.4.2; I.5.3; J.3"
            ],
            "link": "http://arxiv.org/pdf/cs/0703132v1",
            "date": "2007-03-27 05:46:31+00:00"
        }
    ]
}